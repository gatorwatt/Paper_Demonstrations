{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00 - Initialize and Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install:\n",
    "\n",
    "#!pip install Automunge\n",
    "\n",
    "#(to run full notebook you may also need to pip install Catboost, AutoGluon, and FLAML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import:\n",
    "\n",
    "from Automunge import *\n",
    "am = AutoMunge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pick an arbitrary data set we'll utilize the Ames Housing tabular set which was subject of some of our benchmarking experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#housing set\n",
    "df_train = pd.read_csv('housing_train.csv')\n",
    "df_test = pd.read_csv('housing_test.csv')\n",
    "\n",
    "labels_column = 'SalePrice'\n",
    "trainID_column = 'Id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the data looks like in received form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>706</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>978</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>486</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Shng</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>216</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>350.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>655</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>9</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
       "0         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "1         Lvl    AllPub       FR2       Gtl      Veenker      Feedr   \n",
       "2         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "3         Lvl    AllPub    Corner       Gtl      Crawfor       Norm   \n",
       "4         Lvl    AllPub       FR2       Gtl      NoRidge       Norm   \n",
       "\n",
       "  Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       Norm     1Fam     2Story            7            5       2003   \n",
       "1       Norm     1Fam     1Story            6            8       1976   \n",
       "2       Norm     1Fam     2Story            7            5       2001   \n",
       "3       Norm     1Fam     2Story            7            5       1915   \n",
       "4       Norm     1Fam     2Story            8            5       2000   \n",
       "\n",
       "   YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
       "0          2003     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "1          1976     Gable  CompShg     MetalSd     MetalSd       None   \n",
       "2          2002     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "3          1970     Gable  CompShg     Wd Sdng     Wd Shng       None   \n",
       "4          2000     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "\n",
       "   MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure  \\\n",
       "0       196.0        Gd        TA      PConc       Gd       TA           No   \n",
       "1         0.0        TA        TA     CBlock       Gd       TA           Gd   \n",
       "2       162.0        Gd        TA      PConc       Gd       TA           Mn   \n",
       "3         0.0        TA        TA     BrkTil       TA       Gd           No   \n",
       "4       350.0        Gd        TA      PConc       Gd       TA           Av   \n",
       "\n",
       "  BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "0          GLQ         706          Unf           0        150          856   \n",
       "1          ALQ         978          Unf           0        284         1262   \n",
       "2          GLQ         486          Unf           0        434          920   \n",
       "3          ALQ         216          Unf           0        540          756   \n",
       "4          GLQ         655          Unf           0        490         1145   \n",
       "\n",
       "  Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n",
       "0    GasA        Ex          Y      SBrkr       856       854             0   \n",
       "1    GasA        Ex          Y      SBrkr      1262         0             0   \n",
       "2    GasA        Ex          Y      SBrkr       920       866             0   \n",
       "3    GasA        Gd          Y      SBrkr       961       756             0   \n",
       "4    GasA        Ex          Y      SBrkr      1145      1053             0   \n",
       "\n",
       "   GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
       "0       1710             1             0         2         1             3   \n",
       "1       1262             0             1         2         0             3   \n",
       "2       1786             1             0         2         1             3   \n",
       "3       1717             1             0         1         0             3   \n",
       "4       2198             1             0         2         1             4   \n",
       "\n",
       "   KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu  \\\n",
       "0             1          Gd             8        Typ           0         NaN   \n",
       "1             1          TA             6        Typ           1          TA   \n",
       "2             1          Gd             6        Typ           1          TA   \n",
       "3             1          Gd             7        Typ           1          Gd   \n",
       "4             1          Gd             9        Typ           1          TA   \n",
       "\n",
       "  GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n",
       "0     Attchd       2003.0          RFn           2         548         TA   \n",
       "1     Attchd       1976.0          RFn           2         460         TA   \n",
       "2     Attchd       2001.0          RFn           2         608         TA   \n",
       "3     Detchd       1998.0          Unf           3         642         TA   \n",
       "4     Attchd       2000.0          RFn           3         836         TA   \n",
       "\n",
       "  GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "0         TA          Y           0           61              0          0   \n",
       "1         TA          Y         298            0              0          0   \n",
       "2         TA          Y           0           42              0          0   \n",
       "3         TA          Y           0           35            272          0   \n",
       "4         TA          Y         192           84              0          0   \n",
       "\n",
       "   ScreenPorch  PoolArea PoolQC Fence MiscFeature  MiscVal  MoSold  YrSold  \\\n",
       "0            0         0    NaN   NaN         NaN        0       2    2008   \n",
       "1            0         0    NaN   NaN         NaN        0       5    2007   \n",
       "2            0         0    NaN   NaN         NaN        0       9    2008   \n",
       "3            0         0    NaN   NaN         NaN        0       2    2006   \n",
       "4            0         0    NaN   NaN         NaN        0      12    2008   \n",
       "\n",
       "  SaleType SaleCondition  SalePrice  \n",
       "0       WD        Normal     208500  \n",
       "1       WD        Normal     181500  \n",
       "2       WD        Normal     223500  \n",
       "3       WD       Abnorml     140000  \n",
       "4       WD        Normal     250000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 300)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the demonstrations below, we'll add to the automunge call designation of labels_column and trainID_column to ensure they are excluded from basis for ML infill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Assigning Infill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each transformation category has some default infill convention to serve as precursor to ML infill. For cases where a user wishes to override defaults assignments can be passed in the assigninfill parameter. ML infill is applied for columns not otherwise assigned, which default can be deactivated with the MLinfill parameter. When MLinfill is deactivated, columns not explicitly assigned will have infill per the default initialization associated with a transformation category. Here we demonstrate deactivating the ML infill default and assigning infill types zero infill to column1 and ML infill just to column2.\n",
    "\n",
    "Not shown, if the data includes a label set or other features such as an index column appropriate for exclusion from ML infill basis, they should be designated with labels_column or trainID_column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the appendix demonsrtates column headers 'column1' and 'column2'\n",
    "#to make applicable to this data set we'll recast as variables\n",
    "\n",
    "column1 = 'OverallQual'\n",
    "column2 = 'GrLivArea'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make imputations a little more visible for inspection\n",
    "# we'll apply an injection of missing data to 50% of entries\n",
    "# in target columns\n",
    "\n",
    "assignnan = {'injections' : {column1 : { 'inject_ratio' : 0.5}, \n",
    "                             column2 : { 'inject_ratio' : 0.5}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is the original code as appeared in the appendix for reference:\n",
    "\n",
    "# assigninfill = {'zeroinfill' : ['column1'], \n",
    "#                 'MLinfill'   : ['column2'] }\n",
    "\n",
    "# train, train_ID, labels, \\\n",
    "# val, val_ID, val_labels, \\\n",
    "# test, test_ID, test_labels, \\\n",
    "# postprocess_dict = \\\n",
    "# am.automunge(df_train,\n",
    "#              MLinfill = False,\n",
    "#              assigninfill = assigninfill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________\n",
      "Begin Automunge processing\n",
      "\n",
      "evaluating column:  MSSubClass\n",
      "processing column:  MSSubClass\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MSSubClass_nmbr', 'MSSubClass_NArw']\n",
      "\n",
      "evaluating column:  MSZoning\n",
      "processing column:  MSZoning\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['MSZoning_NArw', 'MSZoning_1010_0', 'MSZoning_1010_1', 'MSZoning_1010_2']\n",
      "\n",
      "evaluating column:  LotFrontage\n",
      "processing column:  LotFrontage\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['LotFrontage_nmbr', 'LotFrontage_NArw']\n",
      "\n",
      "evaluating column:  LotArea\n",
      "processing column:  LotArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['LotArea_nmbr', 'LotArea_NArw']\n",
      "\n",
      "evaluating column:  Street\n",
      "processing column:  Street\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['Street_bnry', 'Street_NArw']\n",
      "\n",
      "evaluating column:  Alley\n",
      "processing column:  Alley\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['Alley_bnry', 'Alley_NArw']\n",
      "\n",
      "evaluating column:  LotShape\n",
      "processing column:  LotShape\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LotShape_NArw', 'LotShape_1010_0', 'LotShape_1010_1', 'LotShape_1010_2']\n",
      "\n",
      "evaluating column:  LandContour\n",
      "processing column:  LandContour\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LandContour_NArw', 'LandContour_1010_0', 'LandContour_1010_1', 'LandContour_1010_2']\n",
      "\n",
      "evaluating column:  Utilities\n",
      "processing column:  Utilities\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['Utilities_bnry', 'Utilities_NArw']\n",
      "\n",
      "evaluating column:  LotConfig\n",
      "processing column:  LotConfig\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LotConfig_NArw', 'LotConfig_1010_0', 'LotConfig_1010_1', 'LotConfig_1010_2']\n",
      "\n",
      "evaluating column:  LandSlope\n",
      "processing column:  LandSlope\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LandSlope_NArw', 'LandSlope_1010_0', 'LandSlope_1010_1']\n",
      "\n",
      "evaluating column:  Neighborhood\n",
      "processing column:  Neighborhood\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Neighborhood_NArw', 'Neighborhood_1010_0', 'Neighborhood_1010_1', 'Neighborhood_1010_2', 'Neighborhood_1010_3', 'Neighborhood_1010_4']\n",
      "\n",
      "evaluating column:  Condition1\n",
      "processing column:  Condition1\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Condition1_NArw', 'Condition1_1010_0', 'Condition1_1010_1', 'Condition1_1010_2', 'Condition1_1010_3']\n",
      "\n",
      "evaluating column:  Condition2\n",
      "processing column:  Condition2\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Condition2_NArw', 'Condition2_1010_0', 'Condition2_1010_1', 'Condition2_1010_2', 'Condition2_1010_3']\n",
      "\n",
      "evaluating column:  BldgType\n",
      "processing column:  BldgType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BldgType_NArw', 'BldgType_1010_0', 'BldgType_1010_1', 'BldgType_1010_2']\n",
      "\n",
      "evaluating column:  HouseStyle\n",
      "processing column:  HouseStyle\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['HouseStyle_NArw', 'HouseStyle_1010_0', 'HouseStyle_1010_1', 'HouseStyle_1010_2', 'HouseStyle_1010_3']\n",
      "\n",
      "evaluating column:  OverallQual\n",
      "processing column:  OverallQual\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['OverallQual_nmbr', 'OverallQual_NArw']\n",
      "\n",
      "evaluating column:  OverallCond\n",
      "processing column:  OverallCond\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['OverallCond_nmbr', 'OverallCond_NArw']\n",
      "\n",
      "evaluating column:  YearBuilt\n",
      "processing column:  YearBuilt\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['YearBuilt_nmbr', 'YearBuilt_NArw']\n",
      "\n",
      "evaluating column:  YearRemodAdd\n",
      "processing column:  YearRemodAdd\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['YearRemodAdd_nmbr', 'YearRemodAdd_NArw']\n",
      "\n",
      "evaluating column:  RoofStyle\n",
      "processing column:  RoofStyle\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['RoofStyle_NArw', 'RoofStyle_1010_0', 'RoofStyle_1010_1', 'RoofStyle_1010_2']\n",
      "\n",
      "evaluating column:  RoofMatl\n",
      "processing column:  RoofMatl\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['RoofMatl_NArw', 'RoofMatl_1010_0', 'RoofMatl_1010_1', 'RoofMatl_1010_2', 'RoofMatl_1010_3']\n",
      "\n",
      "evaluating column:  Exterior1st\n",
      "processing column:  Exterior1st\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Exterior1st_NArw', 'Exterior1st_1010_0', 'Exterior1st_1010_1', 'Exterior1st_1010_2', 'Exterior1st_1010_3']\n",
      "\n",
      "evaluating column:  Exterior2nd\n",
      "processing column:  Exterior2nd\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Exterior2nd_NArw', 'Exterior2nd_1010_0', 'Exterior2nd_1010_1', 'Exterior2nd_1010_2', 'Exterior2nd_1010_3', 'Exterior2nd_1010_4']\n",
      "\n",
      "evaluating column:  MasVnrType\n",
      "processing column:  MasVnrType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['MasVnrType_NArw', 'MasVnrType_1010_0', 'MasVnrType_1010_1', 'MasVnrType_1010_2']\n",
      "\n",
      "evaluating column:  MasVnrArea\n",
      "processing column:  MasVnrArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MasVnrArea_nmbr', 'MasVnrArea_NArw']\n",
      "\n",
      "evaluating column:  ExterQual\n",
      "processing column:  ExterQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['ExterQual_NArw', 'ExterQual_1010_0', 'ExterQual_1010_1', 'ExterQual_1010_2']\n",
      "\n",
      "evaluating column:  ExterCond\n",
      "processing column:  ExterCond\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['ExterCond_NArw', 'ExterCond_1010_0', 'ExterCond_1010_1', 'ExterCond_1010_2']\n",
      "\n",
      "evaluating column:  Foundation\n",
      "processing column:  Foundation\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Foundation_NArw', 'Foundation_1010_0', 'Foundation_1010_1', 'Foundation_1010_2']\n",
      "\n",
      "evaluating column:  BsmtQual\n",
      "processing column:  BsmtQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtQual_NArw', 'BsmtQual_1010_0', 'BsmtQual_1010_1', 'BsmtQual_1010_2']\n",
      "\n",
      "evaluating column:  BsmtCond\n",
      "processing column:  BsmtCond\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtCond_NArw', 'BsmtCond_1010_0', 'BsmtCond_1010_1', 'BsmtCond_1010_2']\n",
      "\n",
      "evaluating column:  BsmtExposure\n",
      "processing column:  BsmtExposure\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtExposure_NArw', 'BsmtExposure_1010_0', 'BsmtExposure_1010_1', 'BsmtExposure_1010_2']\n",
      "\n",
      "evaluating column:  BsmtFinType1\n",
      "processing column:  BsmtFinType1\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtFinType1_NArw', 'BsmtFinType1_1010_0', 'BsmtFinType1_1010_1', 'BsmtFinType1_1010_2']\n",
      "\n",
      "evaluating column:  BsmtFinSF1\n",
      "processing column:  BsmtFinSF1\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtFinSF1_nmbr', 'BsmtFinSF1_NArw']\n",
      "\n",
      "evaluating column:  BsmtFinType2\n",
      "processing column:  BsmtFinType2\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtFinType2_NArw', 'BsmtFinType2_1010_0', 'BsmtFinType2_1010_1', 'BsmtFinType2_1010_2']\n",
      "\n",
      "evaluating column:  BsmtFinSF2\n",
      "processing column:  BsmtFinSF2\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtFinSF2_nmbr', 'BsmtFinSF2_NArw']\n",
      "\n",
      "evaluating column:  BsmtUnfSF\n",
      "processing column:  BsmtUnfSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtUnfSF_nmbr', 'BsmtUnfSF_NArw']\n",
      "\n",
      "evaluating column:  TotalBsmtSF\n",
      "processing column:  TotalBsmtSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['TotalBsmtSF_nmbr', 'TotalBsmtSF_NArw']\n",
      "\n",
      "evaluating column:  Heating\n",
      "processing column:  Heating\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Heating_NArw', 'Heating_1010_0', 'Heating_1010_1', 'Heating_1010_2']\n",
      "\n",
      "evaluating column:  HeatingQC\n",
      "processing column:  HeatingQC\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['HeatingQC_NArw', 'HeatingQC_1010_0', 'HeatingQC_1010_1', 'HeatingQC_1010_2']\n",
      "\n",
      "evaluating column:  CentralAir\n",
      "processing column:  CentralAir\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['CentralAir_bnry', 'CentralAir_NArw']\n",
      "\n",
      "evaluating column:  Electrical\n",
      "processing column:  Electrical\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Electrical_NArw', 'Electrical_1010_0', 'Electrical_1010_1', 'Electrical_1010_2']\n",
      "\n",
      "evaluating column:  1stFlrSF\n",
      "processing column:  1stFlrSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['1stFlrSF_nmbr', '1stFlrSF_NArw']\n",
      "\n",
      "evaluating column:  2ndFlrSF\n",
      "processing column:  2ndFlrSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['2ndFlrSF_nmbr', '2ndFlrSF_NArw']\n",
      "\n",
      "evaluating column:  LowQualFinSF\n",
      "processing column:  LowQualFinSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['LowQualFinSF_nmbr', 'LowQualFinSF_NArw']\n",
      "\n",
      "evaluating column:  GrLivArea\n",
      "processing column:  GrLivArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GrLivArea_nmbr', 'GrLivArea_NArw']\n",
      "\n",
      "evaluating column:  BsmtFullBath\n",
      "processing column:  BsmtFullBath\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtFullBath_nmbr', 'BsmtFullBath_NArw']\n",
      "\n",
      "evaluating column:  BsmtHalfBath\n",
      "processing column:  BsmtHalfBath\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtHalfBath_NArw', 'BsmtHalfBath_1010_0', 'BsmtHalfBath_1010_1']\n",
      "\n",
      "evaluating column:  FullBath\n",
      "processing column:  FullBath\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['FullBath_nmbr', 'FullBath_NArw']\n",
      "\n",
      "evaluating column:  HalfBath\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing column:  HalfBath\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['HalfBath_NArw', 'HalfBath_1010_0', 'HalfBath_1010_1']\n",
      "\n",
      "evaluating column:  BedroomAbvGr\n",
      "processing column:  BedroomAbvGr\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BedroomAbvGr_nmbr', 'BedroomAbvGr_NArw']\n",
      "\n",
      "evaluating column:  KitchenAbvGr\n",
      "processing column:  KitchenAbvGr\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['KitchenAbvGr_nmbr', 'KitchenAbvGr_NArw']\n",
      "\n",
      "evaluating column:  KitchenQual\n",
      "processing column:  KitchenQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['KitchenQual_NArw', 'KitchenQual_1010_0', 'KitchenQual_1010_1', 'KitchenQual_1010_2']\n",
      "\n",
      "evaluating column:  TotRmsAbvGrd\n",
      "processing column:  TotRmsAbvGrd\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['TotRmsAbvGrd_nmbr', 'TotRmsAbvGrd_NArw']\n",
      "\n",
      "evaluating column:  Functional\n",
      "processing column:  Functional\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Functional_NArw', 'Functional_1010_0', 'Functional_1010_1', 'Functional_1010_2']\n",
      "\n",
      "evaluating column:  Fireplaces\n",
      "processing column:  Fireplaces\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['Fireplaces_nmbr', 'Fireplaces_NArw']\n",
      "\n",
      "evaluating column:  FireplaceQu\n",
      "processing column:  FireplaceQu\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['FireplaceQu_NArw', 'FireplaceQu_1010_0', 'FireplaceQu_1010_1', 'FireplaceQu_1010_2']\n",
      "\n",
      "evaluating column:  GarageType\n",
      "processing column:  GarageType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageType_NArw', 'GarageType_1010_0', 'GarageType_1010_1', 'GarageType_1010_2']\n",
      "\n",
      "evaluating column:  GarageYrBlt\n",
      "processing column:  GarageYrBlt\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GarageYrBlt_nmbr', 'GarageYrBlt_NArw']\n",
      "\n",
      "evaluating column:  GarageFinish\n",
      "processing column:  GarageFinish\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageFinish_NArw', 'GarageFinish_1010_0', 'GarageFinish_1010_1']\n",
      "\n",
      "evaluating column:  GarageCars\n",
      "processing column:  GarageCars\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GarageCars_nmbr', 'GarageCars_NArw']\n",
      "\n",
      "evaluating column:  GarageArea\n",
      "processing column:  GarageArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GarageArea_nmbr', 'GarageArea_NArw']\n",
      "\n",
      "evaluating column:  GarageQual\n",
      "processing column:  GarageQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageQual_NArw', 'GarageQual_1010_0', 'GarageQual_1010_1', 'GarageQual_1010_2']\n",
      "\n",
      "evaluating column:  GarageCond\n",
      "processing column:  GarageCond\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageCond_NArw', 'GarageCond_1010_0', 'GarageCond_1010_1', 'GarageCond_1010_2']\n",
      "\n",
      "evaluating column:  PavedDrive\n",
      "processing column:  PavedDrive\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['PavedDrive_NArw', 'PavedDrive_1010_0', 'PavedDrive_1010_1']\n",
      "\n",
      "evaluating column:  WoodDeckSF\n",
      "processing column:  WoodDeckSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['WoodDeckSF_nmbr', 'WoodDeckSF_NArw']\n",
      "\n",
      "evaluating column:  OpenPorchSF\n",
      "processing column:  OpenPorchSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['OpenPorchSF_nmbr', 'OpenPorchSF_NArw']\n",
      "\n",
      "evaluating column:  EnclosedPorch\n",
      "processing column:  EnclosedPorch\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['EnclosedPorch_nmbr', 'EnclosedPorch_NArw']\n",
      "\n",
      "evaluating column:  3SsnPorch\n",
      "processing column:  3SsnPorch\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['3SsnPorch_nmbr', '3SsnPorch_NArw']\n",
      "\n",
      "evaluating column:  ScreenPorch\n",
      "processing column:  ScreenPorch\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['ScreenPorch_nmbr', 'ScreenPorch_NArw']\n",
      "\n",
      "evaluating column:  PoolArea\n",
      "processing column:  PoolArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['PoolArea_nmbr', 'PoolArea_NArw']\n",
      "\n",
      "evaluating column:  PoolQC\n",
      "processing column:  PoolQC\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['PoolQC_NArw', 'PoolQC_1010_0', 'PoolQC_1010_1']\n",
      "\n",
      "evaluating column:  Fence\n",
      "processing column:  Fence\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Fence_NArw', 'Fence_1010_0', 'Fence_1010_1', 'Fence_1010_2']\n",
      "\n",
      "evaluating column:  MiscFeature\n",
      "processing column:  MiscFeature\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['MiscFeature_NArw', 'MiscFeature_1010_0', 'MiscFeature_1010_1', 'MiscFeature_1010_2']\n",
      "\n",
      "evaluating column:  MiscVal\n",
      "processing column:  MiscVal\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MiscVal_nmbr', 'MiscVal_NArw']\n",
      "\n",
      "evaluating column:  MoSold\n",
      "processing column:  MoSold\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MoSold_nmbr', 'MoSold_NArw']\n",
      "\n",
      "evaluating column:  YrSold\n",
      "processing column:  YrSold\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['YrSold_nmbr', 'YrSold_NArw']\n",
      "\n",
      "evaluating column:  SaleType\n",
      "processing column:  SaleType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['SaleType_NArw', 'SaleType_1010_0', 'SaleType_1010_1', 'SaleType_1010_2', 'SaleType_1010_3']\n",
      "\n",
      "evaluating column:  SaleCondition\n",
      "processing column:  SaleCondition\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['SaleCondition_NArw', 'SaleCondition_1010_0', 'SaleCondition_1010_1', 'SaleCondition_1010_2']\n",
      "\n",
      "______\n",
      "\n",
      "evaluating label column:  SalePrice\n",
      "processing label column:  SalePrice\n",
      "    root label category:  lbnm\n",
      "\n",
      " returned columns:\n",
      "['SalePrice_exc2']\n",
      "\n",
      "______\n",
      "\n",
      "infill to column:  PoolQC_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  PoolQC_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  MiscFeature_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  MiscFeature_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  MiscFeature_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Alley_bnry\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Fence_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Fence_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Fence_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  GrLivArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  OverallQual_nmbr\n",
      "     infill type: zeroinfill\n",
      "\n",
      "infill to column:  FireplaceQu_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  FireplaceQu_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  FireplaceQu_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  LotFrontage_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  GarageCond_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  GarageCond_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  GarageCond_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  GarageFinish_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  GarageFinish_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  GarageQual_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  GarageQual_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  GarageQual_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  GarageType_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  GarageType_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  GarageType_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  GarageYrBlt_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtExposure_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtExposure_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtExposure_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtFinType2_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtFinType2_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtFinType2_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtCond_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtCond_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtCond_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtFinType1_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtFinType1_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtFinType1_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtQual_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtQual_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtQual_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  MasVnrArea_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  MasVnrType_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  MasVnrType_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  MasVnrType_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Electrical_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Electrical_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Electrical_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  1stFlrSF_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  2ndFlrSF_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  3SsnPorch_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BedroomAbvGr_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BldgType_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BldgType_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BldgType_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtFinSF1_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtFinSF2_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtFullBath_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtHalfBath_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtHalfBath_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  BsmtUnfSF_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  CentralAir_bnry\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Condition1_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Condition1_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Condition1_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Condition1_1010_3\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Condition2_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Condition2_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Condition2_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Condition2_1010_3\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  EnclosedPorch_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  ExterCond_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  ExterCond_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  ExterCond_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  ExterQual_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  ExterQual_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  ExterQual_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Exterior1st_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Exterior1st_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Exterior1st_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Exterior1st_1010_3\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_3\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_4\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Fireplaces_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Foundation_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Foundation_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Foundation_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  FullBath_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Functional_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Functional_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Functional_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  GarageArea_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  GarageCars_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  HalfBath_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  HalfBath_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  HeatingQC_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  HeatingQC_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  HeatingQC_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Heating_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Heating_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Heating_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  HouseStyle_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  HouseStyle_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  HouseStyle_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  HouseStyle_1010_3\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  KitchenAbvGr_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  KitchenQual_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  KitchenQual_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  KitchenQual_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  LandContour_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  LandContour_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  LandContour_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  LandSlope_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  LandSlope_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  LotArea_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  LotConfig_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  LotConfig_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  LotConfig_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  LotShape_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  LotShape_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  LotShape_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  LowQualFinSF_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  MSSubClass_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  MSZoning_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  MSZoning_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  MSZoning_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  MiscVal_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  MoSold_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_3\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_4\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  OpenPorchSF_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  OverallCond_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  PavedDrive_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  PavedDrive_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  PoolArea_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  RoofMatl_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  RoofMatl_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  RoofMatl_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  RoofMatl_1010_3\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  RoofStyle_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  RoofStyle_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  RoofStyle_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  SaleCondition_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  SaleCondition_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  SaleCondition_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  SaleType_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  SaleType_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  SaleType_1010_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  SaleType_1010_3\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  ScreenPorch_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Street_bnry\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  TotRmsAbvGrd_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  TotalBsmtSF_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Utilities_bnry\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  WoodDeckSF_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  YearBuilt_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  YearRemodAdd_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  YrSold_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "______\n",
      "\n",
      "versioning serial stamp:\n",
      "_6.13_499221861534_2021-06-03T20:31:51.976957\n",
      "\n",
      "Automunge returned ID column set: \n",
      "['Id', 'Automunge_index']\n",
      "\n",
      "Automunge returned train column set: \n",
      "['MSSubClass_nmbr', 'LotFrontage_nmbr', 'LotArea_nmbr', 'Street_bnry', 'Alley_bnry', 'Utilities_bnry', 'OverallQual_nmbr', 'OverallCond_nmbr', 'YearBuilt_nmbr', 'YearRemodAdd_nmbr', 'MasVnrArea_nmbr', 'BsmtFinSF1_nmbr', 'BsmtFinSF2_nmbr', 'BsmtUnfSF_nmbr', 'TotalBsmtSF_nmbr', 'CentralAir_bnry', '1stFlrSF_nmbr', '2ndFlrSF_nmbr', 'LowQualFinSF_nmbr', 'GrLivArea_nmbr', 'BsmtFullBath_nmbr', 'FullBath_nmbr', 'BedroomAbvGr_nmbr', 'KitchenAbvGr_nmbr', 'TotRmsAbvGrd_nmbr', 'Fireplaces_nmbr', 'GarageYrBlt_nmbr', 'GarageCars_nmbr', 'GarageArea_nmbr', 'WoodDeckSF_nmbr', 'OpenPorchSF_nmbr', 'EnclosedPorch_nmbr', '3SsnPorch_nmbr', 'ScreenPorch_nmbr', 'PoolArea_nmbr', 'MiscVal_nmbr', 'MoSold_nmbr', 'YrSold_nmbr', 'MSSubClass_NArw', 'MSZoning_NArw', 'MSZoning_1010_0', 'MSZoning_1010_1', 'MSZoning_1010_2', 'LotFrontage_NArw', 'LotArea_NArw', 'Street_NArw', 'Alley_NArw', 'LotShape_NArw', 'LotShape_1010_0', 'LotShape_1010_1', 'LotShape_1010_2', 'LandContour_NArw', 'LandContour_1010_0', 'LandContour_1010_1', 'LandContour_1010_2', 'Utilities_NArw', 'LotConfig_NArw', 'LotConfig_1010_0', 'LotConfig_1010_1', 'LotConfig_1010_2', 'LandSlope_NArw', 'LandSlope_1010_0', 'LandSlope_1010_1', 'Neighborhood_NArw', 'Neighborhood_1010_0', 'Neighborhood_1010_1', 'Neighborhood_1010_2', 'Neighborhood_1010_3', 'Neighborhood_1010_4', 'Condition1_NArw', 'Condition1_1010_0', 'Condition1_1010_1', 'Condition1_1010_2', 'Condition1_1010_3', 'Condition2_NArw', 'Condition2_1010_0', 'Condition2_1010_1', 'Condition2_1010_2', 'Condition2_1010_3', 'BldgType_NArw', 'BldgType_1010_0', 'BldgType_1010_1', 'BldgType_1010_2', 'HouseStyle_NArw', 'HouseStyle_1010_0', 'HouseStyle_1010_1', 'HouseStyle_1010_2', 'HouseStyle_1010_3', 'OverallQual_NArw', 'OverallCond_NArw', 'YearBuilt_NArw', 'YearRemodAdd_NArw', 'RoofStyle_NArw', 'RoofStyle_1010_0', 'RoofStyle_1010_1', 'RoofStyle_1010_2', 'RoofMatl_NArw', 'RoofMatl_1010_0', 'RoofMatl_1010_1', 'RoofMatl_1010_2', 'RoofMatl_1010_3', 'Exterior1st_NArw', 'Exterior1st_1010_0', 'Exterior1st_1010_1', 'Exterior1st_1010_2', 'Exterior1st_1010_3', 'Exterior2nd_NArw', 'Exterior2nd_1010_0', 'Exterior2nd_1010_1', 'Exterior2nd_1010_2', 'Exterior2nd_1010_3', 'Exterior2nd_1010_4', 'MasVnrType_NArw', 'MasVnrType_1010_0', 'MasVnrType_1010_1', 'MasVnrType_1010_2', 'MasVnrArea_NArw', 'ExterQual_NArw', 'ExterQual_1010_0', 'ExterQual_1010_1', 'ExterQual_1010_2', 'ExterCond_NArw', 'ExterCond_1010_0', 'ExterCond_1010_1', 'ExterCond_1010_2', 'Foundation_NArw', 'Foundation_1010_0', 'Foundation_1010_1', 'Foundation_1010_2', 'BsmtQual_NArw', 'BsmtQual_1010_0', 'BsmtQual_1010_1', 'BsmtQual_1010_2', 'BsmtCond_NArw', 'BsmtCond_1010_0', 'BsmtCond_1010_1', 'BsmtCond_1010_2', 'BsmtExposure_NArw', 'BsmtExposure_1010_0', 'BsmtExposure_1010_1', 'BsmtExposure_1010_2', 'BsmtFinType1_NArw', 'BsmtFinType1_1010_0', 'BsmtFinType1_1010_1', 'BsmtFinType1_1010_2', 'BsmtFinSF1_NArw', 'BsmtFinType2_NArw', 'BsmtFinType2_1010_0', 'BsmtFinType2_1010_1', 'BsmtFinType2_1010_2', 'BsmtFinSF2_NArw', 'BsmtUnfSF_NArw', 'TotalBsmtSF_NArw', 'Heating_NArw', 'Heating_1010_0', 'Heating_1010_1', 'Heating_1010_2', 'HeatingQC_NArw', 'HeatingQC_1010_0', 'HeatingQC_1010_1', 'HeatingQC_1010_2', 'CentralAir_NArw', 'Electrical_NArw', 'Electrical_1010_0', 'Electrical_1010_1', 'Electrical_1010_2', '1stFlrSF_NArw', '2ndFlrSF_NArw', 'LowQualFinSF_NArw', 'GrLivArea_NArw', 'BsmtFullBath_NArw', 'BsmtHalfBath_NArw', 'BsmtHalfBath_1010_0', 'BsmtHalfBath_1010_1', 'FullBath_NArw', 'HalfBath_NArw', 'HalfBath_1010_0', 'HalfBath_1010_1', 'BedroomAbvGr_NArw', 'KitchenAbvGr_NArw', 'KitchenQual_NArw', 'KitchenQual_1010_0', 'KitchenQual_1010_1', 'KitchenQual_1010_2', 'TotRmsAbvGrd_NArw', 'Functional_NArw', 'Functional_1010_0', 'Functional_1010_1', 'Functional_1010_2', 'Fireplaces_NArw', 'FireplaceQu_NArw', 'FireplaceQu_1010_0', 'FireplaceQu_1010_1', 'FireplaceQu_1010_2', 'GarageType_NArw', 'GarageType_1010_0', 'GarageType_1010_1', 'GarageType_1010_2', 'GarageYrBlt_NArw', 'GarageFinish_NArw', 'GarageFinish_1010_0', 'GarageFinish_1010_1', 'GarageCars_NArw', 'GarageArea_NArw', 'GarageQual_NArw', 'GarageQual_1010_0', 'GarageQual_1010_1', 'GarageQual_1010_2', 'GarageCond_NArw', 'GarageCond_1010_0', 'GarageCond_1010_1', 'GarageCond_1010_2', 'PavedDrive_NArw', 'PavedDrive_1010_0', 'PavedDrive_1010_1', 'WoodDeckSF_NArw', 'OpenPorchSF_NArw', 'EnclosedPorch_NArw', '3SsnPorch_NArw', 'ScreenPorch_NArw', 'PoolArea_NArw', 'PoolQC_NArw', 'PoolQC_1010_0', 'PoolQC_1010_1', 'Fence_NArw', 'Fence_1010_0', 'Fence_1010_1', 'Fence_1010_2', 'MiscFeature_NArw', 'MiscFeature_1010_0', 'MiscFeature_1010_1', 'MiscFeature_1010_2', 'MiscVal_NArw', 'MoSold_NArw', 'YrSold_NArw', 'SaleType_NArw', 'SaleType_1010_0', 'SaleType_1010_1', 'SaleType_1010_2', 'SaleType_1010_3', 'SaleCondition_NArw', 'SaleCondition_1010_0', 'SaleCondition_1010_1', 'SaleCondition_1010_2']\n",
      "\n",
      "Automunge returned label column set: \n",
      "['SalePrice_exc2']\n",
      "\n",
      "_______________\n",
      "Automunge Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "assigninfill = {'zeroinfill':[column1], \n",
    "                'MLinfill':[column2] }\n",
    "\n",
    "train, train_ID, labels, \\\n",
    "val, val_ID, val_labels, \\\n",
    "test, test_ID, test_labels, \\\n",
    "postprocess_dict = \\\n",
    "am.automunge(df_train,\n",
    "             labels_column = 'SalePrice',\n",
    "             trainID_column = 'Id',\n",
    "             MLinfill = False,\n",
    "             assigninfill = assigninfill,\n",
    "             assignnan = assignnan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OverallQual_nmbr</th>\n",
       "      <th>OverallQual_NArw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.904326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.904326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.904326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>-0.089888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     OverallQual_nmbr  OverallQual_NArw\n",
       "393          0.000000                 1\n",
       "999          0.904326                 0\n",
       "208          0.904326                 0\n",
       "159          0.904326                 0\n",
       "295         -0.089888                 0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here is what the returned sets look like\n",
    "#we'll use the column_map stored in postprocess_dict\n",
    "#to access the associated returned columns\n",
    "\n",
    "#column1 had zero infill applied\n",
    "#the rows with a 1 activation in NArw correspond to imputations\n",
    "\n",
    "train[postprocess_dict['column_map'][column1]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea_nmbr</th>\n",
       "      <th>GrLivArea_NArw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>-2.085469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.889904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>1.442302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2.700867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>-1.489032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GrLivArea_nmbr  GrLivArea_NArw\n",
       "393       -2.085469               0\n",
       "999       -0.889904               1\n",
       "208        1.442302               1\n",
       "159        2.700867               1\n",
       "295       -1.489032               0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#column2 was MiscFeature which had ML infill applied\n",
    "#we'll use the column_map stored in postprocess_dict\n",
    "#to access the associated returned columns\n",
    "\n",
    "#column2 had ML infill applied\n",
    "#the rows with a 1 activation in NArw correspond to imputations\n",
    "\n",
    "train[postprocess_dict['column_map'][column2]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. ML Infill Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default ML infill architecture is a Scikit-Learn random forest with default parameters. Alternate auto ML options are currently available as CatBoost, FLAML, and AutoGluon. Parameters can be passed to the models with ML_cmnd.\n",
    "\n",
    "First we’ll demonstrate applying ML infill with the CatBoost library. Note that we can either defer to the library default parameters or also pass parameters to the model initializations or fit operations. Here we also demonstrate assigning a particular GPU device number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________\n",
      "Begin Automunge processing\n",
      "\n",
      "evaluating column:  MSSubClass\n",
      "processing column:  MSSubClass\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MSSubClass_nmbr', 'MSSubClass_NArw']\n",
      "\n",
      "evaluating column:  MSZoning\n",
      "processing column:  MSZoning\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['MSZoning_NArw', 'MSZoning_1010_0', 'MSZoning_1010_1', 'MSZoning_1010_2']\n",
      "\n",
      "evaluating column:  LotFrontage\n",
      "processing column:  LotFrontage\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['LotFrontage_nmbr', 'LotFrontage_NArw']\n",
      "\n",
      "evaluating column:  LotArea\n",
      "processing column:  LotArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['LotArea_nmbr', 'LotArea_NArw']\n",
      "\n",
      "evaluating column:  Street\n",
      "processing column:  Street\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['Street_bnry', 'Street_NArw']\n",
      "\n",
      "evaluating column:  Alley\n",
      "processing column:  Alley\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['Alley_bnry', 'Alley_NArw']\n",
      "\n",
      "evaluating column:  LotShape\n",
      "processing column:  LotShape\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LotShape_NArw', 'LotShape_1010_0', 'LotShape_1010_1', 'LotShape_1010_2']\n",
      "\n",
      "evaluating column:  LandContour\n",
      "processing column:  LandContour\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LandContour_NArw', 'LandContour_1010_0', 'LandContour_1010_1', 'LandContour_1010_2']\n",
      "\n",
      "evaluating column:  Utilities\n",
      "processing column:  Utilities\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['Utilities_bnry', 'Utilities_NArw']\n",
      "\n",
      "evaluating column:  LotConfig\n",
      "processing column:  LotConfig\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LotConfig_NArw', 'LotConfig_1010_0', 'LotConfig_1010_1', 'LotConfig_1010_2']\n",
      "\n",
      "evaluating column:  LandSlope\n",
      "processing column:  LandSlope\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LandSlope_NArw', 'LandSlope_1010_0', 'LandSlope_1010_1']\n",
      "\n",
      "evaluating column:  Neighborhood\n",
      "processing column:  Neighborhood\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Neighborhood_NArw', 'Neighborhood_1010_0', 'Neighborhood_1010_1', 'Neighborhood_1010_2', 'Neighborhood_1010_3', 'Neighborhood_1010_4']\n",
      "\n",
      "evaluating column:  Condition1\n",
      "processing column:  Condition1\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Condition1_NArw', 'Condition1_1010_0', 'Condition1_1010_1', 'Condition1_1010_2', 'Condition1_1010_3']\n",
      "\n",
      "evaluating column:  Condition2\n",
      "processing column:  Condition2\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Condition2_NArw', 'Condition2_1010_0', 'Condition2_1010_1', 'Condition2_1010_2', 'Condition2_1010_3']\n",
      "\n",
      "evaluating column:  BldgType\n",
      "processing column:  BldgType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BldgType_NArw', 'BldgType_1010_0', 'BldgType_1010_1', 'BldgType_1010_2']\n",
      "\n",
      "evaluating column:  HouseStyle\n",
      "processing column:  HouseStyle\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['HouseStyle_NArw', 'HouseStyle_1010_0', 'HouseStyle_1010_1', 'HouseStyle_1010_2', 'HouseStyle_1010_3']\n",
      "\n",
      "evaluating column:  OverallQual\n",
      "processing column:  OverallQual\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['OverallQual_nmbr', 'OverallQual_NArw']\n",
      "\n",
      "evaluating column:  OverallCond\n",
      "processing column:  OverallCond\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['OverallCond_nmbr', 'OverallCond_NArw']\n",
      "\n",
      "evaluating column:  YearBuilt\n",
      "processing column:  YearBuilt\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['YearBuilt_nmbr', 'YearBuilt_NArw']\n",
      "\n",
      "evaluating column:  YearRemodAdd\n",
      "processing column:  YearRemodAdd\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['YearRemodAdd_nmbr', 'YearRemodAdd_NArw']\n",
      "\n",
      "evaluating column:  RoofStyle\n",
      "processing column:  RoofStyle\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['RoofStyle_NArw', 'RoofStyle_1010_0', 'RoofStyle_1010_1', 'RoofStyle_1010_2']\n",
      "\n",
      "evaluating column:  RoofMatl\n",
      "processing column:  RoofMatl\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['RoofMatl_NArw', 'RoofMatl_1010_0', 'RoofMatl_1010_1', 'RoofMatl_1010_2', 'RoofMatl_1010_3']\n",
      "\n",
      "evaluating column:  Exterior1st\n",
      "processing column:  Exterior1st\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Exterior1st_NArw', 'Exterior1st_1010_0', 'Exterior1st_1010_1', 'Exterior1st_1010_2', 'Exterior1st_1010_3']\n",
      "\n",
      "evaluating column:  Exterior2nd\n",
      "processing column:  Exterior2nd\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Exterior2nd_NArw', 'Exterior2nd_1010_0', 'Exterior2nd_1010_1', 'Exterior2nd_1010_2', 'Exterior2nd_1010_3', 'Exterior2nd_1010_4']\n",
      "\n",
      "evaluating column:  MasVnrType\n",
      "processing column:  MasVnrType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['MasVnrType_NArw', 'MasVnrType_1010_0', 'MasVnrType_1010_1', 'MasVnrType_1010_2']\n",
      "\n",
      "evaluating column:  MasVnrArea\n",
      "processing column:  MasVnrArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MasVnrArea_nmbr', 'MasVnrArea_NArw']\n",
      "\n",
      "evaluating column:  ExterQual\n",
      "processing column:  ExterQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['ExterQual_NArw', 'ExterQual_1010_0', 'ExterQual_1010_1', 'ExterQual_1010_2']\n",
      "\n",
      "evaluating column:  ExterCond\n",
      "processing column:  ExterCond\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['ExterCond_NArw', 'ExterCond_1010_0', 'ExterCond_1010_1', 'ExterCond_1010_2']\n",
      "\n",
      "evaluating column:  Foundation\n",
      "processing column:  Foundation\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Foundation_NArw', 'Foundation_1010_0', 'Foundation_1010_1', 'Foundation_1010_2']\n",
      "\n",
      "evaluating column:  BsmtQual\n",
      "processing column:  BsmtQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtQual_NArw', 'BsmtQual_1010_0', 'BsmtQual_1010_1', 'BsmtQual_1010_2']\n",
      "\n",
      "evaluating column:  BsmtCond\n",
      "processing column:  BsmtCond\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtCond_NArw', 'BsmtCond_1010_0', 'BsmtCond_1010_1', 'BsmtCond_1010_2']\n",
      "\n",
      "evaluating column:  BsmtExposure\n",
      "processing column:  BsmtExposure\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtExposure_NArw', 'BsmtExposure_1010_0', 'BsmtExposure_1010_1', 'BsmtExposure_1010_2']\n",
      "\n",
      "evaluating column:  BsmtFinType1\n",
      "processing column:  BsmtFinType1\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtFinType1_NArw', 'BsmtFinType1_1010_0', 'BsmtFinType1_1010_1', 'BsmtFinType1_1010_2']\n",
      "\n",
      "evaluating column:  BsmtFinSF1\n",
      "processing column:  BsmtFinSF1\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtFinSF1_nmbr', 'BsmtFinSF1_NArw']\n",
      "\n",
      "evaluating column:  BsmtFinType2\n",
      "processing column:  BsmtFinType2\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtFinType2_NArw', 'BsmtFinType2_1010_0', 'BsmtFinType2_1010_1', 'BsmtFinType2_1010_2']\n",
      "\n",
      "evaluating column:  BsmtFinSF2\n",
      "processing column:  BsmtFinSF2\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtFinSF2_nmbr', 'BsmtFinSF2_NArw']\n",
      "\n",
      "evaluating column:  BsmtUnfSF\n",
      "processing column:  BsmtUnfSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtUnfSF_nmbr', 'BsmtUnfSF_NArw']\n",
      "\n",
      "evaluating column:  TotalBsmtSF\n",
      "processing column:  TotalBsmtSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['TotalBsmtSF_nmbr', 'TotalBsmtSF_NArw']\n",
      "\n",
      "evaluating column:  Heating\n",
      "processing column:  Heating\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Heating_NArw', 'Heating_1010_0', 'Heating_1010_1', 'Heating_1010_2']\n",
      "\n",
      "evaluating column:  HeatingQC\n",
      "processing column:  HeatingQC\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['HeatingQC_NArw', 'HeatingQC_1010_0', 'HeatingQC_1010_1', 'HeatingQC_1010_2']\n",
      "\n",
      "evaluating column:  CentralAir\n",
      "processing column:  CentralAir\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['CentralAir_bnry', 'CentralAir_NArw']\n",
      "\n",
      "evaluating column:  Electrical\n",
      "processing column:  Electrical\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Electrical_NArw', 'Electrical_1010_0', 'Electrical_1010_1', 'Electrical_1010_2']\n",
      "\n",
      "evaluating column:  1stFlrSF\n",
      "processing column:  1stFlrSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['1stFlrSF_nmbr', '1stFlrSF_NArw']\n",
      "\n",
      "evaluating column:  2ndFlrSF\n",
      "processing column:  2ndFlrSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['2ndFlrSF_nmbr', '2ndFlrSF_NArw']\n",
      "\n",
      "evaluating column:  LowQualFinSF\n",
      "processing column:  LowQualFinSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['LowQualFinSF_nmbr', 'LowQualFinSF_NArw']\n",
      "\n",
      "evaluating column:  GrLivArea\n",
      "processing column:  GrLivArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GrLivArea_nmbr', 'GrLivArea_NArw']\n",
      "\n",
      "evaluating column:  BsmtFullBath\n",
      "processing column:  BsmtFullBath\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtFullBath_nmbr', 'BsmtFullBath_NArw']\n",
      "\n",
      "evaluating column:  BsmtHalfBath\n",
      "processing column:  BsmtHalfBath\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtHalfBath_NArw', 'BsmtHalfBath_1010_0', 'BsmtHalfBath_1010_1']\n",
      "\n",
      "evaluating column:  FullBath\n",
      "processing column:  FullBath\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['FullBath_nmbr', 'FullBath_NArw']\n",
      "\n",
      "evaluating column:  HalfBath\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing column:  HalfBath\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['HalfBath_NArw', 'HalfBath_1010_0', 'HalfBath_1010_1']\n",
      "\n",
      "evaluating column:  BedroomAbvGr\n",
      "processing column:  BedroomAbvGr\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BedroomAbvGr_nmbr', 'BedroomAbvGr_NArw']\n",
      "\n",
      "evaluating column:  KitchenAbvGr\n",
      "processing column:  KitchenAbvGr\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['KitchenAbvGr_nmbr', 'KitchenAbvGr_NArw']\n",
      "\n",
      "evaluating column:  KitchenQual\n",
      "processing column:  KitchenQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['KitchenQual_NArw', 'KitchenQual_1010_0', 'KitchenQual_1010_1', 'KitchenQual_1010_2']\n",
      "\n",
      "evaluating column:  TotRmsAbvGrd\n",
      "processing column:  TotRmsAbvGrd\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['TotRmsAbvGrd_nmbr', 'TotRmsAbvGrd_NArw']\n",
      "\n",
      "evaluating column:  Functional\n",
      "processing column:  Functional\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Functional_NArw', 'Functional_1010_0', 'Functional_1010_1', 'Functional_1010_2']\n",
      "\n",
      "evaluating column:  Fireplaces\n",
      "processing column:  Fireplaces\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['Fireplaces_nmbr', 'Fireplaces_NArw']\n",
      "\n",
      "evaluating column:  FireplaceQu\n",
      "processing column:  FireplaceQu\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['FireplaceQu_NArw', 'FireplaceQu_1010_0', 'FireplaceQu_1010_1', 'FireplaceQu_1010_2']\n",
      "\n",
      "evaluating column:  GarageType\n",
      "processing column:  GarageType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageType_NArw', 'GarageType_1010_0', 'GarageType_1010_1', 'GarageType_1010_2']\n",
      "\n",
      "evaluating column:  GarageYrBlt\n",
      "processing column:  GarageYrBlt\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GarageYrBlt_nmbr', 'GarageYrBlt_NArw']\n",
      "\n",
      "evaluating column:  GarageFinish\n",
      "processing column:  GarageFinish\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageFinish_NArw', 'GarageFinish_1010_0', 'GarageFinish_1010_1']\n",
      "\n",
      "evaluating column:  GarageCars\n",
      "processing column:  GarageCars\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GarageCars_nmbr', 'GarageCars_NArw']\n",
      "\n",
      "evaluating column:  GarageArea\n",
      "processing column:  GarageArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GarageArea_nmbr', 'GarageArea_NArw']\n",
      "\n",
      "evaluating column:  GarageQual\n",
      "processing column:  GarageQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageQual_NArw', 'GarageQual_1010_0', 'GarageQual_1010_1', 'GarageQual_1010_2']\n",
      "\n",
      "evaluating column:  GarageCond\n",
      "processing column:  GarageCond\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageCond_NArw', 'GarageCond_1010_0', 'GarageCond_1010_1', 'GarageCond_1010_2']\n",
      "\n",
      "evaluating column:  PavedDrive\n",
      "processing column:  PavedDrive\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['PavedDrive_NArw', 'PavedDrive_1010_0', 'PavedDrive_1010_1']\n",
      "\n",
      "evaluating column:  WoodDeckSF\n",
      "processing column:  WoodDeckSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['WoodDeckSF_nmbr', 'WoodDeckSF_NArw']\n",
      "\n",
      "evaluating column:  OpenPorchSF\n",
      "processing column:  OpenPorchSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['OpenPorchSF_nmbr', 'OpenPorchSF_NArw']\n",
      "\n",
      "evaluating column:  EnclosedPorch\n",
      "processing column:  EnclosedPorch\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['EnclosedPorch_nmbr', 'EnclosedPorch_NArw']\n",
      "\n",
      "evaluating column:  3SsnPorch\n",
      "processing column:  3SsnPorch\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['3SsnPorch_nmbr', '3SsnPorch_NArw']\n",
      "\n",
      "evaluating column:  ScreenPorch\n",
      "processing column:  ScreenPorch\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['ScreenPorch_nmbr', 'ScreenPorch_NArw']\n",
      "\n",
      "evaluating column:  PoolArea\n",
      "processing column:  PoolArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['PoolArea_nmbr', 'PoolArea_NArw']\n",
      "\n",
      "evaluating column:  PoolQC\n",
      "processing column:  PoolQC\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['PoolQC_NArw', 'PoolQC_1010_0', 'PoolQC_1010_1']\n",
      "\n",
      "evaluating column:  Fence\n",
      "processing column:  Fence\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Fence_NArw', 'Fence_1010_0', 'Fence_1010_1', 'Fence_1010_2']\n",
      "\n",
      "evaluating column:  MiscFeature\n",
      "processing column:  MiscFeature\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['MiscFeature_NArw', 'MiscFeature_1010_0', 'MiscFeature_1010_1', 'MiscFeature_1010_2']\n",
      "\n",
      "evaluating column:  MiscVal\n",
      "processing column:  MiscVal\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MiscVal_nmbr', 'MiscVal_NArw']\n",
      "\n",
      "evaluating column:  MoSold\n",
      "processing column:  MoSold\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MoSold_nmbr', 'MoSold_NArw']\n",
      "\n",
      "evaluating column:  YrSold\n",
      "processing column:  YrSold\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['YrSold_nmbr', 'YrSold_NArw']\n",
      "\n",
      "evaluating column:  SaleType\n",
      "processing column:  SaleType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['SaleType_NArw', 'SaleType_1010_0', 'SaleType_1010_1', 'SaleType_1010_2', 'SaleType_1010_3']\n",
      "\n",
      "evaluating column:  SaleCondition\n",
      "processing column:  SaleCondition\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['SaleCondition_NArw', 'SaleCondition_1010_0', 'SaleCondition_1010_1', 'SaleCondition_1010_2']\n",
      "\n",
      "______\n",
      "\n",
      "evaluating label column:  SalePrice\n",
      "processing label column:  SalePrice\n",
      "    root label category:  lbnm\n",
      "\n",
      " returned columns:\n",
      "['SalePrice_exc2']\n",
      "\n",
      "______\n",
      "\n",
      "infill to column:  PoolQC_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  PoolQC_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MiscFeature_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MiscFeature_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MiscFeature_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Alley_bnry\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Fence_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Fence_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Fence_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  FireplaceQu_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  FireplaceQu_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  FireplaceQu_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotFrontage_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageCond_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageCond_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageCond_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageFinish_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageFinish_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageQual_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageQual_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageQual_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageType_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageType_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageType_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageYrBlt_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtExposure_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtExposure_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtExposure_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinType2_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinType2_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinType2_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtCond_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtCond_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtCond_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinType1_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinType1_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinType1_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtQual_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtQual_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtQual_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MasVnrArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MasVnrType_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MasVnrType_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MasVnrType_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Electrical_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Electrical_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Electrical_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  1stFlrSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  2ndFlrSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  3SsnPorch_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BedroomAbvGr_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BldgType_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BldgType_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BldgType_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinSF1_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinSF2_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFullBath_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtHalfBath_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtHalfBath_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtUnfSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  CentralAir_bnry\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition1_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition1_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition1_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition1_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition2_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition2_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition2_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition2_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  EnclosedPorch_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ExterCond_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ExterCond_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ExterCond_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ExterQual_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ExterQual_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ExterQual_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior1st_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior1st_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior1st_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior1st_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_4\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Fireplaces_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Foundation_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Foundation_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Foundation_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  FullBath_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Functional_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Functional_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Functional_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageCars_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GrLivArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HalfBath_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HalfBath_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HeatingQC_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HeatingQC_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HeatingQC_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Heating_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Heating_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Heating_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HouseStyle_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HouseStyle_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HouseStyle_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HouseStyle_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  KitchenAbvGr_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  KitchenQual_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  KitchenQual_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  KitchenQual_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LandContour_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LandContour_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LandContour_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LandSlope_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LandSlope_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotConfig_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotConfig_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotConfig_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotShape_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotShape_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotShape_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LowQualFinSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MSSubClass_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MSZoning_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MSZoning_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MSZoning_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MiscVal_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MoSold_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_4\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  OpenPorchSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  OverallCond_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  OverallQual_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  PavedDrive_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  PavedDrive_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  PoolArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofMatl_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofMatl_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofMatl_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofMatl_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofStyle_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofStyle_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofStyle_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleCondition_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleCondition_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleCondition_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleType_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleType_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleType_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleType_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ScreenPorch_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Street_bnry\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  TotRmsAbvGrd_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  TotalBsmtSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Utilities_bnry\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  WoodDeckSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  YearBuilt_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  YearRemodAdd_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  YrSold_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "______\n",
      "\n",
      "versioning serial stamp:\n",
      "_6.13_713267332254_2021-06-03T20:32:05.064538\n",
      "\n",
      "Automunge returned ID column set: \n",
      "['Id', 'Automunge_index']\n",
      "\n",
      "Automunge returned train column set: \n",
      "['MSSubClass_nmbr', 'LotFrontage_nmbr', 'LotArea_nmbr', 'Street_bnry', 'Alley_bnry', 'Utilities_bnry', 'OverallQual_nmbr', 'OverallCond_nmbr', 'YearBuilt_nmbr', 'YearRemodAdd_nmbr', 'MasVnrArea_nmbr', 'BsmtFinSF1_nmbr', 'BsmtFinSF2_nmbr', 'BsmtUnfSF_nmbr', 'TotalBsmtSF_nmbr', 'CentralAir_bnry', '1stFlrSF_nmbr', '2ndFlrSF_nmbr', 'LowQualFinSF_nmbr', 'GrLivArea_nmbr', 'BsmtFullBath_nmbr', 'FullBath_nmbr', 'BedroomAbvGr_nmbr', 'KitchenAbvGr_nmbr', 'TotRmsAbvGrd_nmbr', 'Fireplaces_nmbr', 'GarageYrBlt_nmbr', 'GarageCars_nmbr', 'GarageArea_nmbr', 'WoodDeckSF_nmbr', 'OpenPorchSF_nmbr', 'EnclosedPorch_nmbr', '3SsnPorch_nmbr', 'ScreenPorch_nmbr', 'PoolArea_nmbr', 'MiscVal_nmbr', 'MoSold_nmbr', 'YrSold_nmbr', 'MSSubClass_NArw', 'MSZoning_NArw', 'MSZoning_1010_0', 'MSZoning_1010_1', 'MSZoning_1010_2', 'LotFrontage_NArw', 'LotArea_NArw', 'Street_NArw', 'Alley_NArw', 'LotShape_NArw', 'LotShape_1010_0', 'LotShape_1010_1', 'LotShape_1010_2', 'LandContour_NArw', 'LandContour_1010_0', 'LandContour_1010_1', 'LandContour_1010_2', 'Utilities_NArw', 'LotConfig_NArw', 'LotConfig_1010_0', 'LotConfig_1010_1', 'LotConfig_1010_2', 'LandSlope_NArw', 'LandSlope_1010_0', 'LandSlope_1010_1', 'Neighborhood_NArw', 'Neighborhood_1010_0', 'Neighborhood_1010_1', 'Neighborhood_1010_2', 'Neighborhood_1010_3', 'Neighborhood_1010_4', 'Condition1_NArw', 'Condition1_1010_0', 'Condition1_1010_1', 'Condition1_1010_2', 'Condition1_1010_3', 'Condition2_NArw', 'Condition2_1010_0', 'Condition2_1010_1', 'Condition2_1010_2', 'Condition2_1010_3', 'BldgType_NArw', 'BldgType_1010_0', 'BldgType_1010_1', 'BldgType_1010_2', 'HouseStyle_NArw', 'HouseStyle_1010_0', 'HouseStyle_1010_1', 'HouseStyle_1010_2', 'HouseStyle_1010_3', 'OverallQual_NArw', 'OverallCond_NArw', 'YearBuilt_NArw', 'YearRemodAdd_NArw', 'RoofStyle_NArw', 'RoofStyle_1010_0', 'RoofStyle_1010_1', 'RoofStyle_1010_2', 'RoofMatl_NArw', 'RoofMatl_1010_0', 'RoofMatl_1010_1', 'RoofMatl_1010_2', 'RoofMatl_1010_3', 'Exterior1st_NArw', 'Exterior1st_1010_0', 'Exterior1st_1010_1', 'Exterior1st_1010_2', 'Exterior1st_1010_3', 'Exterior2nd_NArw', 'Exterior2nd_1010_0', 'Exterior2nd_1010_1', 'Exterior2nd_1010_2', 'Exterior2nd_1010_3', 'Exterior2nd_1010_4', 'MasVnrType_NArw', 'MasVnrType_1010_0', 'MasVnrType_1010_1', 'MasVnrType_1010_2', 'MasVnrArea_NArw', 'ExterQual_NArw', 'ExterQual_1010_0', 'ExterQual_1010_1', 'ExterQual_1010_2', 'ExterCond_NArw', 'ExterCond_1010_0', 'ExterCond_1010_1', 'ExterCond_1010_2', 'Foundation_NArw', 'Foundation_1010_0', 'Foundation_1010_1', 'Foundation_1010_2', 'BsmtQual_NArw', 'BsmtQual_1010_0', 'BsmtQual_1010_1', 'BsmtQual_1010_2', 'BsmtCond_NArw', 'BsmtCond_1010_0', 'BsmtCond_1010_1', 'BsmtCond_1010_2', 'BsmtExposure_NArw', 'BsmtExposure_1010_0', 'BsmtExposure_1010_1', 'BsmtExposure_1010_2', 'BsmtFinType1_NArw', 'BsmtFinType1_1010_0', 'BsmtFinType1_1010_1', 'BsmtFinType1_1010_2', 'BsmtFinSF1_NArw', 'BsmtFinType2_NArw', 'BsmtFinType2_1010_0', 'BsmtFinType2_1010_1', 'BsmtFinType2_1010_2', 'BsmtFinSF2_NArw', 'BsmtUnfSF_NArw', 'TotalBsmtSF_NArw', 'Heating_NArw', 'Heating_1010_0', 'Heating_1010_1', 'Heating_1010_2', 'HeatingQC_NArw', 'HeatingQC_1010_0', 'HeatingQC_1010_1', 'HeatingQC_1010_2', 'CentralAir_NArw', 'Electrical_NArw', 'Electrical_1010_0', 'Electrical_1010_1', 'Electrical_1010_2', '1stFlrSF_NArw', '2ndFlrSF_NArw', 'LowQualFinSF_NArw', 'GrLivArea_NArw', 'BsmtFullBath_NArw', 'BsmtHalfBath_NArw', 'BsmtHalfBath_1010_0', 'BsmtHalfBath_1010_1', 'FullBath_NArw', 'HalfBath_NArw', 'HalfBath_1010_0', 'HalfBath_1010_1', 'BedroomAbvGr_NArw', 'KitchenAbvGr_NArw', 'KitchenQual_NArw', 'KitchenQual_1010_0', 'KitchenQual_1010_1', 'KitchenQual_1010_2', 'TotRmsAbvGrd_NArw', 'Functional_NArw', 'Functional_1010_0', 'Functional_1010_1', 'Functional_1010_2', 'Fireplaces_NArw', 'FireplaceQu_NArw', 'FireplaceQu_1010_0', 'FireplaceQu_1010_1', 'FireplaceQu_1010_2', 'GarageType_NArw', 'GarageType_1010_0', 'GarageType_1010_1', 'GarageType_1010_2', 'GarageYrBlt_NArw', 'GarageFinish_NArw', 'GarageFinish_1010_0', 'GarageFinish_1010_1', 'GarageCars_NArw', 'GarageArea_NArw', 'GarageQual_NArw', 'GarageQual_1010_0', 'GarageQual_1010_1', 'GarageQual_1010_2', 'GarageCond_NArw', 'GarageCond_1010_0', 'GarageCond_1010_1', 'GarageCond_1010_2', 'PavedDrive_NArw', 'PavedDrive_1010_0', 'PavedDrive_1010_1', 'WoodDeckSF_NArw', 'OpenPorchSF_NArw', 'EnclosedPorch_NArw', '3SsnPorch_NArw', 'ScreenPorch_NArw', 'PoolArea_NArw', 'PoolQC_NArw', 'PoolQC_1010_0', 'PoolQC_1010_1', 'Fence_NArw', 'Fence_1010_0', 'Fence_1010_1', 'Fence_1010_2', 'MiscFeature_NArw', 'MiscFeature_1010_0', 'MiscFeature_1010_1', 'MiscFeature_1010_2', 'MiscVal_NArw', 'MoSold_NArw', 'YrSold_NArw', 'SaleType_NArw', 'SaleType_1010_0', 'SaleType_1010_1', 'SaleType_1010_2', 'SaleType_1010_3', 'SaleCondition_NArw', 'SaleCondition_1010_0', 'SaleCondition_1010_1', 'SaleCondition_1010_2']\n",
      "\n",
      "Automunge returned label column set: \n",
      "['SalePrice_exc2']\n",
      "\n",
      "_______________\n",
      "Automunge Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML_cmnd = {'autoML_type' : 'catboost'}\n",
    "\n",
    "#(currently running this on macbook so commenting out gpu)\n",
    "# #GPU device assignment takes place in model initialization\n",
    "# ML_cmnd.update({'MLinfill_cmnd' : \n",
    "#                  {'catboost_classifier_model'   : \n",
    "#                    {'task_type' : 'GPU', 'devices' : 0 },\n",
    "#                   'catboost_regressor_model'    : \n",
    "#                    {'task_type' : 'GPU', 'devices' : 0 }}})\n",
    "\n",
    "train, train_ID, labels, \\\n",
    "val, val_ID, val_labels, \\\n",
    "test, test_ID, test_labels, \\\n",
    "postprocess_dict = \\\n",
    "am.automunge(df_train,\n",
    "             labels_column = 'SalePrice',\n",
    "             trainID_column = 'Id',\n",
    "             MLinfill = True,\n",
    "             ML_cmnd = ML_cmnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FLAML library is also available. Here we demonstrate setting a training time budget (in seconds) for each imputation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________\n",
      "Begin Automunge processing\n",
      "\n",
      "evaluating column:  MSSubClass\n",
      "processing column:  MSSubClass\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MSSubClass_nmbr', 'MSSubClass_NArw']\n",
      "\n",
      "evaluating column:  MSZoning\n",
      "processing column:  MSZoning\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['MSZoning_NArw', 'MSZoning_1010_0', 'MSZoning_1010_1', 'MSZoning_1010_2']\n",
      "\n",
      "evaluating column:  LotFrontage\n",
      "processing column:  LotFrontage\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['LotFrontage_nmbr', 'LotFrontage_NArw']\n",
      "\n",
      "evaluating column:  LotArea\n",
      "processing column:  LotArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['LotArea_nmbr', 'LotArea_NArw']\n",
      "\n",
      "evaluating column:  Street\n",
      "processing column:  Street\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['Street_bnry', 'Street_NArw']\n",
      "\n",
      "evaluating column:  Alley\n",
      "processing column:  Alley\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['Alley_bnry', 'Alley_NArw']\n",
      "\n",
      "evaluating column:  LotShape\n",
      "processing column:  LotShape\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LotShape_NArw', 'LotShape_1010_0', 'LotShape_1010_1', 'LotShape_1010_2']\n",
      "\n",
      "evaluating column:  LandContour\n",
      "processing column:  LandContour\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LandContour_NArw', 'LandContour_1010_0', 'LandContour_1010_1', 'LandContour_1010_2']\n",
      "\n",
      "evaluating column:  Utilities\n",
      "processing column:  Utilities\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['Utilities_bnry', 'Utilities_NArw']\n",
      "\n",
      "evaluating column:  LotConfig\n",
      "processing column:  LotConfig\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LotConfig_NArw', 'LotConfig_1010_0', 'LotConfig_1010_1', 'LotConfig_1010_2']\n",
      "\n",
      "evaluating column:  LandSlope\n",
      "processing column:  LandSlope\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LandSlope_NArw', 'LandSlope_1010_0', 'LandSlope_1010_1']\n",
      "\n",
      "evaluating column:  Neighborhood\n",
      "processing column:  Neighborhood\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Neighborhood_NArw', 'Neighborhood_1010_0', 'Neighborhood_1010_1', 'Neighborhood_1010_2', 'Neighborhood_1010_3', 'Neighborhood_1010_4']\n",
      "\n",
      "evaluating column:  Condition1\n",
      "processing column:  Condition1\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Condition1_NArw', 'Condition1_1010_0', 'Condition1_1010_1', 'Condition1_1010_2', 'Condition1_1010_3']\n",
      "\n",
      "evaluating column:  Condition2\n",
      "processing column:  Condition2\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Condition2_NArw', 'Condition2_1010_0', 'Condition2_1010_1', 'Condition2_1010_2', 'Condition2_1010_3']\n",
      "\n",
      "evaluating column:  BldgType\n",
      "processing column:  BldgType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BldgType_NArw', 'BldgType_1010_0', 'BldgType_1010_1', 'BldgType_1010_2']\n",
      "\n",
      "evaluating column:  HouseStyle\n",
      "processing column:  HouseStyle\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['HouseStyle_NArw', 'HouseStyle_1010_0', 'HouseStyle_1010_1', 'HouseStyle_1010_2', 'HouseStyle_1010_3']\n",
      "\n",
      "evaluating column:  OverallQual\n",
      "processing column:  OverallQual\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['OverallQual_nmbr', 'OverallQual_NArw']\n",
      "\n",
      "evaluating column:  OverallCond\n",
      "processing column:  OverallCond\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['OverallCond_nmbr', 'OverallCond_NArw']\n",
      "\n",
      "evaluating column:  YearBuilt\n",
      "processing column:  YearBuilt\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['YearBuilt_nmbr', 'YearBuilt_NArw']\n",
      "\n",
      "evaluating column:  YearRemodAdd\n",
      "processing column:  YearRemodAdd\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['YearRemodAdd_nmbr', 'YearRemodAdd_NArw']\n",
      "\n",
      "evaluating column:  RoofStyle\n",
      "processing column:  RoofStyle\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['RoofStyle_NArw', 'RoofStyle_1010_0', 'RoofStyle_1010_1', 'RoofStyle_1010_2']\n",
      "\n",
      "evaluating column:  RoofMatl\n",
      "processing column:  RoofMatl\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['RoofMatl_NArw', 'RoofMatl_1010_0', 'RoofMatl_1010_1', 'RoofMatl_1010_2', 'RoofMatl_1010_3']\n",
      "\n",
      "evaluating column:  Exterior1st\n",
      "processing column:  Exterior1st\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Exterior1st_NArw', 'Exterior1st_1010_0', 'Exterior1st_1010_1', 'Exterior1st_1010_2', 'Exterior1st_1010_3']\n",
      "\n",
      "evaluating column:  Exterior2nd\n",
      "processing column:  Exterior2nd\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Exterior2nd_NArw', 'Exterior2nd_1010_0', 'Exterior2nd_1010_1', 'Exterior2nd_1010_2', 'Exterior2nd_1010_3', 'Exterior2nd_1010_4']\n",
      "\n",
      "evaluating column:  MasVnrType\n",
      "processing column:  MasVnrType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['MasVnrType_NArw', 'MasVnrType_1010_0', 'MasVnrType_1010_1', 'MasVnrType_1010_2']\n",
      "\n",
      "evaluating column:  MasVnrArea\n",
      "processing column:  MasVnrArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MasVnrArea_nmbr', 'MasVnrArea_NArw']\n",
      "\n",
      "evaluating column:  ExterQual\n",
      "processing column:  ExterQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['ExterQual_NArw', 'ExterQual_1010_0', 'ExterQual_1010_1', 'ExterQual_1010_2']\n",
      "\n",
      "evaluating column:  ExterCond\n",
      "processing column:  ExterCond\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['ExterCond_NArw', 'ExterCond_1010_0', 'ExterCond_1010_1', 'ExterCond_1010_2']\n",
      "\n",
      "evaluating column:  Foundation\n",
      "processing column:  Foundation\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Foundation_NArw', 'Foundation_1010_0', 'Foundation_1010_1', 'Foundation_1010_2']\n",
      "\n",
      "evaluating column:  BsmtQual\n",
      "processing column:  BsmtQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtQual_NArw', 'BsmtQual_1010_0', 'BsmtQual_1010_1', 'BsmtQual_1010_2']\n",
      "\n",
      "evaluating column:  BsmtCond\n",
      "processing column:  BsmtCond\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtCond_NArw', 'BsmtCond_1010_0', 'BsmtCond_1010_1', 'BsmtCond_1010_2']\n",
      "\n",
      "evaluating column:  BsmtExposure\n",
      "processing column:  BsmtExposure\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtExposure_NArw', 'BsmtExposure_1010_0', 'BsmtExposure_1010_1', 'BsmtExposure_1010_2']\n",
      "\n",
      "evaluating column:  BsmtFinType1\n",
      "processing column:  BsmtFinType1\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtFinType1_NArw', 'BsmtFinType1_1010_0', 'BsmtFinType1_1010_1', 'BsmtFinType1_1010_2']\n",
      "\n",
      "evaluating column:  BsmtFinSF1\n",
      "processing column:  BsmtFinSF1\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtFinSF1_nmbr', 'BsmtFinSF1_NArw']\n",
      "\n",
      "evaluating column:  BsmtFinType2\n",
      "processing column:  BsmtFinType2\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtFinType2_NArw', 'BsmtFinType2_1010_0', 'BsmtFinType2_1010_1', 'BsmtFinType2_1010_2']\n",
      "\n",
      "evaluating column:  BsmtFinSF2\n",
      "processing column:  BsmtFinSF2\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtFinSF2_nmbr', 'BsmtFinSF2_NArw']\n",
      "\n",
      "evaluating column:  BsmtUnfSF\n",
      "processing column:  BsmtUnfSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtUnfSF_nmbr', 'BsmtUnfSF_NArw']\n",
      "\n",
      "evaluating column:  TotalBsmtSF\n",
      "processing column:  TotalBsmtSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['TotalBsmtSF_nmbr', 'TotalBsmtSF_NArw']\n",
      "\n",
      "evaluating column:  Heating\n",
      "processing column:  Heating\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Heating_NArw', 'Heating_1010_0', 'Heating_1010_1', 'Heating_1010_2']\n",
      "\n",
      "evaluating column:  HeatingQC\n",
      "processing column:  HeatingQC\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['HeatingQC_NArw', 'HeatingQC_1010_0', 'HeatingQC_1010_1', 'HeatingQC_1010_2']\n",
      "\n",
      "evaluating column:  CentralAir\n",
      "processing column:  CentralAir\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['CentralAir_bnry', 'CentralAir_NArw']\n",
      "\n",
      "evaluating column:  Electrical\n",
      "processing column:  Electrical\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Electrical_NArw', 'Electrical_1010_0', 'Electrical_1010_1', 'Electrical_1010_2']\n",
      "\n",
      "evaluating column:  1stFlrSF\n",
      "processing column:  1stFlrSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['1stFlrSF_nmbr', '1stFlrSF_NArw']\n",
      "\n",
      "evaluating column:  2ndFlrSF\n",
      "processing column:  2ndFlrSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['2ndFlrSF_nmbr', '2ndFlrSF_NArw']\n",
      "\n",
      "evaluating column:  LowQualFinSF\n",
      "processing column:  LowQualFinSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['LowQualFinSF_nmbr', 'LowQualFinSF_NArw']\n",
      "\n",
      "evaluating column:  GrLivArea\n",
      "processing column:  GrLivArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GrLivArea_nmbr', 'GrLivArea_NArw']\n",
      "\n",
      "evaluating column:  BsmtFullBath\n",
      "processing column:  BsmtFullBath\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtFullBath_nmbr', 'BsmtFullBath_NArw']\n",
      "\n",
      "evaluating column:  BsmtHalfBath\n",
      "processing column:  BsmtHalfBath\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtHalfBath_NArw', 'BsmtHalfBath_1010_0', 'BsmtHalfBath_1010_1']\n",
      "\n",
      "evaluating column:  FullBath\n",
      "processing column:  FullBath\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['FullBath_nmbr', 'FullBath_NArw']\n",
      "\n",
      "evaluating column:  HalfBath\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing column:  HalfBath\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['HalfBath_NArw', 'HalfBath_1010_0', 'HalfBath_1010_1']\n",
      "\n",
      "evaluating column:  BedroomAbvGr\n",
      "processing column:  BedroomAbvGr\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BedroomAbvGr_nmbr', 'BedroomAbvGr_NArw']\n",
      "\n",
      "evaluating column:  KitchenAbvGr\n",
      "processing column:  KitchenAbvGr\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['KitchenAbvGr_nmbr', 'KitchenAbvGr_NArw']\n",
      "\n",
      "evaluating column:  KitchenQual\n",
      "processing column:  KitchenQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['KitchenQual_NArw', 'KitchenQual_1010_0', 'KitchenQual_1010_1', 'KitchenQual_1010_2']\n",
      "\n",
      "evaluating column:  TotRmsAbvGrd\n",
      "processing column:  TotRmsAbvGrd\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['TotRmsAbvGrd_nmbr', 'TotRmsAbvGrd_NArw']\n",
      "\n",
      "evaluating column:  Functional\n",
      "processing column:  Functional\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Functional_NArw', 'Functional_1010_0', 'Functional_1010_1', 'Functional_1010_2']\n",
      "\n",
      "evaluating column:  Fireplaces\n",
      "processing column:  Fireplaces\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['Fireplaces_nmbr', 'Fireplaces_NArw']\n",
      "\n",
      "evaluating column:  FireplaceQu\n",
      "processing column:  FireplaceQu\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['FireplaceQu_NArw', 'FireplaceQu_1010_0', 'FireplaceQu_1010_1', 'FireplaceQu_1010_2']\n",
      "\n",
      "evaluating column:  GarageType\n",
      "processing column:  GarageType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageType_NArw', 'GarageType_1010_0', 'GarageType_1010_1', 'GarageType_1010_2']\n",
      "\n",
      "evaluating column:  GarageYrBlt\n",
      "processing column:  GarageYrBlt\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GarageYrBlt_nmbr', 'GarageYrBlt_NArw']\n",
      "\n",
      "evaluating column:  GarageFinish\n",
      "processing column:  GarageFinish\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageFinish_NArw', 'GarageFinish_1010_0', 'GarageFinish_1010_1']\n",
      "\n",
      "evaluating column:  GarageCars\n",
      "processing column:  GarageCars\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GarageCars_nmbr', 'GarageCars_NArw']\n",
      "\n",
      "evaluating column:  GarageArea\n",
      "processing column:  GarageArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GarageArea_nmbr', 'GarageArea_NArw']\n",
      "\n",
      "evaluating column:  GarageQual\n",
      "processing column:  GarageQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageQual_NArw', 'GarageQual_1010_0', 'GarageQual_1010_1', 'GarageQual_1010_2']\n",
      "\n",
      "evaluating column:  GarageCond\n",
      "processing column:  GarageCond\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageCond_NArw', 'GarageCond_1010_0', 'GarageCond_1010_1', 'GarageCond_1010_2']\n",
      "\n",
      "evaluating column:  PavedDrive\n",
      "processing column:  PavedDrive\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['PavedDrive_NArw', 'PavedDrive_1010_0', 'PavedDrive_1010_1']\n",
      "\n",
      "evaluating column:  WoodDeckSF\n",
      "processing column:  WoodDeckSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['WoodDeckSF_nmbr', 'WoodDeckSF_NArw']\n",
      "\n",
      "evaluating column:  OpenPorchSF\n",
      "processing column:  OpenPorchSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['OpenPorchSF_nmbr', 'OpenPorchSF_NArw']\n",
      "\n",
      "evaluating column:  EnclosedPorch\n",
      "processing column:  EnclosedPorch\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['EnclosedPorch_nmbr', 'EnclosedPorch_NArw']\n",
      "\n",
      "evaluating column:  3SsnPorch\n",
      "processing column:  3SsnPorch\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['3SsnPorch_nmbr', '3SsnPorch_NArw']\n",
      "\n",
      "evaluating column:  ScreenPorch\n",
      "processing column:  ScreenPorch\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['ScreenPorch_nmbr', 'ScreenPorch_NArw']\n",
      "\n",
      "evaluating column:  PoolArea\n",
      "processing column:  PoolArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['PoolArea_nmbr', 'PoolArea_NArw']\n",
      "\n",
      "evaluating column:  PoolQC\n",
      "processing column:  PoolQC\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['PoolQC_NArw', 'PoolQC_1010_0', 'PoolQC_1010_1']\n",
      "\n",
      "evaluating column:  Fence\n",
      "processing column:  Fence\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Fence_NArw', 'Fence_1010_0', 'Fence_1010_1', 'Fence_1010_2']\n",
      "\n",
      "evaluating column:  MiscFeature\n",
      "processing column:  MiscFeature\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['MiscFeature_NArw', 'MiscFeature_1010_0', 'MiscFeature_1010_1', 'MiscFeature_1010_2']\n",
      "\n",
      "evaluating column:  MiscVal\n",
      "processing column:  MiscVal\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MiscVal_nmbr', 'MiscVal_NArw']\n",
      "\n",
      "evaluating column:  MoSold\n",
      "processing column:  MoSold\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MoSold_nmbr', 'MoSold_NArw']\n",
      "\n",
      "evaluating column:  YrSold\n",
      "processing column:  YrSold\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['YrSold_nmbr', 'YrSold_NArw']\n",
      "\n",
      "evaluating column:  SaleType\n",
      "processing column:  SaleType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['SaleType_NArw', 'SaleType_1010_0', 'SaleType_1010_1', 'SaleType_1010_2', 'SaleType_1010_3']\n",
      "\n",
      "evaluating column:  SaleCondition\n",
      "processing column:  SaleCondition\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['SaleCondition_NArw', 'SaleCondition_1010_0', 'SaleCondition_1010_1', 'SaleCondition_1010_2']\n",
      "\n",
      "______\n",
      "\n",
      "evaluating label column:  SalePrice\n",
      "processing label column:  SalePrice\n",
      "    root label category:  lbnm\n",
      "\n",
      " returned columns:\n",
      "['SalePrice_exc2']\n",
      "\n",
      "______\n",
      "\n",
      "infill to column:  PoolQC_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  PoolQC_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MiscFeature_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  MiscFeature_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MiscFeature_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Alley_bnry\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Fence_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Fence_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Fence_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  FireplaceQu_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  FireplaceQu_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  FireplaceQu_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotFrontage_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageCond_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  GarageCond_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageCond_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageFinish_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  GarageFinish_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageQual_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  GarageQual_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageQual_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageType_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  GarageType_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageType_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageYrBlt_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtExposure_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BsmtExposure_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtExposure_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinType2_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BsmtFinType2_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinType2_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtCond_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BsmtCond_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtCond_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinType1_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BsmtFinType1_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinType1_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtQual_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BsmtQual_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtQual_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MasVnrArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MasVnrType_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  MasVnrType_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MasVnrType_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Electrical_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Electrical_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Electrical_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  1stFlrSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  2ndFlrSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  3SsnPorch_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BedroomAbvGr_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BldgType_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BldgType_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BldgType_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinSF1_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinSF2_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFullBath_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtHalfBath_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BsmtHalfBath_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtUnfSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  CentralAir_bnry\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Condition1_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Condition1_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition1_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition1_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition2_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Condition2_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition2_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition2_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  EnclosedPorch_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ExterCond_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  ExterCond_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ExterCond_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ExterQual_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  ExterQual_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ExterQual_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior1st_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Exterior1st_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior1st_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior1st_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Exterior2nd_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_4\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Fireplaces_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Foundation_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Foundation_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Foundation_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  FullBath_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Functional_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Functional_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Functional_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageCars_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GrLivArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HalfBath_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  HalfBath_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HeatingQC_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  HeatingQC_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HeatingQC_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Heating_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Heating_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Heating_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HouseStyle_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  HouseStyle_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HouseStyle_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HouseStyle_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  KitchenAbvGr_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  KitchenQual_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  KitchenQual_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  KitchenQual_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LandContour_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  LandContour_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LandContour_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LandSlope_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  LandSlope_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotConfig_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  LotConfig_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotConfig_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotShape_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  LotShape_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotShape_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LowQualFinSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MSSubClass_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MSZoning_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  MSZoning_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MSZoning_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MiscVal_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MoSold_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Neighborhood_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_4\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  OpenPorchSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  OverallCond_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  OverallQual_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  PavedDrive_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  PavedDrive_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  PoolArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofMatl_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  RoofMatl_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofMatl_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofMatl_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofStyle_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  RoofStyle_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofStyle_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleCondition_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  SaleCondition_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleCondition_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleType_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  SaleType_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleType_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleType_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ScreenPorch_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Street_bnry\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  TotRmsAbvGrd_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  TotalBsmtSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Utilities_bnry\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  WoodDeckSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  YearBuilt_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  YearRemodAdd_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  YrSold_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "______\n",
      "\n",
      "versioning serial stamp:\n",
      "_6.13_606391621018_2021-06-03T20:44:02.192758\n",
      "\n",
      "Automunge returned ID column set: \n",
      "['Id', 'Automunge_index']\n",
      "\n",
      "Automunge returned train column set: \n",
      "['MSSubClass_nmbr', 'LotFrontage_nmbr', 'LotArea_nmbr', 'Street_bnry', 'Alley_bnry', 'Utilities_bnry', 'OverallQual_nmbr', 'OverallCond_nmbr', 'YearBuilt_nmbr', 'YearRemodAdd_nmbr', 'MasVnrArea_nmbr', 'BsmtFinSF1_nmbr', 'BsmtFinSF2_nmbr', 'BsmtUnfSF_nmbr', 'TotalBsmtSF_nmbr', 'CentralAir_bnry', '1stFlrSF_nmbr', '2ndFlrSF_nmbr', 'LowQualFinSF_nmbr', 'GrLivArea_nmbr', 'BsmtFullBath_nmbr', 'FullBath_nmbr', 'BedroomAbvGr_nmbr', 'KitchenAbvGr_nmbr', 'TotRmsAbvGrd_nmbr', 'Fireplaces_nmbr', 'GarageYrBlt_nmbr', 'GarageCars_nmbr', 'GarageArea_nmbr', 'WoodDeckSF_nmbr', 'OpenPorchSF_nmbr', 'EnclosedPorch_nmbr', '3SsnPorch_nmbr', 'ScreenPorch_nmbr', 'PoolArea_nmbr', 'MiscVal_nmbr', 'MoSold_nmbr', 'YrSold_nmbr', 'MSSubClass_NArw', 'MSZoning_NArw', 'MSZoning_1010_0', 'MSZoning_1010_1', 'MSZoning_1010_2', 'LotFrontage_NArw', 'LotArea_NArw', 'Street_NArw', 'Alley_NArw', 'LotShape_NArw', 'LotShape_1010_0', 'LotShape_1010_1', 'LotShape_1010_2', 'LandContour_NArw', 'LandContour_1010_0', 'LandContour_1010_1', 'LandContour_1010_2', 'Utilities_NArw', 'LotConfig_NArw', 'LotConfig_1010_0', 'LotConfig_1010_1', 'LotConfig_1010_2', 'LandSlope_NArw', 'LandSlope_1010_0', 'LandSlope_1010_1', 'Neighborhood_NArw', 'Neighborhood_1010_0', 'Neighborhood_1010_1', 'Neighborhood_1010_2', 'Neighborhood_1010_3', 'Neighborhood_1010_4', 'Condition1_NArw', 'Condition1_1010_0', 'Condition1_1010_1', 'Condition1_1010_2', 'Condition1_1010_3', 'Condition2_NArw', 'Condition2_1010_0', 'Condition2_1010_1', 'Condition2_1010_2', 'Condition2_1010_3', 'BldgType_NArw', 'BldgType_1010_0', 'BldgType_1010_1', 'BldgType_1010_2', 'HouseStyle_NArw', 'HouseStyle_1010_0', 'HouseStyle_1010_1', 'HouseStyle_1010_2', 'HouseStyle_1010_3', 'OverallQual_NArw', 'OverallCond_NArw', 'YearBuilt_NArw', 'YearRemodAdd_NArw', 'RoofStyle_NArw', 'RoofStyle_1010_0', 'RoofStyle_1010_1', 'RoofStyle_1010_2', 'RoofMatl_NArw', 'RoofMatl_1010_0', 'RoofMatl_1010_1', 'RoofMatl_1010_2', 'RoofMatl_1010_3', 'Exterior1st_NArw', 'Exterior1st_1010_0', 'Exterior1st_1010_1', 'Exterior1st_1010_2', 'Exterior1st_1010_3', 'Exterior2nd_NArw', 'Exterior2nd_1010_0', 'Exterior2nd_1010_1', 'Exterior2nd_1010_2', 'Exterior2nd_1010_3', 'Exterior2nd_1010_4', 'MasVnrType_NArw', 'MasVnrType_1010_0', 'MasVnrType_1010_1', 'MasVnrType_1010_2', 'MasVnrArea_NArw', 'ExterQual_NArw', 'ExterQual_1010_0', 'ExterQual_1010_1', 'ExterQual_1010_2', 'ExterCond_NArw', 'ExterCond_1010_0', 'ExterCond_1010_1', 'ExterCond_1010_2', 'Foundation_NArw', 'Foundation_1010_0', 'Foundation_1010_1', 'Foundation_1010_2', 'BsmtQual_NArw', 'BsmtQual_1010_0', 'BsmtQual_1010_1', 'BsmtQual_1010_2', 'BsmtCond_NArw', 'BsmtCond_1010_0', 'BsmtCond_1010_1', 'BsmtCond_1010_2', 'BsmtExposure_NArw', 'BsmtExposure_1010_0', 'BsmtExposure_1010_1', 'BsmtExposure_1010_2', 'BsmtFinType1_NArw', 'BsmtFinType1_1010_0', 'BsmtFinType1_1010_1', 'BsmtFinType1_1010_2', 'BsmtFinSF1_NArw', 'BsmtFinType2_NArw', 'BsmtFinType2_1010_0', 'BsmtFinType2_1010_1', 'BsmtFinType2_1010_2', 'BsmtFinSF2_NArw', 'BsmtUnfSF_NArw', 'TotalBsmtSF_NArw', 'Heating_NArw', 'Heating_1010_0', 'Heating_1010_1', 'Heating_1010_2', 'HeatingQC_NArw', 'HeatingQC_1010_0', 'HeatingQC_1010_1', 'HeatingQC_1010_2', 'CentralAir_NArw', 'Electrical_NArw', 'Electrical_1010_0', 'Electrical_1010_1', 'Electrical_1010_2', '1stFlrSF_NArw', '2ndFlrSF_NArw', 'LowQualFinSF_NArw', 'GrLivArea_NArw', 'BsmtFullBath_NArw', 'BsmtHalfBath_NArw', 'BsmtHalfBath_1010_0', 'BsmtHalfBath_1010_1', 'FullBath_NArw', 'HalfBath_NArw', 'HalfBath_1010_0', 'HalfBath_1010_1', 'BedroomAbvGr_NArw', 'KitchenAbvGr_NArw', 'KitchenQual_NArw', 'KitchenQual_1010_0', 'KitchenQual_1010_1', 'KitchenQual_1010_2', 'TotRmsAbvGrd_NArw', 'Functional_NArw', 'Functional_1010_0', 'Functional_1010_1', 'Functional_1010_2', 'Fireplaces_NArw', 'FireplaceQu_NArw', 'FireplaceQu_1010_0', 'FireplaceQu_1010_1', 'FireplaceQu_1010_2', 'GarageType_NArw', 'GarageType_1010_0', 'GarageType_1010_1', 'GarageType_1010_2', 'GarageYrBlt_NArw', 'GarageFinish_NArw', 'GarageFinish_1010_0', 'GarageFinish_1010_1', 'GarageCars_NArw', 'GarageArea_NArw', 'GarageQual_NArw', 'GarageQual_1010_0', 'GarageQual_1010_1', 'GarageQual_1010_2', 'GarageCond_NArw', 'GarageCond_1010_0', 'GarageCond_1010_1', 'GarageCond_1010_2', 'PavedDrive_NArw', 'PavedDrive_1010_0', 'PavedDrive_1010_1', 'WoodDeckSF_NArw', 'OpenPorchSF_NArw', 'EnclosedPorch_NArw', '3SsnPorch_NArw', 'ScreenPorch_NArw', 'PoolArea_NArw', 'PoolQC_NArw', 'PoolQC_1010_0', 'PoolQC_1010_1', 'Fence_NArw', 'Fence_1010_0', 'Fence_1010_1', 'Fence_1010_2', 'MiscFeature_NArw', 'MiscFeature_1010_0', 'MiscFeature_1010_1', 'MiscFeature_1010_2', 'MiscVal_NArw', 'MoSold_NArw', 'YrSold_NArw', 'SaleType_NArw', 'SaleType_1010_0', 'SaleType_1010_1', 'SaleType_1010_2', 'SaleType_1010_3', 'SaleCondition_NArw', 'SaleCondition_1010_0', 'SaleCondition_1010_1', 'SaleCondition_1010_2']\n",
      "\n",
      "Automunge returned label column set: \n",
      "['SalePrice_exc2']\n",
      "\n",
      "_______________\n",
      "Automunge Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML_cmnd = {'autoML_type' : 'flaml'}\n",
    "\n",
    "# ML_cmnd.update({'MLinfill_cmnd' : \n",
    "#                  {'flaml_classifier_fit' :  {'time_budget' : 60 },\n",
    "#                   'flaml_regressor_fit' : {'time_budget' : 60 }}})\n",
    "\n",
    "#just to make things run a little quicker setting a lower threshold\n",
    "ML_cmnd.update({'MLinfill_cmnd' : \n",
    "                 {'flaml_classifier_fit' :  {'time_budget' : 5 },\n",
    "                  'flaml_regressor_fit' : {'time_budget' : 5 }}})\n",
    "\n",
    "train, train_ID, labels, \\\n",
    "val, val_ID, val_labels, \\\n",
    "test, test_ID, test_labels, \\\n",
    "postprocess_dict = \\\n",
    "am.automunge(df_train,\n",
    "             labels_column = 'SalePrice',\n",
    "             trainID_column = 'Id',\n",
    "             MLinfill = True,\n",
    "             ML_cmnd = ML_cmnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another demonstration, here is an example of applying the AutoGluon library for ML infill and also applying the best_quality option which causes AutoGluon to train extra models for the aggregated ensembles. (Note this will likely result in large disk space usage, especially when applying to every column, so recommend saving this for final production if at all.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'best_quality' not activated in this demonstration for speed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________\n",
      "Begin Automunge processing\n",
      "\n",
      "evaluating column:  MSSubClass\n",
      "processing column:  MSSubClass\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MSSubClass_nmbr', 'MSSubClass_NArw']\n",
      "\n",
      "evaluating column:  MSZoning\n",
      "processing column:  MSZoning\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['MSZoning_NArw', 'MSZoning_1010_0', 'MSZoning_1010_1', 'MSZoning_1010_2']\n",
      "\n",
      "evaluating column:  LotFrontage\n",
      "processing column:  LotFrontage\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['LotFrontage_nmbr', 'LotFrontage_NArw']\n",
      "\n",
      "evaluating column:  LotArea\n",
      "processing column:  LotArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['LotArea_nmbr', 'LotArea_NArw']\n",
      "\n",
      "evaluating column:  Street\n",
      "processing column:  Street\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['Street_bnry', 'Street_NArw']\n",
      "\n",
      "evaluating column:  Alley\n",
      "processing column:  Alley\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['Alley_bnry', 'Alley_NArw']\n",
      "\n",
      "evaluating column:  LotShape\n",
      "processing column:  LotShape\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LotShape_NArw', 'LotShape_1010_0', 'LotShape_1010_1', 'LotShape_1010_2']\n",
      "\n",
      "evaluating column:  LandContour\n",
      "processing column:  LandContour\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LandContour_NArw', 'LandContour_1010_0', 'LandContour_1010_1', 'LandContour_1010_2']\n",
      "\n",
      "evaluating column:  Utilities\n",
      "processing column:  Utilities\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['Utilities_bnry', 'Utilities_NArw']\n",
      "\n",
      "evaluating column:  LotConfig\n",
      "processing column:  LotConfig\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LotConfig_NArw', 'LotConfig_1010_0', 'LotConfig_1010_1', 'LotConfig_1010_2']\n",
      "\n",
      "evaluating column:  LandSlope\n",
      "processing column:  LandSlope\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LandSlope_NArw', 'LandSlope_1010_0', 'LandSlope_1010_1']\n",
      "\n",
      "evaluating column:  Neighborhood\n",
      "processing column:  Neighborhood\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Neighborhood_NArw', 'Neighborhood_1010_0', 'Neighborhood_1010_1', 'Neighborhood_1010_2', 'Neighborhood_1010_3', 'Neighborhood_1010_4']\n",
      "\n",
      "evaluating column:  Condition1\n",
      "processing column:  Condition1\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Condition1_NArw', 'Condition1_1010_0', 'Condition1_1010_1', 'Condition1_1010_2', 'Condition1_1010_3']\n",
      "\n",
      "evaluating column:  Condition2\n",
      "processing column:  Condition2\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Condition2_NArw', 'Condition2_1010_0', 'Condition2_1010_1', 'Condition2_1010_2', 'Condition2_1010_3']\n",
      "\n",
      "evaluating column:  BldgType\n",
      "processing column:  BldgType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BldgType_NArw', 'BldgType_1010_0', 'BldgType_1010_1', 'BldgType_1010_2']\n",
      "\n",
      "evaluating column:  HouseStyle\n",
      "processing column:  HouseStyle\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['HouseStyle_NArw', 'HouseStyle_1010_0', 'HouseStyle_1010_1', 'HouseStyle_1010_2', 'HouseStyle_1010_3']\n",
      "\n",
      "evaluating column:  OverallQual\n",
      "processing column:  OverallQual\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['OverallQual_nmbr', 'OverallQual_NArw']\n",
      "\n",
      "evaluating column:  OverallCond\n",
      "processing column:  OverallCond\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['OverallCond_nmbr', 'OverallCond_NArw']\n",
      "\n",
      "evaluating column:  YearBuilt\n",
      "processing column:  YearBuilt\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['YearBuilt_nmbr', 'YearBuilt_NArw']\n",
      "\n",
      "evaluating column:  YearRemodAdd\n",
      "processing column:  YearRemodAdd\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['YearRemodAdd_nmbr', 'YearRemodAdd_NArw']\n",
      "\n",
      "evaluating column:  RoofStyle\n",
      "processing column:  RoofStyle\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['RoofStyle_NArw', 'RoofStyle_1010_0', 'RoofStyle_1010_1', 'RoofStyle_1010_2']\n",
      "\n",
      "evaluating column:  RoofMatl\n",
      "processing column:  RoofMatl\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['RoofMatl_NArw', 'RoofMatl_1010_0', 'RoofMatl_1010_1', 'RoofMatl_1010_2', 'RoofMatl_1010_3']\n",
      "\n",
      "evaluating column:  Exterior1st\n",
      "processing column:  Exterior1st\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Exterior1st_NArw', 'Exterior1st_1010_0', 'Exterior1st_1010_1', 'Exterior1st_1010_2', 'Exterior1st_1010_3']\n",
      "\n",
      "evaluating column:  Exterior2nd\n",
      "processing column:  Exterior2nd\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Exterior2nd_NArw', 'Exterior2nd_1010_0', 'Exterior2nd_1010_1', 'Exterior2nd_1010_2', 'Exterior2nd_1010_3', 'Exterior2nd_1010_4']\n",
      "\n",
      "evaluating column:  MasVnrType\n",
      "processing column:  MasVnrType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['MasVnrType_NArw', 'MasVnrType_1010_0', 'MasVnrType_1010_1', 'MasVnrType_1010_2']\n",
      "\n",
      "evaluating column:  MasVnrArea\n",
      "processing column:  MasVnrArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MasVnrArea_nmbr', 'MasVnrArea_NArw']\n",
      "\n",
      "evaluating column:  ExterQual\n",
      "processing column:  ExterQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['ExterQual_NArw', 'ExterQual_1010_0', 'ExterQual_1010_1', 'ExterQual_1010_2']\n",
      "\n",
      "evaluating column:  ExterCond\n",
      "processing column:  ExterCond\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['ExterCond_NArw', 'ExterCond_1010_0', 'ExterCond_1010_1', 'ExterCond_1010_2']\n",
      "\n",
      "evaluating column:  Foundation\n",
      "processing column:  Foundation\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Foundation_NArw', 'Foundation_1010_0', 'Foundation_1010_1', 'Foundation_1010_2']\n",
      "\n",
      "evaluating column:  BsmtQual\n",
      "processing column:  BsmtQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtQual_NArw', 'BsmtQual_1010_0', 'BsmtQual_1010_1', 'BsmtQual_1010_2']\n",
      "\n",
      "evaluating column:  BsmtCond\n",
      "processing column:  BsmtCond\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtCond_NArw', 'BsmtCond_1010_0', 'BsmtCond_1010_1', 'BsmtCond_1010_2']\n",
      "\n",
      "evaluating column:  BsmtExposure\n",
      "processing column:  BsmtExposure\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtExposure_NArw', 'BsmtExposure_1010_0', 'BsmtExposure_1010_1', 'BsmtExposure_1010_2']\n",
      "\n",
      "evaluating column:  BsmtFinType1\n",
      "processing column:  BsmtFinType1\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtFinType1_NArw', 'BsmtFinType1_1010_0', 'BsmtFinType1_1010_1', 'BsmtFinType1_1010_2']\n",
      "\n",
      "evaluating column:  BsmtFinSF1\n",
      "processing column:  BsmtFinSF1\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtFinSF1_nmbr', 'BsmtFinSF1_NArw']\n",
      "\n",
      "evaluating column:  BsmtFinType2\n",
      "processing column:  BsmtFinType2\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtFinType2_NArw', 'BsmtFinType2_1010_0', 'BsmtFinType2_1010_1', 'BsmtFinType2_1010_2']\n",
      "\n",
      "evaluating column:  BsmtFinSF2\n",
      "processing column:  BsmtFinSF2\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtFinSF2_nmbr', 'BsmtFinSF2_NArw']\n",
      "\n",
      "evaluating column:  BsmtUnfSF\n",
      "processing column:  BsmtUnfSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtUnfSF_nmbr', 'BsmtUnfSF_NArw']\n",
      "\n",
      "evaluating column:  TotalBsmtSF\n",
      "processing column:  TotalBsmtSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['TotalBsmtSF_nmbr', 'TotalBsmtSF_NArw']\n",
      "\n",
      "evaluating column:  Heating\n",
      "processing column:  Heating\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Heating_NArw', 'Heating_1010_0', 'Heating_1010_1', 'Heating_1010_2']\n",
      "\n",
      "evaluating column:  HeatingQC\n",
      "processing column:  HeatingQC\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['HeatingQC_NArw', 'HeatingQC_1010_0', 'HeatingQC_1010_1', 'HeatingQC_1010_2']\n",
      "\n",
      "evaluating column:  CentralAir\n",
      "processing column:  CentralAir\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['CentralAir_bnry', 'CentralAir_NArw']\n",
      "\n",
      "evaluating column:  Electrical\n",
      "processing column:  Electrical\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Electrical_NArw', 'Electrical_1010_0', 'Electrical_1010_1', 'Electrical_1010_2']\n",
      "\n",
      "evaluating column:  1stFlrSF\n",
      "processing column:  1stFlrSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['1stFlrSF_nmbr', '1stFlrSF_NArw']\n",
      "\n",
      "evaluating column:  2ndFlrSF\n",
      "processing column:  2ndFlrSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['2ndFlrSF_nmbr', '2ndFlrSF_NArw']\n",
      "\n",
      "evaluating column:  LowQualFinSF\n",
      "processing column:  LowQualFinSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['LowQualFinSF_nmbr', 'LowQualFinSF_NArw']\n",
      "\n",
      "evaluating column:  GrLivArea\n",
      "processing column:  GrLivArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GrLivArea_nmbr', 'GrLivArea_NArw']\n",
      "\n",
      "evaluating column:  BsmtFullBath\n",
      "processing column:  BsmtFullBath\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtFullBath_nmbr', 'BsmtFullBath_NArw']\n",
      "\n",
      "evaluating column:  BsmtHalfBath\n",
      "processing column:  BsmtHalfBath\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtHalfBath_NArw', 'BsmtHalfBath_1010_0', 'BsmtHalfBath_1010_1']\n",
      "\n",
      "evaluating column:  FullBath\n",
      "processing column:  FullBath\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['FullBath_nmbr', 'FullBath_NArw']\n",
      "\n",
      "evaluating column:  HalfBath\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing column:  HalfBath\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['HalfBath_NArw', 'HalfBath_1010_0', 'HalfBath_1010_1']\n",
      "\n",
      "evaluating column:  BedroomAbvGr\n",
      "processing column:  BedroomAbvGr\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BedroomAbvGr_nmbr', 'BedroomAbvGr_NArw']\n",
      "\n",
      "evaluating column:  KitchenAbvGr\n",
      "processing column:  KitchenAbvGr\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['KitchenAbvGr_nmbr', 'KitchenAbvGr_NArw']\n",
      "\n",
      "evaluating column:  KitchenQual\n",
      "processing column:  KitchenQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['KitchenQual_NArw', 'KitchenQual_1010_0', 'KitchenQual_1010_1', 'KitchenQual_1010_2']\n",
      "\n",
      "evaluating column:  TotRmsAbvGrd\n",
      "processing column:  TotRmsAbvGrd\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['TotRmsAbvGrd_nmbr', 'TotRmsAbvGrd_NArw']\n",
      "\n",
      "evaluating column:  Functional\n",
      "processing column:  Functional\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Functional_NArw', 'Functional_1010_0', 'Functional_1010_1', 'Functional_1010_2']\n",
      "\n",
      "evaluating column:  Fireplaces\n",
      "processing column:  Fireplaces\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['Fireplaces_nmbr', 'Fireplaces_NArw']\n",
      "\n",
      "evaluating column:  FireplaceQu\n",
      "processing column:  FireplaceQu\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['FireplaceQu_NArw', 'FireplaceQu_1010_0', 'FireplaceQu_1010_1', 'FireplaceQu_1010_2']\n",
      "\n",
      "evaluating column:  GarageType\n",
      "processing column:  GarageType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageType_NArw', 'GarageType_1010_0', 'GarageType_1010_1', 'GarageType_1010_2']\n",
      "\n",
      "evaluating column:  GarageYrBlt\n",
      "processing column:  GarageYrBlt\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GarageYrBlt_nmbr', 'GarageYrBlt_NArw']\n",
      "\n",
      "evaluating column:  GarageFinish\n",
      "processing column:  GarageFinish\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageFinish_NArw', 'GarageFinish_1010_0', 'GarageFinish_1010_1']\n",
      "\n",
      "evaluating column:  GarageCars\n",
      "processing column:  GarageCars\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GarageCars_nmbr', 'GarageCars_NArw']\n",
      "\n",
      "evaluating column:  GarageArea\n",
      "processing column:  GarageArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GarageArea_nmbr', 'GarageArea_NArw']\n",
      "\n",
      "evaluating column:  GarageQual\n",
      "processing column:  GarageQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageQual_NArw', 'GarageQual_1010_0', 'GarageQual_1010_1', 'GarageQual_1010_2']\n",
      "\n",
      "evaluating column:  GarageCond\n",
      "processing column:  GarageCond\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageCond_NArw', 'GarageCond_1010_0', 'GarageCond_1010_1', 'GarageCond_1010_2']\n",
      "\n",
      "evaluating column:  PavedDrive\n",
      "processing column:  PavedDrive\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['PavedDrive_NArw', 'PavedDrive_1010_0', 'PavedDrive_1010_1']\n",
      "\n",
      "evaluating column:  WoodDeckSF\n",
      "processing column:  WoodDeckSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['WoodDeckSF_nmbr', 'WoodDeckSF_NArw']\n",
      "\n",
      "evaluating column:  OpenPorchSF\n",
      "processing column:  OpenPorchSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['OpenPorchSF_nmbr', 'OpenPorchSF_NArw']\n",
      "\n",
      "evaluating column:  EnclosedPorch\n",
      "processing column:  EnclosedPorch\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['EnclosedPorch_nmbr', 'EnclosedPorch_NArw']\n",
      "\n",
      "evaluating column:  3SsnPorch\n",
      "processing column:  3SsnPorch\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['3SsnPorch_nmbr', '3SsnPorch_NArw']\n",
      "\n",
      "evaluating column:  ScreenPorch\n",
      "processing column:  ScreenPorch\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['ScreenPorch_nmbr', 'ScreenPorch_NArw']\n",
      "\n",
      "evaluating column:  PoolArea\n",
      "processing column:  PoolArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['PoolArea_nmbr', 'PoolArea_NArw']\n",
      "\n",
      "evaluating column:  PoolQC\n",
      "processing column:  PoolQC\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['PoolQC_NArw', 'PoolQC_1010_0', 'PoolQC_1010_1']\n",
      "\n",
      "evaluating column:  Fence\n",
      "processing column:  Fence\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Fence_NArw', 'Fence_1010_0', 'Fence_1010_1', 'Fence_1010_2']\n",
      "\n",
      "evaluating column:  MiscFeature\n",
      "processing column:  MiscFeature\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['MiscFeature_NArw', 'MiscFeature_1010_0', 'MiscFeature_1010_1', 'MiscFeature_1010_2']\n",
      "\n",
      "evaluating column:  MiscVal\n",
      "processing column:  MiscVal\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MiscVal_nmbr', 'MiscVal_NArw']\n",
      "\n",
      "evaluating column:  MoSold\n",
      "processing column:  MoSold\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MoSold_nmbr', 'MoSold_NArw']\n",
      "\n",
      "evaluating column:  YrSold\n",
      "processing column:  YrSold\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['YrSold_nmbr', 'YrSold_NArw']\n",
      "\n",
      "evaluating column:  SaleType\n",
      "processing column:  SaleType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['SaleType_NArw', 'SaleType_1010_0', 'SaleType_1010_1', 'SaleType_1010_2', 'SaleType_1010_3']\n",
      "\n",
      "evaluating column:  SaleCondition\n",
      "processing column:  SaleCondition\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['SaleCondition_NArw', 'SaleCondition_1010_0', 'SaleCondition_1010_1', 'SaleCondition_1010_2']\n",
      "\n",
      "______\n",
      "\n",
      "evaluating label column:  SalePrice\n",
      "processing label column:  SalePrice\n",
      "    root label category:  lbnm\n",
      "\n",
      " returned columns:\n",
      "['SalePrice_exc2']\n",
      "\n",
      "______\n",
      "\n",
      "infill to column:  PoolQC_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005117/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005117/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    7\n",
      "Train Data Columns: 241\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t3 unique label values:  ['0', '1', '2']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Updated label_count_threshold from 10 to 2 to avoid cutting too many classes.\n",
      "Warning: Updated holdout_frac from 0.2 to 0.501 to avoid cutting too many classes.\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17272.09 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 133): ['train_3', 'train_4', 'train_5', 'train_15', 'train_23', 'train_32', 'train_38', 'train_39', 'train_40', 'train_41', 'train_42', 'train_44', 'train_45', 'train_46', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_58', 'train_60', 'train_61', 'train_62', 'train_63', 'train_64', 'train_69', 'train_70', 'train_74', 'train_75', 'train_76', 'train_77', 'train_78', 'train_79', 'train_80', 'train_81', 'train_82', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_93', 'train_96', 'train_97', 'train_99', 'train_101', 'train_106', 'train_107', 'train_112', 'train_113', 'train_116', 'train_117', 'train_118', 'train_121', 'train_124', 'train_125', 'train_126', 'train_129', 'train_130', 'train_133', 'train_134', 'train_135', 'train_136', 'train_137', 'train_138', 'train_141', 'train_145', 'train_146', 'train_149', 'train_150', 'train_151', 'train_152', 'train_153', 'train_154', 'train_155', 'train_156', 'train_157', 'train_161', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_171', 'train_172', 'train_174', 'train_175', 'train_176', 'train_178', 'train_179', 'train_180', 'train_181', 'train_184', 'train_185', 'train_186', 'train_187', 'train_188', 'train_189', 'train_190', 'train_194', 'train_196', 'train_197', 'train_198', 'train_199', 'train_202', 'train_203', 'train_204', 'train_207', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_219', 'train_220', 'train_224', 'train_229', 'train_230', 'train_231', 'train_232', 'train_236', 'train_237']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 108 | ['train_0', 'train_1', 'train_2', 'train_6', 'train_7', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 108 | ['train_0', 'train_1', 'train_2', 'train_6', 'train_7', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t108 features in original data used to generate 108 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.25\t = Validation accuracy score\n",
      "\t2.07s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 264, in _predict_proba\n",
      "    y_pred_proba = self.model.predict_proba(X)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/neighbors/_classification.py\", line 219, in predict_proba\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 616, in kneighbors\n",
      "    raise ValueError(\n",
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 264, in _predict_proba\n",
      "    y_pred_proba = self.model.predict_proba(X)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/neighbors/_classification.py\", line 219, in predict_proba\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 616, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 5\n",
      "Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 5\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 264, in _predict_proba\n",
      "    y_pred_proba = self.model.predict_proba(X)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/neighbors/_classification.py\", line 219, in predict_proba\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 616, in kneighbors\n",
      "    raise ValueError(\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 264, in _predict_proba\n",
      "    y_pred_proba = self.model.predict_proba(X)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/neighbors/_classification.py\", line 219, in predict_proba\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 616, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 5\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.75\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.75\t = Validation accuracy score\n",
      "\t0.36s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.75\t = Validation accuracy score\n",
      "\t0.27s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.75\t = Validation accuracy score\n",
      "\t0.28s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.25\t = Validation accuracy score\n",
      "\t0.22s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.25\t = Validation accuracy score\n",
      "\t0.15s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.25\t = Validation accuracy score\n",
      "\t0.32s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.25\t = Validation accuracy score\n",
      "\t0.16s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.75\t = Validation accuracy score\n",
      "\t0.17s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.0s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005122/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005122/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    54\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t4 unique label values:  ['2', '0', '1', '3']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Updated label_count_threshold from 10 to 2 to avoid cutting too many classes.\n",
      "Warning: Updated holdout_frac from 0.2 to 0.501 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 2 examples. AutoGluon will only keep 3 out of 4 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 2 examples that will be kept for training models: 0.9814814814814815\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17241.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 88): ['train_4', 'train_5', 'train_34', 'train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_70', 'train_74', 'train_75', 'train_79', 'train_80', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_98', 'train_99', 'train_100', 'train_101', 'train_106', 'train_107', 'train_112', 'train_113', 'train_116', 'train_117', 'train_118', 'train_121', 'train_125', 'train_145', 'train_150', 'train_151', 'train_152', 'train_153', 'train_154', 'train_157', 'train_161', 'train_162', 'train_164', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_171', 'train_172', 'train_174', 'train_175', 'train_178', 'train_179', 'train_180', 'train_181', 'train_184', 'train_185', 'train_189', 'train_202', 'train_203', 'train_206', 'train_210', 'train_212', 'train_215', 'train_216', 'train_217', 'train_218', 'train_219', 'train_220', 'train_221', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236', 'train_239']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 152 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_6', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 152 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_6', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t152 features in original data used to generate 152 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.15s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  PoolQC_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MiscFeature_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.9259\t = Validation accuracy score\n",
      "\t2.54s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.9259\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.9259\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9259\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.9259\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.8889\t = Validation accuracy score\n",
      "\t0.28s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.8889\t = Validation accuracy score\n",
      "\t0.28s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9259\t = Validation accuracy score\n",
      "\t0.23s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9259\t = Validation accuracy score\n",
      "\t0.16s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9259\t = Validation accuracy score\n",
      "\t0.79s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9259\t = Validation accuracy score\n",
      "\t0.27s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9259\t = Validation accuracy score\n",
      "\t0.23s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.28s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005129/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005129/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    91\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17236.46 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.18 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 89): ['train_3', 'train_4', 'train_31', 'train_33', 'train_37', 'train_38', 'train_43', 'train_44', 'train_45', 'train_46', 'train_49', 'train_50', 'train_53', 'train_54', 'train_56', 'train_57', 'train_58', 'train_59', 'train_61', 'train_67', 'train_68', 'train_72', 'train_73', 'train_74', 'train_75', 'train_76', 'train_77', 'train_81', 'train_82', 'train_86', 'train_87', 'train_88', 'train_89', 'train_90', 'train_94', 'train_95', 'train_96', 'train_97', 'train_98', 'train_99', 'train_104', 'train_105', 'train_115', 'train_116', 'train_119', 'train_123', 'train_143', 'train_148', 'train_149', 'train_150', 'train_151', 'train_155', 'train_159', 'train_160', 'train_164', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_172', 'train_173', 'train_174', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_219', 'train_227', 'train_228', 'train_229', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 153 | ['train_0', 'train_1', 'train_2', 'train_5', 'train_6', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 153 | ['train_0', 'train_1', 'train_2', 'train_5', 'train_6', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t153 features in original data used to generate 153 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.11 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: RandomForestClassifierGini ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  MiscFeature_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MiscFeature_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Alley_bnry\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.8421\t = Validation accuracy score\n",
      "\t0.41s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.8421\t = Validation accuracy score\n",
      "\t0.4s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.8947\t = Validation accuracy score\n",
      "\t0.3s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.8947\t = Validation accuracy score\n",
      "\t0.31s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.8421\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.8421\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9474\t = Validation accuracy score\n",
      "\t0.18s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9474\t = Validation accuracy score\n",
      "\t0.25s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.8947\t = Validation accuracy score\n",
      "\t0.59s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.8421\t = Validation accuracy score\n",
      "\t2.18s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9474\t = Validation accuracy score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9474\t = Validation accuracy score\n",
      "\t0.21s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.94s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005135/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005135/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    281\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t4 unique label values:  ['2', '1', '0', '3']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17205.5 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.54 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 81): ['train_3', 'train_5', 'train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_61', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_100', 'train_101', 'train_106', 'train_107', 'train_112', 'train_113', 'train_116', 'train_117', 'train_118', 'train_121', 'train_125', 'train_145', 'train_150', 'train_151', 'train_152', 'train_153', 'train_154', 'train_157', 'train_161', 'train_162', 'train_164', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_171', 'train_172', 'train_174', 'train_175', 'train_178', 'train_179', 'train_180', 'train_181', 'train_184', 'train_185', 'train_189', 'train_202', 'train_203', 'train_212', 'train_215', 'train_216', 'train_217', 'train_218', 'train_219', 'train_220', 'train_225', 'train_226', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 159 | ['train_0', 'train_1', 'train_2', 'train_4', 'train_6', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 159 | ['train_0', 'train_1', 'train_2', 'train_4', 'train_6', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t159 features in original data used to generate 159 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.16s ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Fence_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.5614\t = Validation accuracy score\n",
      "\t2.39s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.386\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.4386\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.5263\t = Validation accuracy score\n",
      "\t0.43s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.5263\t = Validation accuracy score\n",
      "\t0.42s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.4737\t = Validation accuracy score\n",
      "\t0.33s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.5088\t = Validation accuracy score\n",
      "\t0.34s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.5614\t = Validation accuracy score\n",
      "\t0.32s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.5789\t = Validation accuracy score\n",
      "\t0.29s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.5789\t = Validation accuracy score\n",
      "\t1.45s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.6316\t = Validation accuracy score\n",
      "\t0.9s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.6316\t = Validation accuracy score\n",
      "\t0.23s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 7.87s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005143/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005143/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    770\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t5 unique label values:  ['4', '2', '1', '0', '3']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 5\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17177.42 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.48 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 72): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_117', 'train_118', 'train_121', 'train_125', 'train_145', 'train_150', 'train_151', 'train_152', 'train_153', 'train_157', 'train_161', 'train_162', 'train_164', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_171', 'train_174', 'train_175', 'train_178', 'train_179', 'train_180', 'train_181', 'train_184', 'train_185', 'train_189', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t168 features in original data used to generate 168 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Fence_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Fence_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  FireplaceQu_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.6753\t = Validation accuracy score\n",
      "\t4.13s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.6364\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.6299\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.6883\t = Validation accuracy score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.6818\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.7013\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.6948\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.7013\t = Validation accuracy score\n",
      "\t0.95s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.7273\t = Validation accuracy score\n",
      "\t0.7s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.7338\t = Validation accuracy score\n",
      "\t2.6s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.7143\t = Validation accuracy score\n",
      "\t3.67s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.7338\t = Validation accuracy score\n",
      "\t0.23s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 15.07s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005159/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005159/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1201\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (11.031138364952225, -2.2271116889639586, -0.0, 1.10265)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17077.73 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.33 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 71): ['train_4', 'train_37', 'train_38', 'train_42', 'train_43', 'train_45', 'train_46', 'train_49', 'train_50', 'train_53', 'train_54', 'train_58', 'train_61', 'train_67', 'train_72', 'train_73', 'train_77', 'train_81', 'train_82', 'train_86', 'train_87', 'train_88', 'train_89', 'train_90', 'train_94', 'train_95', 'train_99', 'train_104', 'train_105', 'train_115', 'train_116', 'train_119', 'train_123', 'train_143', 'train_148', 'train_149', 'train_150', 'train_151', 'train_155', 'train_159', 'train_164', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 171 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 171 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_5', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t171 features in original data used to generate 171 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.64 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  FireplaceQu_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  FireplaceQu_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotFrontage_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.6691\t = Validation root_mean_squared_error score\n",
      "\t0.69s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.6633\t = Validation root_mean_squared_error score\n",
      "\t0.64s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.8247\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.8163\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.6259\t = Validation root_mean_squared_error score\n",
      "\t0.88s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.6974\t = Validation root_mean_squared_error score\n",
      "\t0.64s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.6068\t = Validation root_mean_squared_error score\n",
      "\t1.33s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.7493\t = Validation root_mean_squared_error score\n",
      "\t7.64s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.6788\t = Validation root_mean_squared_error score\n",
      "\t1.15s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.6014\t = Validation root_mean_squared_error score\n",
      "\t0.34s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.28s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005213/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005213/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1379\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t5 unique label values:  ['4', '1', '2', '3', '0']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 2 out of 5 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9869470630891951\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16904.68 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.62 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  GarageCond_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 74): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_117', 'train_118', 'train_121', 'train_125', 'train_145', 'train_150', 'train_151', 'train_152', 'train_153', 'train_157', 'train_161', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_171', 'train_174', 'train_175', 'train_178', 'train_179', 'train_180', 'train_181', 'train_184', 'train_185', 'train_189', 'train_194', 'train_198', 'train_199', 'train_202', 'train_203', 'train_204', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t166 features in original data used to generate 166 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9707\t = Validation accuracy score\n",
      "\t0.46s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.9707\t = Validation accuracy score\n",
      "\t0.45s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.9707\t = Validation accuracy score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.9707\t = Validation accuracy score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.9744\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.9744\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.978\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.978\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9744\t = Validation accuracy score\n",
      "\t0.83s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.9744\t = Validation accuracy score\n",
      "\t4.33s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9744\t = Validation accuracy score\n",
      "\t0.79s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.978\t = Validation accuracy score\n",
      "\t0.33s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 9.69s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005223/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005223/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1379\n",
      "Train Data Columns: 241\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t3 unique label values:  ['1', '2', '0']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16921.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.67 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  GarageCond_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageCond_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageFinish_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 74): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_117', 'train_118', 'train_121', 'train_125', 'train_145', 'train_150', 'train_151', 'train_152', 'train_153', 'train_157', 'train_161', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_171', 'train_174', 'train_175', 'train_178', 'train_179', 'train_180', 'train_181', 'train_184', 'train_185', 'train_189', 'train_194', 'train_198', 'train_199', 'train_200', 'train_201', 'train_205', 'train_209', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_222', 'train_226', 'train_229', 'train_230', 'train_231', 'train_232', 'train_237']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t167 features in original data used to generate 167 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.85 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.6558\t = Validation accuracy score\n",
      "\t6.5s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.6667\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.6848\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.7101\t = Validation accuracy score\n",
      "\t0.49s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.7065\t = Validation accuracy score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.692\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.7138\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.7029\t = Validation accuracy score\n",
      "\t1.0s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.6993\t = Validation accuracy score\n",
      "\t1.32s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.7065\t = Validation accuracy score\n",
      "\t5.63s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.7101\t = Validation accuracy score\n",
      "\t4.96s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.7319\t = Validation accuracy score\n",
      "\t0.27s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 22.89s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005246/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005246/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1379\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t5 unique label values:  ['4', '1', '2', '0', '3']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 3 out of 5 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9956490210297317\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16882.61 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.65 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  GarageFinish_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageQual_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 74): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_117', 'train_118', 'train_121', 'train_125', 'train_145', 'train_150', 'train_151', 'train_152', 'train_153', 'train_157', 'train_161', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_171', 'train_174', 'train_175', 'train_178', 'train_179', 'train_180', 'train_181', 'train_184', 'train_185', 'train_189', 'train_194', 'train_198', 'train_199', 'train_202', 'train_203', 'train_204', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t166 features in original data used to generate 166 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.83 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.9527\t = Validation accuracy score\n",
      "\t4.85s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.9491\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.9491\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9527\t = Validation accuracy score\n",
      "\t0.51s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.9527\t = Validation accuracy score\n",
      "\t0.5s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.9564\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.9564\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.96\t = Validation accuracy score\n",
      "\t0.74s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9673\t = Validation accuracy score\n",
      "\t0.72s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9564\t = Validation accuracy score\n",
      "\t2.02s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9564\t = Validation accuracy score\n",
      "\t2.54s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9673\t = Validation accuracy score\n",
      "\t0.26s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.05s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005301/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005301/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1379\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t6 unique label values:  ['1', '5', '3', '4', '2', '0']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 4 out of 6 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9891225525743292\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16836.31 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.63 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  GarageQual_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageQual_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageType_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 74): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_117', 'train_118', 'train_121', 'train_125', 'train_145', 'train_150', 'train_151', 'train_152', 'train_153', 'train_157', 'train_161', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_171', 'train_174', 'train_175', 'train_178', 'train_179', 'train_180', 'train_181', 'train_184', 'train_185', 'train_189', 'train_194', 'train_195', 'train_198', 'train_199', 'train_200', 'train_204', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t166 features in original data used to generate 166 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.8462\t = Validation accuracy score\n",
      "\t6.32s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.8022\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.8022\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.8462\t = Validation accuracy score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.8462\t = Validation accuracy score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.8388\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.8425\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.8791\t = Validation accuracy score\n",
      "\t1.12s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.8498\t = Validation accuracy score\n",
      "\t1.34s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.8791\t = Validation accuracy score\n",
      "\t5.9s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.8608\t = Validation accuracy score\n",
      "\t4.8s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.8864\t = Validation accuracy score\n",
      "\t0.27s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 22.84s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005324/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005324/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1379\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1.3125394082948738, -3.2718286056182913, 0.0, 1.02897)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16859.85 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.67 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  GarageType_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageType_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageYrBlt_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 74): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_116', 'train_117', 'train_120', 'train_124', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_173', 'train_174', 'train_177', 'train_178', 'train_179', 'train_180', 'train_183', 'train_184', 'train_188', 'train_193', 'train_197', 'train_200', 'train_201', 'train_202', 'train_206', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t168 features in original data used to generate 168 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.85 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.3848\t = Validation root_mean_squared_error score\n",
      "\t0.7s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.3708\t = Validation root_mean_squared_error score\n",
      "\t0.64s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.4855\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.4839\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.3519\t = Validation root_mean_squared_error score\n",
      "\t0.58s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.3921\t = Validation root_mean_squared_error score\n",
      "\t0.42s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.3809\t = Validation root_mean_squared_error score\n",
      "\t1.26s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.435\t = Validation root_mean_squared_error score\n",
      "\t6.88s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain_set's rmse: 0.000288267\tvalid_set's rmse: 0.389978\n",
      "[2000]\ttrain_set's rmse: 2.83864e-06\tvalid_set's rmse: 0.389967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.39\t = Validation root_mean_squared_error score\n",
      "\t10.27s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.3492\t = Validation root_mean_squared_error score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 22.54s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005346/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005346/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1422\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t4 unique label values:  ['3', '1', '2', '0']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16905.84 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.74 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BsmtExposure_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 75): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_117', 'train_118', 'train_121', 'train_125', 'train_129', 'train_130', 'train_133', 'train_134', 'train_137', 'train_141', 'train_146', 'train_147', 'train_148', 'train_149', 'train_153', 'train_157', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_170', 'train_171', 'train_174', 'train_175', 'train_176', 'train_177', 'train_180', 'train_181', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 165 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 165 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t165 features in original data used to generate 165 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.89 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.7439\t = Validation accuracy score\n",
      "\t6.14s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.6702\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.7018\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.7333\t = Validation accuracy score\n",
      "\t0.5s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.7228\t = Validation accuracy score\n",
      "\t0.5s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.7228\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.7333\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.7509\t = Validation accuracy score\n",
      "\t1.47s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.7614\t = Validation accuracy score\n",
      "\t1.6s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.7579\t = Validation accuracy score\n",
      "\t3.25s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.7193\t = Validation accuracy score\n",
      "\t4.91s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.7649\t = Validation accuracy score\n",
      "\t0.28s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 20.86s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005408/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005408/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1422\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t6 unique label values:  ['5', '1', '0', '4', '3', '2']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 6\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16784.02 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.74 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BsmtExposure_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtExposure_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinType2_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 76): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_117', 'train_118', 'train_121', 'train_125', 'train_129', 'train_130', 'train_133', 'train_134', 'train_138', 'train_141', 'train_145', 'train_146', 'train_147', 'train_148', 'train_149', 'train_153', 'train_157', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_170', 'train_171', 'train_174', 'train_175', 'train_176', 'train_177', 'train_180', 'train_181', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 164 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 164 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t164 features in original data used to generate 164 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.88 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.9439\t = Validation accuracy score\n",
      "\t6.24s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.8947\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.8947\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.8947\t = Validation accuracy score\n",
      "\t0.49s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.8877\t = Validation accuracy score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.8842\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.8842\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9439\t = Validation accuracy score\n",
      "\t0.96s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9263\t = Validation accuracy score\n",
      "\t0.89s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9404\t = Validation accuracy score\n",
      "\t3.92s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9368\t = Validation accuracy score\n",
      "\t4.89s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9474\t = Validation accuracy score\n",
      "\t0.27s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 20.2s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005428/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005428/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1423\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t4 unique label values:  ['3', '1', '0', '2']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 3 out of 4 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9985945186226283\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16680.82 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.74 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BsmtFinType2_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinType2_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtCond_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 74): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_117', 'train_118', 'train_121', 'train_125', 'train_129', 'train_130', 'train_134', 'train_137', 'train_141', 'train_146', 'train_147', 'train_148', 'train_149', 'train_153', 'train_157', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_170', 'train_171', 'train_174', 'train_175', 'train_176', 'train_177', 'train_180', 'train_181', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t166 features in original data used to generate 166 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.9 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.9228\t = Validation accuracy score\n",
      "\t4.59s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.9158\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.9193\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9228\t = Validation accuracy score\n",
      "\t0.51s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.9228\t = Validation accuracy score\n",
      "\t0.5s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.9228\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.9228\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9263\t = Validation accuracy score\n",
      "\t0.81s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9263\t = Validation accuracy score\n",
      "\t1.02s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9228\t = Validation accuracy score\n",
      "\t1.53s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9263\t = Validation accuracy score\n",
      "\t3.12s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9263\t = Validation accuracy score\n",
      "\t0.26s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.31s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005442/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005442/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1423\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t6 unique label values:  ['2', '0', '5', '4', '1', '3']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 6\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16615.43 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.74 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BsmtCond_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtCond_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinType1_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 75): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_117', 'train_118', 'train_121', 'train_125', 'train_129', 'train_130', 'train_133', 'train_134', 'train_138', 'train_141', 'train_146', 'train_147', 'train_148', 'train_149', 'train_153', 'train_157', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_170', 'train_171', 'train_174', 'train_175', 'train_176', 'train_177', 'train_180', 'train_181', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 165 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 165 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t165 features in original data used to generate 165 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.89 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.7263\t = Validation accuracy score\n",
      "\t5.16s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.5579\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.5825\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.6982\t = Validation accuracy score\n",
      "\t0.53s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.6947\t = Validation accuracy score\n",
      "\t0.52s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.6491\t = Validation accuracy score\n",
      "\t0.41s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.6316\t = Validation accuracy score\n",
      "\t0.41s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.7193\t = Validation accuracy score\n",
      "\t2.13s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.6912\t = Validation accuracy score\n",
      "\t2.07s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.7368\t = Validation accuracy score\n",
      "\t4.97s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.7158\t = Validation accuracy score\n",
      "\t5.84s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.7474\t = Validation accuracy score\n",
      "\t0.29s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 23.8s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005506/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005506/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1423\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t4 unique label values:  ['2', '3', '0', '1']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16729.7 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.74 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BsmtFinType1_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinType1_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtQual_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 74): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_117', 'train_118', 'train_121', 'train_125', 'train_129', 'train_130', 'train_134', 'train_137', 'train_141', 'train_146', 'train_147', 'train_148', 'train_149', 'train_153', 'train_157', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_170', 'train_171', 'train_174', 'train_175', 'train_176', 'train_177', 'train_180', 'train_181', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t166 features in original data used to generate 166 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.9 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.8386\t = Validation accuracy score\n",
      "\t5.88s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.8351\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.8351\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.8526\t = Validation accuracy score\n",
      "\t0.51s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.8526\t = Validation accuracy score\n",
      "\t0.5s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.8561\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.8526\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.8667\t = Validation accuracy score\n",
      "\t1.27s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.8772\t = Validation accuracy score\n",
      "\t1.28s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.8561\t = Validation accuracy score\n",
      "\t2.03s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.8737\t = Validation accuracy score\n",
      "\t5.23s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.8772\t = Validation accuracy score\n",
      "\t0.29s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 19.2s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005526/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005526/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1452\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (8.286659430224768, -0.5742137196941471, -0.0, 1.00275)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16669.14 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BsmtQual_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtQual_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MasVnrArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 75): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_111', 'train_112', 'train_115', 'train_116', 'train_119', 'train_123', 'train_128', 'train_132', 'train_136', 'train_143', 'train_148', 'train_149', 'train_150', 'train_151', 'train_155', 'train_159', 'train_164', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t167 features in original data used to generate 167 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.94 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.5351\t = Validation root_mean_squared_error score\n",
      "\t0.68s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.6054\t = Validation root_mean_squared_error score\n",
      "\t0.57s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.7231\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.7193\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.551\t = Validation root_mean_squared_error score\n",
      "\t0.69s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.5611\t = Validation root_mean_squared_error score\n",
      "\t0.41s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.5524\t = Validation root_mean_squared_error score\n",
      "\t1.51s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.6146\t = Validation root_mean_squared_error score\n",
      "\t10.41s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.5665\t = Validation root_mean_squared_error score\n",
      "\t1.94s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.5163\t = Validation root_mean_squared_error score\n",
      "\t0.34s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 17.46s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005543/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005543/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1452\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t4 unique label values:  ['1', '2', '3', '0']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16599.72 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.8 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  MasVnrType_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 74): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_112', 'train_113', 'train_114', 'train_117', 'train_121', 'train_126', 'train_130', 'train_134', 'train_141', 'train_146', 'train_147', 'train_148', 'train_149', 'train_153', 'train_157', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_170', 'train_171', 'train_174', 'train_175', 'train_176', 'train_177', 'train_180', 'train_181', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t166 features in original data used to generate 166 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.94 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.9313\t = Validation accuracy score\n",
      "\t6.97s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.7285\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.7388\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9278\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.921\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.811\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.8213\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9313\t = Validation accuracy score\n",
      "\t1.03s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9141\t = Validation accuracy score\n",
      "\t1.27s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9313\t = Validation accuracy score\n",
      "\t3.92s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9175\t = Validation accuracy score\n",
      "\t3.4s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9381\t = Validation accuracy score\n",
      "\t0.25s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 19.71s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005603/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005603/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1459\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t5 unique label values:  ['4', '1', '0', '2', '3']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 3 out of 5 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9972583961617546\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16463.72 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  MasVnrType_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MasVnrType_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Electrical_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 74): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_113', 'train_117', 'train_118', 'train_121', 'train_125', 'train_130', 'train_134', 'train_138', 'train_145', 'train_150', 'train_151', 'train_152', 'train_153', 'train_157', 'train_161', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_170', 'train_171', 'train_174', 'train_175', 'train_176', 'train_177', 'train_180', 'train_181', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t166 features in original data used to generate 166 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.94 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.9175\t = Validation accuracy score\n",
      "\t4.42s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.9003\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.9003\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9175\t = Validation accuracy score\n",
      "\t0.49s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.9175\t = Validation accuracy score\n",
      "\t0.49s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.9141\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.9175\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.921\t = Validation accuracy score\n",
      "\t1.07s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9175\t = Validation accuracy score\n",
      "\t0.8s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9175\t = Validation accuracy score\n",
      "\t1.51s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.921\t = Validation accuracy score\n",
      "\t1.9s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.921\t = Validation accuracy score\n",
      "\t0.25s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 12.75s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005616/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005616/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (9.129553114010687, -2.1434376489218288, 0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16396.71 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Electrical_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Electrical_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  1stFlrSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.3903\t = Validation root_mean_squared_error score\n",
      "\t0.8s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.3978\t = Validation root_mean_squared_error score\n",
      "\t0.76s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.6277\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.6237\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain_set's rmse: 0.00380301\tvalid_set's rmse: 0.35927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.3587\t = Validation root_mean_squared_error score\n",
      "\t2.97s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain_set's rmse: 0.00346364\tvalid_set's rmse: 0.436376\n",
      "[2000]\ttrain_set's rmse: 0.00028543\tvalid_set's rmse: 0.434583\n",
      "[3000]\ttrain_set's rmse: 4.19607e-05\tvalid_set's rmse: 0.434541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4345\t = Validation root_mean_squared_error score\n",
      "\t4.14s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.3754\t = Validation root_mean_squared_error score\n",
      "\t9.76s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.3398\t = Validation root_mean_squared_error score\n",
      "\t16.61s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain_set's rmse: 0.00277812\tvalid_set's rmse: 0.339338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.3392\t = Validation root_mean_squared_error score\n",
      "\t6.65s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.3156\t = Validation root_mean_squared_error score\n",
      "\t0.34s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 43.5s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005700/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005700/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (3.9356142533042577, -0.7948908644380643, -0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16845.98 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  2ndFlrSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.1984\t = Validation root_mean_squared_error score\n",
      "\t0.66s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.1672\t = Validation root_mean_squared_error score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.4309\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.4255\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.1686\t = Validation root_mean_squared_error score\n",
      "\t0.66s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.2024\t = Validation root_mean_squared_error score\n",
      "\t1.11s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.14\t = Validation root_mean_squared_error score\n",
      "\t4.07s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.2445\t = Validation root_mean_squared_error score\n",
      "\t13.65s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.1321\t = Validation root_mean_squared_error score\n",
      "\t1.68s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.1201\t = Validation root_mean_squared_error score\n",
      "\t0.34s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 23.64s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005723/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005723/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (17.211335458445188, -0.11629943710230206, 0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16742.88 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_173', 'train_174', 'train_177', 'train_178', 'train_179', 'train_180', 'train_183', 'train_184', 'train_188', 'train_201', 'train_202', 'train_211', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  3SsnPorch_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-1.2305\t = Validation root_mean_squared_error score\n",
      "\t0.55s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-1.1861\t = Validation root_mean_squared_error score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-1.1442\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-1.1272\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-1.0759\t = Validation root_mean_squared_error score\n",
      "\t0.41s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-1.075\t = Validation root_mean_squared_error score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-1.0774\t = Validation root_mean_squared_error score\n",
      "\t0.67s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-1.0853\t = Validation root_mean_squared_error score\n",
      "\t4.34s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-1.0792\t = Validation root_mean_squared_error score\n",
      "\t0.8s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-1.0694\t = Validation root_mean_squared_error score\n",
      "\t0.34s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 8.56s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005732/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005732/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (6.292841148012137, -3.513747859163548, 0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16692.99 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_173', 'train_174', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BedroomAbvGr_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.6386\t = Validation root_mean_squared_error score\n",
      "\t0.66s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.635\t = Validation root_mean_squared_error score\n",
      "\t0.57s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.8298\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.8259\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.65\t = Validation root_mean_squared_error score\n",
      "\t0.46s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.6542\t = Validation root_mean_squared_error score\n",
      "\t0.4s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.6212\t = Validation root_mean_squared_error score\n",
      "\t3.87s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.6901\t = Validation root_mean_squared_error score\n",
      "\t12.55s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.6505\t = Validation root_mean_squared_error score\n",
      "\t4.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.6089\t = Validation root_mean_squared_error score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 23.78s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005756/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005756/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t5 unique label values:  ['0', '1', '2', '4', '3']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 5\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16559.04 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_80', 'train_84', 'train_85', 'train_86', 'train_87', 'train_88', 'train_92', 'train_93', 'train_97', 'train_102', 'train_103', 'train_109', 'train_113', 'train_114', 'train_117', 'train_121', 'train_126', 'train_130', 'train_134', 'train_141', 'train_146', 'train_147', 'train_148', 'train_149', 'train_153', 'train_157', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_170', 'train_171', 'train_174', 'train_175', 'train_176', 'train_177', 'train_180', 'train_181', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t167 features in original data used to generate 167 features in processed data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BldgType_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTrain Data (Processed) Memory Usage: 1.96 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.9692\t = Validation accuracy score\n",
      "\t7.46s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.9247\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.9384\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9555\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.9521\t = Validation accuracy score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.9589\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.9658\t = Validation accuracy score\n",
      "\t0.36s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9829\t = Validation accuracy score\n",
      "\t0.76s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9726\t = Validation accuracy score\n",
      "\t0.92s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9829\t = Validation accuracy score\n",
      "\t3.26s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9692\t = Validation accuracy score\n",
      "\t3.51s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9829\t = Validation accuracy score\n",
      "\t0.24s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 18.98s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005815/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005815/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (11.401846178273868, -0.9726849003236182, -0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16486.54 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_148', 'train_149', 'train_150', 'train_151', 'train_155', 'train_159', 'train_164', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BldgType_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BldgType_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinSF1_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.5415\t = Validation root_mean_squared_error score\n",
      "\t0.64s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.5658\t = Validation root_mean_squared_error score\n",
      "\t0.59s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.7038\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.6995\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain_set's rmse: 0.00304776\tvalid_set's rmse: 0.490642\n",
      "[2000]\ttrain_set's rmse: 8.0119e-05\tvalid_set's rmse: 0.489448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4894\t = Validation root_mean_squared_error score\n",
      "\t3.33s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain_set's rmse: 0.00234111\tvalid_set's rmse: 0.521398\n",
      "[2000]\ttrain_set's rmse: 0.000163631\tvalid_set's rmse: 0.520511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.5205\t = Validation root_mean_squared_error score\n",
      "\t4.11s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.4999\t = Validation root_mean_squared_error score\n",
      "\t6.12s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.5186\t = Validation root_mean_squared_error score\n",
      "\t12.72s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain_set's rmse: 0.00101787\tvalid_set's rmse: 0.501047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.501\t = Validation root_mean_squared_error score\n",
      "\t4.49s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.484\t = Validation root_mean_squared_error score\n",
      "\t0.34s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 33.63s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005849/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005849/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (8.848605997891852, -0.2885539604701581, -0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16649.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_155', 'train_159', 'train_164', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BsmtFinSF2_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.4996\t = Validation root_mean_squared_error score\n",
      "\t0.59s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.6298\t = Validation root_mean_squared_error score\n",
      "\t0.52s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-1.1008\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-1.0994\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.4146\t = Validation root_mean_squared_error score\n",
      "\t0.64s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.5219\t = Validation root_mean_squared_error score\n",
      "\t1.02s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.501\t = Validation root_mean_squared_error score\n",
      "\t9.14s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-1.1225\t = Validation root_mean_squared_error score\n",
      "\t4.57s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.5296\t = Validation root_mean_squared_error score\n",
      "\t2.2s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.4146\t = Validation root_mean_squared_error score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 20.08s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005909/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005909/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (4.961659106657423, -0.8196835076441235, -0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16698.08 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BsmtFullBath_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.6958\t = Validation root_mean_squared_error score\n",
      "\t0.7s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.6716\t = Validation root_mean_squared_error score\n",
      "\t0.56s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.7936\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.7925\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.6818\t = Validation root_mean_squared_error score\n",
      "\t0.5s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.6613\t = Validation root_mean_squared_error score\n",
      "\t0.43s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.6477\t = Validation root_mean_squared_error score\n",
      "\t1.53s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.7528\t = Validation root_mean_squared_error score\n",
      "\t5.83s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.6938\t = Validation root_mean_squared_error score\n",
      "\t1.34s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.6387\t = Validation root_mean_squared_error score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11.99s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005921/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005921/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 241\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t3 unique label values:  ['0', '1', '2']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 2 out of 3 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9986301369863013\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16633.07 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_113', 'train_117', 'train_118', 'train_121', 'train_125', 'train_130', 'train_134', 'train_138', 'train_145', 'train_150', 'train_151', 'train_152', 'train_153', 'train_157', 'train_161', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_171', 'train_172', 'train_175', 'train_176', 'train_177', 'train_178', 'train_181', 'train_182', 'train_186', 'train_199', 'train_200', 'train_209', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_222', 'train_226', 'train_229', 'train_230', 'train_231', 'train_232', 'train_237']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t168 features in original data used to generate 168 features in processed data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BsmtHalfBath_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9452\t = Validation accuracy score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.9452\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.9452\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.9452\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.9452\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.9452\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9521\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9521\t = Validation accuracy score\n",
      "\t0.44s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9486\t = Validation accuracy score\n",
      "\t1.08s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.9452\t = Validation accuracy score\n",
      "\t4.37s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9555\t = Validation accuracy score\n",
      "\t1.66s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9555\t = Validation accuracy score\n",
      "\t0.34s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11.24s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_005932/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_005932/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (4.0029234317160105, -1.2837357583879425, -0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16521.17 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_155', 'train_159', 'train_164', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  BsmtHalfBath_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtUnfSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.2418\t = Validation root_mean_squared_error score\n",
      "\t0.77s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.242\t = Validation root_mean_squared_error score\n",
      "\t0.74s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.5244\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.5205\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.1942\t = Validation root_mean_squared_error score\n",
      "\t0.54s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.2127\t = Validation root_mean_squared_error score\n",
      "\t0.66s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.1399\t = Validation root_mean_squared_error score\n",
      "\t4.47s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.2131\t = Validation root_mean_squared_error score\n",
      "\t20.62s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain_set's rmse: 0.00455097\tvalid_set's rmse: 0.213886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.2128\t = Validation root_mean_squared_error score\n",
      "\t7.64s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.1212\t = Validation root_mean_squared_error score\n",
      "\t0.34s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 36.94s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010009/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010009/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16362.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_164', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  CentralAir_bnry\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9521\t = Validation accuracy score\n",
      "\t0.45s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.9521\t = Validation accuracy score\n",
      "\t0.45s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.9589\t = Validation accuracy score\n",
      "\t0.36s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.9521\t = Validation accuracy score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.9521\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.9521\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9555\t = Validation accuracy score\n",
      "\t0.45s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9623\t = Validation accuracy score\n",
      "\t0.33s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9589\t = Validation accuracy score\n",
      "\t0.93s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.9623\t = Validation accuracy score\n",
      "\t6.17s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9555\t = Validation accuracy score\n",
      "\t1.17s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9623\t = Validation accuracy score\n",
      "\t0.32s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 12.08s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010021/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010021/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 239\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t9 unique label values:  ['2', '1', '4', '0', '5', '8', '6', '3', '7']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 6 out of 9 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9897260273972602\n",
      "Train Data Class Count: 6\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16373.28 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.77 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_70', 'train_74', 'train_78', 'train_79', 'train_83', 'train_84', 'train_85', 'train_86', 'train_87', 'train_91', 'train_92', 'train_96', 'train_101', 'train_102', 'train_108', 'train_112', 'train_113', 'train_116', 'train_120', 'train_125', 'train_129', 'train_133', 'train_140', 'train_145', 'train_146', 'train_147', 'train_148', 'train_152', 'train_156', 'train_161', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_169', 'train_170', 'train_173', 'train_174', 'train_175', 'train_176', 'train_179', 'train_180', 'train_184', 'train_197', 'train_198', 'train_207', 'train_210', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_220', 'train_224', 'train_227', 'train_228', 'train_229', 'train_230', 'train_235']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Condition1_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t166 features in original data used to generate 166 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.93 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.872\t = Validation accuracy score\n",
      "\t4.33s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.8685\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.872\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.872\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.872\t = Validation accuracy score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.8754\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.872\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.872\t = Validation accuracy score\n",
      "\t1.18s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.8754\t = Validation accuracy score\n",
      "\t1.31s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.872\t = Validation accuracy score\n",
      "\t2.73s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.8754\t = Validation accuracy score\n",
      "\t3.97s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.8754\t = Validation accuracy score\n",
      "\t0.25s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 16.61s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010038/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010038/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 239\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t8 unique label values:  ['2', '0', '7', '1', '4', '3', '6', '5']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Updated label_count_threshold from 10 to 6 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 6 examples. AutoGluon will only keep 2 out of 8 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 6 examples that will be kept for training models: 0.9938356164383562\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16470.11 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.79 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Condition1_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition1_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition1_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition2_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 72): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_78', 'train_79', 'train_83', 'train_84', 'train_85', 'train_86', 'train_87', 'train_91', 'train_92', 'train_96', 'train_101', 'train_102', 'train_108', 'train_112', 'train_113', 'train_116', 'train_120', 'train_125', 'train_129', 'train_133', 'train_140', 'train_145', 'train_146', 'train_147', 'train_148', 'train_152', 'train_156', 'train_161', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_169', 'train_170', 'train_173', 'train_174', 'train_175', 'train_176', 'train_179', 'train_180', 'train_184', 'train_197', 'train_198', 'train_207', 'train_210', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_220', 'train_224', 'train_227', 'train_228', 'train_229', 'train_230', 'train_235']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t167 features in original data used to generate 167 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.95 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.43s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.44s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.33s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.33s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.26s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.24s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.76s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t4.59s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.63s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.33s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 9.5s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010047/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010047/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (8.672337598563445, -0.3592018228542554, 0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16400.43 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_173', 'train_174', 'train_177', 'train_178', 'train_179', 'train_180', 'train_183', 'train_184', 'train_188', 'train_201', 'train_202', 'train_211', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Condition2_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition2_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition2_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  EnclosedPorch_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.7955\t = Validation root_mean_squared_error score\n",
      "\t0.68s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.7701\t = Validation root_mean_squared_error score\n",
      "\t0.55s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.8511\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.8528\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.7165\t = Validation root_mean_squared_error score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.7192\t = Validation root_mean_squared_error score\n",
      "\t0.66s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.7179\t = Validation root_mean_squared_error score\n",
      "\t1.14s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.7434\t = Validation root_mean_squared_error score\n",
      "\t6.37s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.7675\t = Validation root_mean_squared_error score\n",
      "\t1.21s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.6828\t = Validation root_mean_squared_error score\n",
      "\t0.36s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 12.19s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010059/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010059/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t5 unique label values:  ['4', '2', '1', '3', '0']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 3 out of 5 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9972602739726028\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16321.96 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  ExterCond_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 73): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_113', 'train_117', 'train_118', 'train_121', 'train_126', 'train_130', 'train_134', 'train_141', 'train_146', 'train_147', 'train_148', 'train_149', 'train_153', 'train_157', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_170', 'train_171', 'train_174', 'train_175', 'train_176', 'train_177', 'train_180', 'train_181', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t167 features in original data used to generate 167 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.96 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.8904\t = Validation accuracy score\n",
      "\t8.0s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.8836\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.8836\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.8801\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.8801\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.8801\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.8801\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.8904\t = Validation accuracy score\n",
      "\t0.97s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9041\t = Validation accuracy score\n",
      "\t1.11s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.8801\t = Validation accuracy score\n",
      "\t1.51s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.8801\t = Validation accuracy score\n",
      "\t2.67s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9041\t = Validation accuracy score\n",
      "\t0.25s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 17.32s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010117/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010117/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t4 unique label values:  ['2', '3', '0', '1']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16101.27 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 72): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_113', 'train_117', 'train_121', 'train_126', 'train_130', 'train_134', 'train_141', 'train_146', 'train_147', 'train_148', 'train_149', 'train_153', 'train_157', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_170', 'train_171', 'train_174', 'train_175', 'train_176', 'train_177', 'train_180', 'train_181', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  ExterCond_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ExterCond_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ExterQual_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t168 features in original data used to generate 168 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.8664\t = Validation accuracy score\n",
      "\t6.29s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.8356\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.839\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.8767\t = Validation accuracy score\n",
      "\t0.49s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.8801\t = Validation accuracy score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.8801\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.887\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.8836\t = Validation accuracy score\n",
      "\t1.16s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.8836\t = Validation accuracy score\n",
      "\t1.47s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.8836\t = Validation accuracy score\n",
      "\t2.03s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.8767\t = Validation accuracy score\n",
      "\t3.78s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.8904\t = Validation accuracy score\n",
      "\t0.28s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 18.04s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010135/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010135/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 239\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 15) unique label values:  ['12', '8', '13', '6', '3', '14', '5', '9', '0', '11']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 10 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9952054794520548\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16125.71 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.79 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  ExterQual_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ExterQual_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior1st_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 73): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_102', 'train_108', 'train_112', 'train_113', 'train_116', 'train_120', 'train_125', 'train_129', 'train_133', 'train_140', 'train_145', 'train_146', 'train_147', 'train_148', 'train_152', 'train_156', 'train_161', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_169', 'train_170', 'train_173', 'train_174', 'train_175', 'train_176', 'train_179', 'train_180', 'train_184', 'train_197', 'train_198', 'train_207', 'train_210', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_220', 'train_224', 'train_227', 'train_228', 'train_229', 'train_230', 'train_235']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t166 features in original data used to generate 166 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.94 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.8316\t = Validation accuracy score\n",
      "\t11.68s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.5739\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.5773\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.8557\t = Validation accuracy score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.8419\t = Validation accuracy score\n",
      "\t0.49s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.8763\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.8694\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.8935\t = Validation accuracy score\n",
      "\t2.17s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.89\t = Validation accuracy score\n",
      "\t2.12s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.8969\t = Validation accuracy score\n",
      "\t6.9s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.8935\t = Validation accuracy score\n",
      "\t9.55s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9038\t = Validation accuracy score\n",
      "\t0.33s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 36.28s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010211/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010211/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 238\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 16) unique label values:  ['13', '8', '15', '6', '10', '14', '5', '3', '12', '0']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 11 out of 16 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9883561643835617\n",
      "Train Data Class Count: 11\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16311.58 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.76 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Exterior1st_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior1st_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior1st_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 72): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_107', 'train_111', 'train_112', 'train_115', 'train_119', 'train_124', 'train_128', 'train_132', 'train_139', 'train_144', 'train_145', 'train_146', 'train_147', 'train_151', 'train_155', 'train_160', 'train_161', 'train_162', 'train_163', 'train_164', 'train_165', 'train_168', 'train_169', 'train_172', 'train_173', 'train_174', 'train_175', 'train_178', 'train_179', 'train_183', 'train_196', 'train_197', 'train_206', 'train_209', 'train_210', 'train_211', 'train_212', 'train_213', 'train_214', 'train_219', 'train_223', 'train_226', 'train_227', 'train_228', 'train_229', 'train_234']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t166 features in original data used to generate 166 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.93 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.8097\t = Validation accuracy score\n",
      "\t7.84s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.5329\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.5502\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.8685\t = Validation accuracy score\n",
      "\t0.49s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.8616\t = Validation accuracy score\n",
      "\t0.5s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.8754\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.8685\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.8893\t = Validation accuracy score\n",
      "\t1.91s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9031\t = Validation accuracy score\n",
      "\t1.8s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9135\t = Validation accuracy score\n",
      "\t2.76s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.8858\t = Validation accuracy score\n",
      "\t10.23s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9135\t = Validation accuracy score\n",
      "\t0.32s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 28.45s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010240/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010240/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (3.7026690890841065, -0.9509006699369512, 0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16376.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Exterior2nd_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_4\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Fireplaces_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_173', 'train_174', 'train_177', 'train_178', 'train_179', 'train_180', 'train_183', 'train_184', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.3918\t = Validation root_mean_squared_error score\n",
      "\t0.6s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.408\t = Validation root_mean_squared_error score\n",
      "\t0.45s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.7756\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.7726\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.4023\t = Validation root_mean_squared_error score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.4095\t = Validation root_mean_squared_error score\n",
      "\t0.51s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.3904\t = Validation root_mean_squared_error score\n",
      "\t1.46s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.5053\t = Validation root_mean_squared_error score\n",
      "\t11.89s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.3971\t = Validation root_mean_squared_error score\n",
      "\t1.24s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.3868\t = Validation root_mean_squared_error score\n",
      "\t0.34s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 17.78s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010258/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010258/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t6 unique label values:  ['2', '1', '0', '5', '3', '4']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 4 out of 6 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9938356164383562\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16558.96 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.8 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_113', 'train_117', 'train_118', 'train_121', 'train_126', 'train_130', 'train_134', 'train_141', 'train_146', 'train_147', 'train_148', 'train_149', 'train_153', 'train_157', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_170', 'train_171', 'train_174', 'train_175', 'train_176', 'train_177', 'train_180', 'train_181', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t167 features in original data used to generate 167 features in processed data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Foundation_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTrain Data (Processed) Memory Usage: 1.95 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.8316\t = Validation accuracy score\n",
      "\t5.68s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.8213\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.811\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.8488\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.8522\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.8247\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.8385\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.8557\t = Validation accuracy score\n",
      "\t1.09s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.8557\t = Validation accuracy score\n",
      "\t0.99s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.8694\t = Validation accuracy score\n",
      "\t2.08s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.8454\t = Validation accuracy score\n",
      "\t3.74s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.8694\t = Validation accuracy score\n",
      "\t0.25s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 16.71s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010314/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010314/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (2.6046294251774866, -2.8408488002532493, 0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16464.55 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Foundation_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Foundation_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  FullBath_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.6145\t = Validation root_mean_squared_error score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.6496\t = Validation root_mean_squared_error score\n",
      "\t0.52s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.763\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.7613\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.6225\t = Validation root_mean_squared_error score\n",
      "\t0.49s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.6413\t = Validation root_mean_squared_error score\n",
      "\t0.46s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.6276\t = Validation root_mean_squared_error score\n",
      "\t1.9s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.7171\t = Validation root_mean_squared_error score\n",
      "\t15.78s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.6239\t = Validation root_mean_squared_error score\n",
      "\t2.1s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.6016\t = Validation root_mean_squared_error score\n",
      "\t0.34s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 23.06s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010337/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010337/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t7 unique label values:  ['6', '2', '0', '3', '4', '1', '5']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 5 out of 7 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9958904109589041\n",
      "Train Data Class Count: 5\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16492.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.8 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_113', 'train_117', 'train_118', 'train_121', 'train_125', 'train_130', 'train_134', 'train_138', 'train_145', 'train_150', 'train_151', 'train_152', 'train_153', 'train_157', 'train_161', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_171', 'train_174', 'train_175', 'train_178', 'train_179', 'train_180', 'train_181', 'train_184', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t167 features in original data used to generate 167 features in processed data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Functional_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTrain Data (Processed) Memory Usage: 1.95 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.9347\t = Validation accuracy score\n",
      "\t4.3s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.9381\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.9381\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9381\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.9381\t = Validation accuracy score\n",
      "\t0.46s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.9381\t = Validation accuracy score\n",
      "\t0.36s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.9381\t = Validation accuracy score\n",
      "\t0.36s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9381\t = Validation accuracy score\n",
      "\t0.9s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9381\t = Validation accuracy score\n",
      "\t0.89s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9381\t = Validation accuracy score\n",
      "\t4.66s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9381\t = Validation accuracy score\n",
      "\t3.05s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9381\t = Validation accuracy score\n",
      "\t0.24s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 16.79s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010354/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010354/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (4.420011523545205, -2.212204989237499, 0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16900.99 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_173', 'train_174', 'train_177', 'train_178', 'train_179', 'train_180', 'train_183', 'train_184', 'train_188', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Functional_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Functional_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4819\t = Validation root_mean_squared_error score\n",
      "\t0.76s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.506\t = Validation root_mean_squared_error score\n",
      "\t0.69s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.6732\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.6695\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.491\t = Validation root_mean_squared_error score\n",
      "\t0.64s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.4847\t = Validation root_mean_squared_error score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.474\t = Validation root_mean_squared_error score\n",
      "\t1.7s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.5646\t = Validation root_mean_squared_error score\n",
      "\t6.16s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.4934\t = Validation root_mean_squared_error score\n",
      "\t1.67s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.4709\t = Validation root_mean_squared_error score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 13.25s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010408/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010408/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (2.9878654678657948, -2.364629726102377, -0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16799.92 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_173', 'train_174', 'train_177', 'train_178', 'train_179', 'train_180', 'train_183', 'train_184', 'train_188', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  GarageCars_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.2981\t = Validation root_mean_squared_error score\n",
      "\t0.58s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.2726\t = Validation root_mean_squared_error score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.5629\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.5617\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.2895\t = Validation root_mean_squared_error score\n",
      "\t0.44s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.3155\t = Validation root_mean_squared_error score\n",
      "\t0.55s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.2836\t = Validation root_mean_squared_error score\n",
      "\t1.58s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.4112\t = Validation root_mean_squared_error score\n",
      "\t13.45s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.2916\t = Validation root_mean_squared_error score\n",
      "\t1.48s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.2682\t = Validation root_mean_squared_error score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 19.64s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010427/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010427/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (7.852883630950883, -2.2483497688982794, -0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16721.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  GrLivArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.3718\t = Validation root_mean_squared_error score\n",
      "\t0.73s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.3522\t = Validation root_mean_squared_error score\n",
      "\t0.7s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.5923\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.5894\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain_set's rmse: 0.00590361\tvalid_set's rmse: 0.283916\n",
      "[2000]\ttrain_set's rmse: 0.000524703\tvalid_set's rmse: 0.278467\n",
      "[3000]\ttrain_set's rmse: 2.19668e-05\tvalid_set's rmse: 0.278158\n",
      "[4000]\ttrain_set's rmse: 2.02069e-06\tvalid_set's rmse: 0.278152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.2782\t = Validation root_mean_squared_error score\n",
      "\t5.71s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain_set's rmse: 0.00310778\tvalid_set's rmse: 0.300898\n",
      "[2000]\ttrain_set's rmse: 0.000283879\tvalid_set's rmse: 0.299449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.2994\t = Validation root_mean_squared_error score\n",
      "\t3.09s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.264\t = Validation root_mean_squared_error score\n",
      "\t5.36s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.2091\t = Validation root_mean_squared_error score\n",
      "\t24.14s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.304\t = Validation root_mean_squared_error score\n",
      "\t2.01s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.2051\t = Validation root_mean_squared_error score\n",
      "\t0.29s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 43.38s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010511/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010511/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 241\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t3 unique label values:  ['1', '0', '2']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16615.06 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_113', 'train_117', 'train_118', 'train_121', 'train_125', 'train_130', 'train_134', 'train_138', 'train_145', 'train_150', 'train_151', 'train_152', 'train_153', 'train_157', 'train_161', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_171', 'train_174', 'train_175', 'train_176', 'train_177', 'train_178', 'train_181', 'train_182', 'train_186', 'train_199', 'train_200', 'train_209', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_222', 'train_226', 'train_229', 'train_230', 'train_231', 'train_232', 'train_237']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t168 features in original data used to generate 168 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  HalfBath_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.8801\t = Validation accuracy score\n",
      "\t5.29s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.8356\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.8322\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.8596\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.8699\t = Validation accuracy score\n",
      "\t0.46s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.8562\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.8527\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.8938\t = Validation accuracy score\n",
      "\t0.96s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.8801\t = Validation accuracy score\n",
      "\t0.84s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.8801\t = Validation accuracy score\n",
      "\t2.63s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.8767\t = Validation accuracy score\n",
      "\t3.49s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.8938\t = Validation accuracy score\n",
      "\t0.24s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 16.36s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010527/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010527/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t5 unique label values:  ['0', '2', '4', '1', '3']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 4 out of 5 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9993150684931507\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16885.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_113', 'train_117', 'train_118', 'train_121', 'train_125', 'train_130', 'train_134', 'train_138', 'train_145', 'train_150', 'train_151', 'train_152', 'train_153', 'train_157', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_170', 'train_171', 'train_174', 'train_175', 'train_176', 'train_177', 'train_180', 'train_181', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t167 features in original data used to generate 167 features in processed data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  HalfBath_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HeatingQC_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTrain Data (Processed) Memory Usage: 1.96 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.6404\t = Validation accuracy score\n",
      "\t5.54s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.6267\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.6199\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.6644\t = Validation accuracy score\n",
      "\t0.49s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.661\t = Validation accuracy score\n",
      "\t0.49s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.6712\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.6678\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.6575\t = Validation accuracy score\n",
      "\t1.33s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.6815\t = Validation accuracy score\n",
      "\t1.3s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.6747\t = Validation accuracy score\n",
      "\t3.17s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.637\t = Validation accuracy score\n",
      "\t4.99s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.6884\t = Validation accuracy score\n",
      "\t0.27s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 19.69s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010547/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010547/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t6 unique label values:  ['1', '2', '3', '5', '4', '0']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 2 out of 6 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9904109589041096\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16798.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.79 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  HeatingQC_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HeatingQC_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Heating_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 73): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_113', 'train_117', 'train_118', 'train_121', 'train_125', 'train_130', 'train_134', 'train_138', 'train_145', 'train_150', 'train_151', 'train_152', 'train_153', 'train_157', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_170', 'train_171', 'train_174', 'train_175', 'train_176', 'train_177', 'train_180', 'train_181', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t167 features in original data used to generate 167 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.94 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9862\t = Validation accuracy score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.9862\t = Validation accuracy score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.9862\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.9862\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.9862\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.9862\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9897\t = Validation accuracy score\n",
      "\t0.32s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9862\t = Validation accuracy score\n",
      "\t0.44s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9862\t = Validation accuracy score\n",
      "\t0.89s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.9862\t = Validation accuracy score\n",
      "\t4.75s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9862\t = Validation accuracy score\n",
      "\t0.61s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9897\t = Validation accuracy score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 10.16s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010557/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010557/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 239\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t8 unique label values:  ['5', '2', '0', '1', '6', '7', '4', '3']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 7 out of 8 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9945205479452055\n",
      "Train Data Class Count: 7\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16821.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.79 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Heating_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Heating_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HouseStyle_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 72): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_85', 'train_86', 'train_87', 'train_91', 'train_92', 'train_96', 'train_101', 'train_102', 'train_108', 'train_112', 'train_113', 'train_116', 'train_120', 'train_125', 'train_129', 'train_133', 'train_140', 'train_145', 'train_146', 'train_147', 'train_148', 'train_152', 'train_156', 'train_161', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_169', 'train_170', 'train_173', 'train_174', 'train_175', 'train_176', 'train_179', 'train_180', 'train_184', 'train_197', 'train_198', 'train_207', 'train_210', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_220', 'train_224', 'train_227', 'train_228', 'train_229', 'train_230', 'train_235']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t167 features in original data used to generate 167 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.95 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.8866\t = Validation accuracy score\n",
      "\t7.02s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.8144\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.8179\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9038\t = Validation accuracy score\n",
      "\t0.49s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.9072\t = Validation accuracy score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.9003\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.89\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9691\t = Validation accuracy score\n",
      "\t1.24s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9588\t = Validation accuracy score\n",
      "\t1.55s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9622\t = Validation accuracy score\n",
      "\t6.58s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9656\t = Validation accuracy score\n",
      "\t5.43s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9691\t = Validation accuracy score\n",
      "\t0.3s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 25.44s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010622/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010622/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (8.865574248408814, -4.749858853986208, 0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16641.3 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_173', 'train_174', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  HouseStyle_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HouseStyle_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HouseStyle_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  KitchenAbvGr_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.4461\t = Validation root_mean_squared_error score\n",
      "\t0.57s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.385\t = Validation root_mean_squared_error score\n",
      "\t0.45s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.5123\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.5063\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.4065\t = Validation root_mean_squared_error score\n",
      "\t0.45s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.4142\t = Validation root_mean_squared_error score\n",
      "\t0.89s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.361\t = Validation root_mean_squared_error score\n",
      "\t1.71s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.5837\t = Validation root_mean_squared_error score\n",
      "\t9.39s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.4075\t = Validation root_mean_squared_error score\n",
      "\t1.25s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.3384\t = Validation root_mean_squared_error score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 15.91s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010638/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010638/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t4 unique label values:  ['2', '3', '0', '1']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16602.63 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  KitchenQual_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 72): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_113', 'train_117', 'train_118', 'train_121', 'train_125', 'train_130', 'train_134', 'train_138', 'train_145', 'train_150', 'train_151', 'train_152', 'train_153', 'train_157', 'train_161', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_171', 'train_174', 'train_175', 'train_178', 'train_179', 'train_180', 'train_181', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t168 features in original data used to generate 168 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.8082\t = Validation accuracy score\n",
      "\t5.44s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.7671\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.774\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.7979\t = Validation accuracy score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.8116\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.8151\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.8151\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.7979\t = Validation accuracy score\n",
      "\t1.24s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.8219\t = Validation accuracy score\n",
      "\t1.39s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.7945\t = Validation accuracy score\n",
      "\t2.39s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.7911\t = Validation accuracy score\n",
      "\t3.71s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.8253\t = Validation accuracy score\n",
      "\t0.27s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 17.4s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010656/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010656/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t4 unique label values:  ['3', '0', '2', '1']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16530.45 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  KitchenQual_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  KitchenQual_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LandContour_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 72): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_56', 'train_59', 'train_65', 'train_70', 'train_71', 'train_75', 'train_79', 'train_80', 'train_84', 'train_85', 'train_86', 'train_87', 'train_88', 'train_92', 'train_93', 'train_97', 'train_102', 'train_103', 'train_109', 'train_113', 'train_114', 'train_117', 'train_121', 'train_126', 'train_130', 'train_134', 'train_141', 'train_146', 'train_147', 'train_148', 'train_149', 'train_153', 'train_157', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_170', 'train_171', 'train_174', 'train_175', 'train_176', 'train_177', 'train_180', 'train_181', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t168 features in original data used to generate 168 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.911\t = Validation accuracy score\n",
      "\t7.69s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.8904\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.887\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9007\t = Validation accuracy score\n",
      "\t0.51s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.8973\t = Validation accuracy score\n",
      "\t0.51s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.9041\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.9041\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9075\t = Validation accuracy score\n",
      "\t1.11s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9178\t = Validation accuracy score\n",
      "\t1.25s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9075\t = Validation accuracy score\n",
      "\t2.73s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9212\t = Validation accuracy score\n",
      "\t4.2s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9212\t = Validation accuracy score\n",
      "\t0.28s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 20.54s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010716/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010716/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 241\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t3 unique label values:  ['0', '1', '2']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16448.48 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  LandContour_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LandContour_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LandSlope_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 73): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_66', 'train_71', 'train_72', 'train_76', 'train_80', 'train_81', 'train_85', 'train_86', 'train_87', 'train_88', 'train_89', 'train_93', 'train_94', 'train_98', 'train_103', 'train_104', 'train_110', 'train_114', 'train_115', 'train_118', 'train_122', 'train_127', 'train_131', 'train_135', 'train_142', 'train_147', 'train_148', 'train_149', 'train_150', 'train_154', 'train_158', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_168', 'train_171', 'train_172', 'train_175', 'train_176', 'train_177', 'train_178', 'train_181', 'train_182', 'train_186', 'train_199', 'train_200', 'train_209', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_222', 'train_226', 'train_229', 'train_230', 'train_231', 'train_232', 'train_237']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t168 features in original data used to generate 168 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.9555\t = Validation accuracy score\n",
      "\t7.81s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.9452\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.9452\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9452\t = Validation accuracy score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.9452\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.9486\t = Validation accuracy score\n",
      "\t0.36s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.9486\t = Validation accuracy score\n",
      "\t0.36s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9486\t = Validation accuracy score\n",
      "\t0.76s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9555\t = Validation accuracy score\n",
      "\t1.0s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9521\t = Validation accuracy score\n",
      "\t2.8s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9452\t = Validation accuracy score\n",
      "\t1.83s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9623\t = Validation accuracy score\n",
      "\t0.25s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 17.3s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010734/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010734/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (20.511245148264887, -0.923412828397377, -0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16444.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_45', 'train_46', 'train_49', 'train_50', 'train_53', 'train_54', 'train_58', 'train_61', 'train_67', 'train_72', 'train_73', 'train_77', 'train_81', 'train_82', 'train_86', 'train_87', 'train_88', 'train_89', 'train_90', 'train_94', 'train_95', 'train_99', 'train_104', 'train_105', 'train_111', 'train_115', 'train_116', 'train_119', 'train_123', 'train_128', 'train_132', 'train_136', 'train_143', 'train_148', 'train_149', 'train_150', 'train_151', 'train_155', 'train_159', 'train_164', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  LandSlope_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4916\t = Validation root_mean_squared_error score\n",
      "\t0.9s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.4182\t = Validation root_mean_squared_error score\n",
      "\t0.86s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.542\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.538\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.3965\t = Validation root_mean_squared_error score\n",
      "\t0.58s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.3947\t = Validation root_mean_squared_error score\n",
      "\t0.56s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.3951\t = Validation root_mean_squared_error score\n",
      "\t5.42s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.7255\t = Validation root_mean_squared_error score\n",
      "\t5.01s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.3891\t = Validation root_mean_squared_error score\n",
      "\t1.81s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.3608\t = Validation root_mean_squared_error score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 16.47s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010750/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010750/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t5 unique label values:  ['4', '2', '0', '1', '3']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 4 out of 5 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9972602739726028\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16391.96 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  LotConfig_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 73): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_59', 'train_65', 'train_70', 'train_71', 'train_75', 'train_79', 'train_80', 'train_84', 'train_85', 'train_86', 'train_87', 'train_88', 'train_92', 'train_93', 'train_97', 'train_102', 'train_103', 'train_109', 'train_113', 'train_114', 'train_117', 'train_121', 'train_126', 'train_130', 'train_134', 'train_141', 'train_146', 'train_147', 'train_148', 'train_149', 'train_153', 'train_157', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_170', 'train_171', 'train_174', 'train_175', 'train_176', 'train_177', 'train_180', 'train_181', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t167 features in original data used to generate 167 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.96 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.7226\t = Validation accuracy score\n",
      "\t4.67s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.7123\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.7192\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.7158\t = Validation accuracy score\n",
      "\t0.52s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.7192\t = Validation accuracy score\n",
      "\t0.51s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.7158\t = Validation accuracy score\n",
      "\t0.4s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.7158\t = Validation accuracy score\n",
      "\t0.41s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.7603\t = Validation accuracy score\n",
      "\t1.84s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.7397\t = Validation accuracy score\n",
      "\t2.03s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.7397\t = Validation accuracy score\n",
      "\t3.17s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.7637\t = Validation accuracy score\n",
      "\t4.96s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.7637\t = Validation accuracy score\n",
      "\t0.28s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 20.4s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010811/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010811/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t4 unique label values:  ['3', '0', '1', '2']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16298.79 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  LotConfig_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotConfig_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotShape_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 72): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_56', 'train_59', 'train_65', 'train_70', 'train_71', 'train_75', 'train_79', 'train_80', 'train_84', 'train_85', 'train_86', 'train_87', 'train_88', 'train_92', 'train_93', 'train_97', 'train_102', 'train_103', 'train_109', 'train_113', 'train_114', 'train_117', 'train_121', 'train_126', 'train_130', 'train_134', 'train_141', 'train_146', 'train_147', 'train_148', 'train_149', 'train_153', 'train_157', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_170', 'train_171', 'train_174', 'train_175', 'train_176', 'train_177', 'train_180', 'train_181', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t168 features in original data used to generate 168 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.75\t = Validation accuracy score\n",
      "\t6.53s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.6438\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.6404\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.7363\t = Validation accuracy score\n",
      "\t0.52s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.7603\t = Validation accuracy score\n",
      "\t0.52s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.7534\t = Validation accuracy score\n",
      "\t0.4s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.7534\t = Validation accuracy score\n",
      "\t0.4s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.7603\t = Validation accuracy score\n",
      "\t1.24s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.7534\t = Validation accuracy score\n",
      "\t1.32s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.7671\t = Validation accuracy score\n",
      "\t2.77s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.7568\t = Validation accuracy score\n",
      "\t3.73s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.7705\t = Validation accuracy score\n",
      "\t0.27s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 18.98s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010830/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010830/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (11.643759769239269, -0.12020053800860488, 0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16234.03 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  LotShape_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotShape_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LowQualFinSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.7185\t = Validation root_mean_squared_error score\n",
      "\t0.64s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.6825\t = Validation root_mean_squared_error score\n",
      "\t0.57s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.7074\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.7098\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.5428\t = Validation root_mean_squared_error score\n",
      "\t0.94s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.6139\t = Validation root_mean_squared_error score\n",
      "\t0.44s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.4772\t = Validation root_mean_squared_error score\n",
      "\t5.89s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.6311\t = Validation root_mean_squared_error score\n",
      "\t5.08s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.6342\t = Validation root_mean_squared_error score\n",
      "\t1.0s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.464\t = Validation root_mean_squared_error score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 15.71s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010845/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010845/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (3.1465943981111675, -0.8722638821913684, -0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16591.9 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_42', 'train_43', 'train_45', 'train_46', 'train_49', 'train_50', 'train_53', 'train_54', 'train_58', 'train_61', 'train_67', 'train_72', 'train_73', 'train_77', 'train_81', 'train_82', 'train_86', 'train_87', 'train_88', 'train_89', 'train_90', 'train_94', 'train_95', 'train_99', 'train_104', 'train_105', 'train_111', 'train_115', 'train_116', 'train_119', 'train_123', 'train_128', 'train_132', 'train_136', 'train_143', 'train_148', 'train_149', 'train_150', 'train_151', 'train_155', 'train_159', 'train_164', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  MSSubClass_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.26\t = Validation root_mean_squared_error score\n",
      "\t0.61s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.2774\t = Validation root_mean_squared_error score\n",
      "\t0.54s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.5017\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.4933\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.2565\t = Validation root_mean_squared_error score\n",
      "\t0.6s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.2465\t = Validation root_mean_squared_error score\n",
      "\t0.55s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.2617\t = Validation root_mean_squared_error score\n",
      "\t1.11s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.3097\t = Validation root_mean_squared_error score\n",
      "\t19.57s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.2574\t = Validation root_mean_squared_error score\n",
      "\t1.59s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.2112\t = Validation root_mean_squared_error score\n",
      "\t0.3s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 25.65s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010911/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010911/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t5 unique label values:  ['3', '4', '0', '1', '2']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 5\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16531.99 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_38', 'train_40', 'train_41', 'train_43', 'train_44', 'train_47', 'train_48', 'train_51', 'train_52', 'train_56', 'train_59', 'train_65', 'train_70', 'train_71', 'train_75', 'train_79', 'train_80', 'train_84', 'train_85', 'train_86', 'train_87', 'train_88', 'train_92', 'train_93', 'train_97', 'train_102', 'train_103', 'train_109', 'train_113', 'train_114', 'train_117', 'train_121', 'train_126', 'train_130', 'train_134', 'train_141', 'train_146', 'train_147', 'train_148', 'train_149', 'train_153', 'train_157', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_170', 'train_171', 'train_174', 'train_175', 'train_176', 'train_177', 'train_180', 'train_181', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t167 features in original data used to generate 167 features in processed data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  MSZoning_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTrain Data (Processed) Memory Usage: 1.96 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.911\t = Validation accuracy score\n",
      "\t7.4s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.8493\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.8493\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.8973\t = Validation accuracy score\n",
      "\t0.46s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.911\t = Validation accuracy score\n",
      "\t0.45s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.9144\t = Validation accuracy score\n",
      "\t0.36s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.9178\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9281\t = Validation accuracy score\n",
      "\t0.97s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9384\t = Validation accuracy score\n",
      "\t1.23s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9315\t = Validation accuracy score\n",
      "\t6.82s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9144\t = Validation accuracy score\n",
      "\t3.49s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9418\t = Validation accuracy score\n",
      "\t0.25s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 22.96s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010934/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010934/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (31.15459310882023, -0.08765777630136591, -0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16401.42 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_173', 'train_174', 'train_177', 'train_178', 'train_179', 'train_180', 'train_183', 'train_184', 'train_188', 'train_201', 'train_202', 'train_211', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_219', 'train_224', 'train_228', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  MSZoning_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MSZoning_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MiscVal_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.2086\t = Validation root_mean_squared_error score\n",
      "\t0.46s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.2343\t = Validation root_mean_squared_error score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.4911\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.4854\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.1948\t = Validation root_mean_squared_error score\n",
      "\t0.32s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.1993\t = Validation root_mean_squared_error score\n",
      "\t0.32s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.2156\t = Validation root_mean_squared_error score\n",
      "\t1.04s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.2975\t = Validation root_mean_squared_error score\n",
      "\t4.59s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.246\t = Validation root_mean_squared_error score\n",
      "\t0.88s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.1867\t = Validation root_mean_squared_error score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 9.12s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010943/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010943/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (2.1001727880223924, -1.9684369798472843, 0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16323.83 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_173', 'train_174', 'train_177', 'train_178', 'train_179', 'train_180', 'train_183', 'train_184', 'train_188', 'train_201', 'train_202', 'train_211', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_219', 'train_224', 'train_228', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  MoSold_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.9393\t = Validation root_mean_squared_error score\n",
      "\t0.78s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.9801\t = Validation root_mean_squared_error score\n",
      "\t0.73s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-1.0428\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-1.0494\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.9312\t = Validation root_mean_squared_error score\n",
      "\t0.43s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.9545\t = Validation root_mean_squared_error score\n",
      "\t0.45s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.9365\t = Validation root_mean_squared_error score\n",
      "\t0.77s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.9724\t = Validation root_mean_squared_error score\n",
      "\t4.53s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.9376\t = Validation root_mean_squared_error score\n",
      "\t1.38s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.9249\t = Validation root_mean_squared_error score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 10.19s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_010954/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_010954/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 238\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 25) unique label values:  ['5', '24', '6', '15', '11', '21', '14', '17', '3', '19']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 23 out of 25 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9924657534246575\n",
      "Train Data Class Count: 23\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16252.07 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.77 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Neighborhood_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 73): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_68', 'train_69', 'train_73', 'train_77', 'train_78', 'train_82', 'train_83', 'train_84', 'train_85', 'train_86', 'train_90', 'train_91', 'train_95', 'train_100', 'train_101', 'train_107', 'train_111', 'train_112', 'train_115', 'train_119', 'train_124', 'train_128', 'train_132', 'train_139', 'train_144', 'train_145', 'train_146', 'train_147', 'train_151', 'train_155', 'train_160', 'train_161', 'train_162', 'train_163', 'train_164', 'train_165', 'train_168', 'train_169', 'train_172', 'train_173', 'train_174', 'train_175', 'train_178', 'train_179', 'train_183', 'train_196', 'train_197', 'train_206', 'train_209', 'train_210', 'train_211', 'train_212', 'train_213', 'train_214', 'train_219', 'train_223', 'train_226', 'train_227', 'train_228', 'train_229', 'train_234']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 165 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 165 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t165 features in original data used to generate 165 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.92 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.5276\t = Validation accuracy score\n",
      "\t6.05s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.4586\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.4655\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.5931\t = Validation accuracy score\n",
      "\t0.51s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.5897\t = Validation accuracy score\n",
      "\t0.53s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.5862\t = Validation accuracy score\n",
      "\t0.41s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.5897\t = Validation accuracy score\n",
      "\t0.42s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.6793\t = Validation accuracy score\n",
      "\t4.07s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.6276\t = Validation accuracy score\n",
      "\t4.85s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.6655\t = Validation accuracy score\n",
      "\t18.06s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.6517\t = Validation accuracy score\n",
      "\t19.45s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.6862\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 57.48s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_011051/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_011051/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (7.551610677132842, -0.7042419476205177, 0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16445.35 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_173', 'train_174', 'train_177', 'train_178', 'train_179', 'train_180', 'train_183', 'train_184', 'train_188', 'train_201', 'train_202', 'train_211', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Neighborhood_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_4\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  OpenPorchSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.8258\t = Validation root_mean_squared_error score\n",
      "\t0.98s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.8797\t = Validation root_mean_squared_error score\n",
      "\t0.86s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.8334\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.8288\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.8119\t = Validation root_mean_squared_error score\n",
      "\t0.66s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.8017\t = Validation root_mean_squared_error score\n",
      "\t0.64s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.809\t = Validation root_mean_squared_error score\n",
      "\t1.65s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.8648\t = Validation root_mean_squared_error score\n",
      "\t12.48s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.8453\t = Validation root_mean_squared_error score\n",
      "\t1.77s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.7819\t = Validation root_mean_squared_error score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 20.26s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_011111/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_011111/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (3.077515793964418, -4.111561100736462, 0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16259.78 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_94', 'train_95', 'train_99', 'train_104', 'train_105', 'train_111', 'train_115', 'train_116', 'train_119', 'train_123', 'train_128', 'train_132', 'train_136', 'train_143', 'train_148', 'train_149', 'train_150', 'train_151', 'train_155', 'train_159', 'train_164', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  OverallCond_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.7008\t = Validation root_mean_squared_error score\n",
      "\t0.75s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.8009\t = Validation root_mean_squared_error score\n",
      "\t0.65s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.9007\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.8989\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.7078\t = Validation root_mean_squared_error score\n",
      "\t0.76s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.7334\t = Validation root_mean_squared_error score\n",
      "\t0.61s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.6755\t = Validation root_mean_squared_error score\n",
      "\t1.5s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.8709\t = Validation root_mean_squared_error score\n",
      "\t5.74s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.7203\t = Validation root_mean_squared_error score\n",
      "\t1.92s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.6734\t = Validation root_mean_squared_error score\n",
      "\t0.36s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 13.1s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_011125/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_011125/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (2.820458909096378, -3.6871495308555806, 0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16238.32 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_94', 'train_95', 'train_99', 'train_104', 'train_105', 'train_111', 'train_115', 'train_116', 'train_119', 'train_123', 'train_128', 'train_132', 'train_136', 'train_143', 'train_148', 'train_149', 'train_150', 'train_151', 'train_155', 'train_159', 'train_164', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  OverallQual_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.5109\t = Validation root_mean_squared_error score\n",
      "\t0.72s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.5749\t = Validation root_mean_squared_error score\n",
      "\t0.61s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.5964\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.5944\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.5186\t = Validation root_mean_squared_error score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.5219\t = Validation root_mean_squared_error score\n",
      "\t0.61s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.5115\t = Validation root_mean_squared_error score\n",
      "\t1.65s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.57\t = Validation root_mean_squared_error score\n",
      "\t7.36s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.5226\t = Validation root_mean_squared_error score\n",
      "\t1.86s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.4981\t = Validation root_mean_squared_error score\n",
      "\t0.34s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.5s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_011139/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_011139/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 241\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t3 unique label values:  ['2', '0', '1']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16202.2 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_113', 'train_117', 'train_118', 'train_121', 'train_125', 'train_130', 'train_134', 'train_138', 'train_145', 'train_150', 'train_151', 'train_152', 'train_153', 'train_157', 'train_161', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_171', 'train_174', 'train_175', 'train_178', 'train_179', 'train_180', 'train_181', 'train_184', 'train_185', 'train_189', 'train_202', 'train_203', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_222', 'train_226', 'train_229', 'train_230', 'train_231', 'train_232', 'train_237']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t168 features in original data used to generate 168 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  PavedDrive_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.9247\t = Validation accuracy score\n",
      "\t5.87s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.9144\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.911\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9212\t = Validation accuracy score\n",
      "\t0.49s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.9144\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.9247\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.9247\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9178\t = Validation accuracy score\n",
      "\t0.81s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9212\t = Validation accuracy score\n",
      "\t0.7s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9247\t = Validation accuracy score\n",
      "\t2.3s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9178\t = Validation accuracy score\n",
      "\t2.24s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9247\t = Validation accuracy score\n",
      "\t0.26s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.97s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_011154/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_011154/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (18.299909869656002, -0.06866821893757184, -0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16238.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_173', 'train_174', 'train_177', 'train_178', 'train_179', 'train_180', 'train_183', 'train_184', 'train_188', 'train_201', 'train_202', 'train_211', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  PavedDrive_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  PoolArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.1136\t = Validation root_mean_squared_error score\n",
      "\t0.4s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.1522\t = Validation root_mean_squared_error score\n",
      "\t0.28s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-1.111\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-1.1078\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-1.0415\t = Validation root_mean_squared_error score\n",
      "\t0.44s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-1.0347\t = Validation root_mean_squared_error score\n",
      "\t0.68s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.3992\t = Validation root_mean_squared_error score\n",
      "\t2.24s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-1.0647\t = Validation root_mean_squared_error score\n",
      "\t4.74s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.078\t = Validation root_mean_squared_error score\n",
      "\t1.12s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.0331\t = Validation root_mean_squared_error score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11.06s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_011205/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_011205/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 239\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t8 unique label values:  ['1', '7', '3', '6', '2', '5', '4', '0']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 2 out of 8 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9897260273972602\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16125.79 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.77 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  RoofMatl_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 72): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_101', 'train_102', 'train_108', 'train_112', 'train_113', 'train_116', 'train_120', 'train_125', 'train_129', 'train_133', 'train_140', 'train_145', 'train_146', 'train_147', 'train_148', 'train_152', 'train_156', 'train_161', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_169', 'train_170', 'train_173', 'train_174', 'train_175', 'train_176', 'train_179', 'train_180', 'train_184', 'train_197', 'train_198', 'train_207', 'train_210', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_220', 'train_224', 'train_227', 'train_228', 'train_229', 'train_230', 'train_235']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t167 features in original data used to generate 167 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.94 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9931\t = Validation accuracy score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.9931\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.9931\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.9931\t = Validation accuracy score\n",
      "\t0.36s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.9931\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.9931\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9931\t = Validation accuracy score\n",
      "\t0.54s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9965\t = Validation accuracy score\n",
      "\t0.3s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9862\t = Validation accuracy score\n",
      "\t0.85s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.9931\t = Validation accuracy score\n",
      "\t4.93s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9965\t = Validation accuracy score\n",
      "\t0.74s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9965\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 10.48s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_011216/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_011216/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t6 unique label values:  ['1', '3', '2', '4', '0', '5']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 4 out of 6 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9938356164383562\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16011.3 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.8 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  RoofMatl_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofMatl_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofMatl_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofStyle_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 73): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_93', 'train_97', 'train_102', 'train_103', 'train_109', 'train_113', 'train_114', 'train_117', 'train_121', 'train_126', 'train_130', 'train_134', 'train_141', 'train_146', 'train_147', 'train_148', 'train_149', 'train_153', 'train_157', 'train_162', 'train_163', 'train_164', 'train_165', 'train_166', 'train_167', 'train_170', 'train_171', 'train_174', 'train_175', 'train_176', 'train_177', 'train_180', 'train_181', 'train_185', 'train_198', 'train_199', 'train_208', 'train_211', 'train_212', 'train_213', 'train_214', 'train_215', 'train_216', 'train_221', 'train_225', 'train_228', 'train_229', 'train_230', 'train_231', 'train_236']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t167 features in original data used to generate 167 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.95 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.8041\t = Validation accuracy score\n",
      "\t5.77s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.7732\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.7766\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.8144\t = Validation accuracy score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.8076\t = Validation accuracy score\n",
      "\t0.49s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.8007\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.8076\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.8282\t = Validation accuracy score\n",
      "\t0.8s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.8144\t = Validation accuracy score\n",
      "\t0.73s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.8247\t = Validation accuracy score\n",
      "\t4.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.8282\t = Validation accuracy score\n",
      "\t3.83s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.8282\t = Validation accuracy score\n",
      "\t0.26s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 18.35s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_011234/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_011234/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 240\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t6 unique label values:  ['4', '0', '5', '1', '2', '3']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 5 out of 6 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9972602739726028\n",
      "Train Data Class Count: 5\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15880.35 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  RoofStyle_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofStyle_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleCondition_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 73): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_113', 'train_117', 'train_118', 'train_121', 'train_125', 'train_130', 'train_134', 'train_138', 'train_145', 'train_150', 'train_151', 'train_152', 'train_153', 'train_157', 'train_161', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_171', 'train_174', 'train_175', 'train_178', 'train_179', 'train_180', 'train_181', 'train_184', 'train_185', 'train_189', 'train_202', 'train_203', 'train_212', 'train_215', 'train_216', 'train_217', 'train_218', 'train_219', 'train_220', 'train_225', 'train_229', 'train_232', 'train_233', 'train_234', 'train_235']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 167 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t167 features in original data used to generate 167 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.96 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.8973\t = Validation accuracy score\n",
      "\t6.8s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.8493\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.863\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9041\t = Validation accuracy score\n",
      "\t0.52s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.9041\t = Validation accuracy score\n",
      "\t0.5s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.9007\t = Validation accuracy score\n",
      "\t0.4s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.9007\t = Validation accuracy score\n",
      "\t0.4s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9178\t = Validation accuracy score\n",
      "\t1.45s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9075\t = Validation accuracy score\n",
      "\t1.3s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9075\t = Validation accuracy score\n",
      "\t2.66s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9041\t = Validation accuracy score\n",
      "\t4.18s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9178\t = Validation accuracy score\n",
      "\t0.27s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 19.78s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_011254/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_011254/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 239\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t9 unique label values:  ['8', '6', '0', '3', '4', '1', '5', '2', '7']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 3 out of 9 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9808219178082191\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15942.44 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.75 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  SaleCondition_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleCondition_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleType_1010_0\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 73): ['train_38', 'train_39', 'train_44', 'train_45', 'train_47', 'train_48', 'train_51', 'train_52', 'train_55', 'train_56', 'train_60', 'train_63', 'train_69', 'train_74', 'train_75', 'train_79', 'train_83', 'train_84', 'train_88', 'train_89', 'train_90', 'train_91', 'train_92', 'train_96', 'train_97', 'train_101', 'train_106', 'train_107', 'train_113', 'train_117', 'train_118', 'train_121', 'train_125', 'train_130', 'train_134', 'train_138', 'train_145', 'train_150', 'train_151', 'train_152', 'train_153', 'train_157', 'train_161', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_171', 'train_174', 'train_175', 'train_178', 'train_179', 'train_180', 'train_181', 'train_184', 'train_185', 'train_189', 'train_202', 'train_203', 'train_212', 'train_215', 'train_216', 'train_217', 'train_218', 'train_219', 'train_220', 'train_225', 'train_229', 'train_232', 'train_233', 'train_234', 'train_235']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t166 features in original data used to generate 166 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.91 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.9617\t = Validation accuracy score\n",
      "\t8.61s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.892\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.8955\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9686\t = Validation accuracy score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.9686\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.9686\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.9686\t = Validation accuracy score\n",
      "\t0.36s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9686\t = Validation accuracy score\n",
      "\t0.75s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9791\t = Validation accuracy score\n",
      "\t0.7s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9686\t = Validation accuracy score\n",
      "\t1.52s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9721\t = Validation accuracy score\n",
      "\t3.01s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9791\t = Validation accuracy score\n",
      "\t0.26s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 17.71s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_011312/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_011312/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (8.338604627661638, -0.27011580124313217, -0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15865.81 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_173', 'train_174', 'train_177', 'train_178', 'train_179', 'train_180', 'train_183', 'train_184', 'train_188', 'train_201', 'train_202', 'train_211', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  SaleType_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleType_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleType_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ScreenPorch_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-1.0991\t = Validation root_mean_squared_error score\n",
      "\t0.68s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-1.1797\t = Validation root_mean_squared_error score\n",
      "\t0.59s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-1.1331\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-1.1355\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-1.044\t = Validation root_mean_squared_error score\n",
      "\t0.45s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-1.0366\t = Validation root_mean_squared_error score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-1.0342\t = Validation root_mean_squared_error score\n",
      "\t1.06s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-1.075\t = Validation root_mean_squared_error score\n",
      "\t4.82s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-1.0559\t = Validation root_mean_squared_error score\n",
      "\t1.31s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-1.0281\t = Validation root_mean_squared_error score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 10.53s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_011322/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_011322/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Updated label_count_threshold from 10 to 6 to avoid cutting too many classes.\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15956.79 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_45', 'train_46', 'train_49', 'train_50', 'train_53', 'train_54', 'train_58', 'train_61', 'train_67', 'train_72', 'train_73', 'train_77', 'train_81', 'train_82', 'train_86', 'train_87', 'train_88', 'train_89', 'train_90', 'train_94', 'train_95', 'train_99', 'train_104', 'train_105', 'train_111', 'train_115', 'train_116', 'train_119', 'train_123', 'train_128', 'train_132', 'train_136', 'train_143', 'train_148', 'train_149', 'train_150', 'train_151', 'train_155', 'train_159', 'train_164', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Street_bnry\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.48s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.36s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.26s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.34s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.82s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t4.7s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.76s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9966\t = Validation accuracy score\n",
      "\t0.32s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 9.96s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_011332/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_011332/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (4.603311594902235, -2.779516960817937, -0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16071.94 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_173', 'train_174', 'train_177', 'train_178', 'train_179', 'train_180', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  TotRmsAbvGrd_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4406\t = Validation root_mean_squared_error score\n",
      "\t0.7s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.4303\t = Validation root_mean_squared_error score\n",
      "\t0.63s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.614\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.61\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.436\t = Validation root_mean_squared_error score\n",
      "\t0.56s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.4449\t = Validation root_mean_squared_error score\n",
      "\t0.49s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.4447\t = Validation root_mean_squared_error score\n",
      "\t1.54s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.4712\t = Validation root_mean_squared_error score\n",
      "\t12.54s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.4531\t = Validation root_mean_squared_error score\n",
      "\t2.11s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.4158\t = Validation root_mean_squared_error score\n",
      "\t0.33s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 19.74s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_011352/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_011352/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (11.51700302286161, -2.4103410492171595, 0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16007.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_155', 'train_159', 'train_164', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  TotalBsmtSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.5422\t = Validation root_mean_squared_error score\n",
      "\t0.78s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.5269\t = Validation root_mean_squared_error score\n",
      "\t0.71s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.6563\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.6525\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.5029\t = Validation root_mean_squared_error score\n",
      "\t1.4s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain_set's rmse: 0.00508757\tvalid_set's rmse: 0.521533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.5215\t = Validation root_mean_squared_error score\n",
      "\t1.51s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.522\t = Validation root_mean_squared_error score\n",
      "\t5.63s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.4538\t = Validation root_mean_squared_error score\n",
      "\t13.94s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.5239\t = Validation root_mean_squared_error score\n",
      "\t2.64s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.4521\t = Validation root_mean_squared_error score\n",
      "\t0.33s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 27.99s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_011420/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_011420/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Updated label_count_threshold from 10 to 2 to avoid cutting too many classes.\n",
      "Warning: Updated holdout_frac from 0.2 to 0.501 to avoid cutting too many classes.\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15913.97 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_58', 'train_61', 'train_67', 'train_72', 'train_73', 'train_77', 'train_81', 'train_82', 'train_86', 'train_87', 'train_88', 'train_89', 'train_90', 'train_94', 'train_95', 'train_99', 'train_104', 'train_105', 'train_111', 'train_115', 'train_116', 'train_119', 'train_123', 'train_128', 'train_132', 'train_136', 'train_143', 'train_148', 'train_149', 'train_150', 'train_151', 'train_155', 'train_159', 'train_164', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  Utilities_bnry\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  WoodDeckSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_011420-001/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_011420-001/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (6.085549836323009, -0.7519181992725877, 0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15914.05 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_173', 'train_174', 'train_177', 'train_178', 'train_179', 'train_180', 'train_183', 'train_184', 'train_188', 'train_201', 'train_202', 'train_211', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.8733\t = Validation root_mean_squared_error score\n",
      "\t0.72s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.8966\t = Validation root_mean_squared_error score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.9311\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.9304\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.8681\t = Validation root_mean_squared_error score\n",
      "\t0.32s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.8517\t = Validation root_mean_squared_error score\n",
      "\t0.51s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.8447\t = Validation root_mean_squared_error score\n",
      "\t1.09s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.8587\t = Validation root_mean_squared_error score\n",
      "\t5.98s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.8789\t = Validation root_mean_squared_error score\n",
      "\t1.12s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.8239\t = Validation root_mean_squared_error score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11.51s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_011432/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_011432/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1.282399590658155, -3.2866974672174014, 0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15862.92 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_94', 'train_95', 'train_99', 'train_104', 'train_105', 'train_111', 'train_115', 'train_116', 'train_119', 'train_123', 'train_128', 'train_132', 'train_136', 'train_143', 'train_148', 'train_149', 'train_150', 'train_151', 'train_155', 'train_159', 'train_164', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  YearBuilt_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.2094\t = Validation root_mean_squared_error score\n",
      "\t0.69s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.2892\t = Validation root_mean_squared_error score\n",
      "\t0.61s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.3701\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.3681\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.2522\t = Validation root_mean_squared_error score\n",
      "\t0.46s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.2581\t = Validation root_mean_squared_error score\n",
      "\t0.59s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.2444\t = Validation root_mean_squared_error score\n",
      "\t4.1s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.278\t = Validation root_mean_squared_error score\n",
      "\t7.67s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.2406\t = Validation root_mean_squared_error score\n",
      "\t1.45s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.2031\t = Validation root_mean_squared_error score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 16.71s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_011448/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_011448/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (1.2174255905655957, -1.6887898479984382, 0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15935.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_94', 'train_95', 'train_99', 'train_104', 'train_105', 'train_111', 'train_115', 'train_116', 'train_119', 'train_123', 'train_128', 'train_132', 'train_136', 'train_143', 'train_148', 'train_149', 'train_150', 'train_151', 'train_155', 'train_159', 'train_164', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_172', 'train_173', 'train_176', 'train_177', 'train_178', 'train_179', 'train_182', 'train_183', 'train_187', 'train_200', 'train_201', 'train_210', 'train_213', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_223', 'train_227', 'train_230', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n",
      "Fitting model: RandomForestRegressorMSE ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  YearRemodAdd_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.5555\t = Validation root_mean_squared_error score\n",
      "\t0.69s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-0.6089\t = Validation root_mean_squared_error score\n",
      "\t0.64s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-0.7403\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-0.7403\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.5868\t = Validation root_mean_squared_error score\n",
      "\t0.59s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-0.6157\t = Validation root_mean_squared_error score\n",
      "\t0.55s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.5642\t = Validation root_mean_squared_error score\n",
      "\t1.12s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-0.6473\t = Validation root_mean_squared_error score\n",
      "\t5.91s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.576\t = Validation root_mean_squared_error score\n",
      "\t1.71s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.5514\t = Validation root_mean_squared_error score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 12.4s ...\n",
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210604_011501/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20210604_011501/\n",
      "AutoGluon Version:  0.0.15\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 242\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (1.6446461865129716, -1.367186277969796, 0.0, 1.0)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15912.46 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.83 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 73): ['train_37', 'train_38', 'train_43', 'train_44', 'train_46', 'train_47', 'train_50', 'train_51', 'train_54', 'train_55', 'train_59', 'train_62', 'train_68', 'train_73', 'train_74', 'train_78', 'train_82', 'train_83', 'train_87', 'train_88', 'train_89', 'train_90', 'train_91', 'train_95', 'train_96', 'train_100', 'train_105', 'train_106', 'train_112', 'train_116', 'train_117', 'train_120', 'train_124', 'train_129', 'train_133', 'train_137', 'train_144', 'train_149', 'train_150', 'train_151', 'train_152', 'train_156', 'train_160', 'train_165', 'train_166', 'train_167', 'train_168', 'train_169', 'train_170', 'train_173', 'train_174', 'train_177', 'train_178', 'train_179', 'train_180', 'train_183', 'train_184', 'train_188', 'train_201', 'train_202', 'train_211', 'train_214', 'train_215', 'train_216', 'train_217', 'train_218', 'train_219', 'train_224', 'train_228', 'train_231', 'train_232', 'train_233', 'train_238']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['train_0', 'train_1', 'train_2', 'train_3', 'train_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'root_mean_squared_error'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infill to column:  YrSold_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: RandomForestRegressorMSE ...\n",
      "\t-0.9723\t = Validation root_mean_squared_error score\n",
      "\t0.8s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE ...\n",
      "\t-1.0164\t = Validation root_mean_squared_error score\n",
      "\t0.73s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif ...\n",
      "\t-1.0589\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist ...\n",
      "\t-1.0594\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor ...\n",
      "\t-0.972\t = Validation root_mean_squared_error score\n",
      "\t0.52s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorXT ...\n",
      "\t-1.0021\t = Validation root_mean_squared_error score\n",
      "\t0.68s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor ...\n",
      "\t-0.9655\t = Validation root_mean_squared_error score\n",
      "\t0.98s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor ...\n",
      "\t-1.0263\t = Validation root_mean_squared_error score\n",
      "\t5.03s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom ...\n",
      "\t-0.9942\t = Validation root_mean_squared_error score\n",
      "\t1.04s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.9626\t = Validation root_mean_squared_error score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 10.98s ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______\n",
      "\n",
      "versioning serial stamp:\n",
      "_6.13_643291668352_2021-06-03T20:51:01.427031\n",
      "\n",
      "Automunge returned ID column set: \n",
      "['Id', 'Automunge_index']\n",
      "\n",
      "Automunge returned train column set: \n",
      "['MSSubClass_nmbr', 'LotFrontage_nmbr', 'LotArea_nmbr', 'Street_bnry', 'Alley_bnry', 'Utilities_bnry', 'OverallQual_nmbr', 'OverallCond_nmbr', 'YearBuilt_nmbr', 'YearRemodAdd_nmbr', 'MasVnrArea_nmbr', 'BsmtFinSF1_nmbr', 'BsmtFinSF2_nmbr', 'BsmtUnfSF_nmbr', 'TotalBsmtSF_nmbr', 'CentralAir_bnry', '1stFlrSF_nmbr', '2ndFlrSF_nmbr', 'LowQualFinSF_nmbr', 'GrLivArea_nmbr', 'BsmtFullBath_nmbr', 'FullBath_nmbr', 'BedroomAbvGr_nmbr', 'KitchenAbvGr_nmbr', 'TotRmsAbvGrd_nmbr', 'Fireplaces_nmbr', 'GarageYrBlt_nmbr', 'GarageCars_nmbr', 'GarageArea_nmbr', 'WoodDeckSF_nmbr', 'OpenPorchSF_nmbr', 'EnclosedPorch_nmbr', '3SsnPorch_nmbr', 'ScreenPorch_nmbr', 'PoolArea_nmbr', 'MiscVal_nmbr', 'MoSold_nmbr', 'YrSold_nmbr', 'MSSubClass_NArw', 'MSZoning_NArw', 'MSZoning_1010_0', 'MSZoning_1010_1', 'MSZoning_1010_2', 'LotFrontage_NArw', 'LotArea_NArw', 'Street_NArw', 'Alley_NArw', 'LotShape_NArw', 'LotShape_1010_0', 'LotShape_1010_1', 'LotShape_1010_2', 'LandContour_NArw', 'LandContour_1010_0', 'LandContour_1010_1', 'LandContour_1010_2', 'Utilities_NArw', 'LotConfig_NArw', 'LotConfig_1010_0', 'LotConfig_1010_1', 'LotConfig_1010_2', 'LandSlope_NArw', 'LandSlope_1010_0', 'LandSlope_1010_1', 'Neighborhood_NArw', 'Neighborhood_1010_0', 'Neighborhood_1010_1', 'Neighborhood_1010_2', 'Neighborhood_1010_3', 'Neighborhood_1010_4', 'Condition1_NArw', 'Condition1_1010_0', 'Condition1_1010_1', 'Condition1_1010_2', 'Condition1_1010_3', 'Condition2_NArw', 'Condition2_1010_0', 'Condition2_1010_1', 'Condition2_1010_2', 'Condition2_1010_3', 'BldgType_NArw', 'BldgType_1010_0', 'BldgType_1010_1', 'BldgType_1010_2', 'HouseStyle_NArw', 'HouseStyle_1010_0', 'HouseStyle_1010_1', 'HouseStyle_1010_2', 'HouseStyle_1010_3', 'OverallQual_NArw', 'OverallCond_NArw', 'YearBuilt_NArw', 'YearRemodAdd_NArw', 'RoofStyle_NArw', 'RoofStyle_1010_0', 'RoofStyle_1010_1', 'RoofStyle_1010_2', 'RoofMatl_NArw', 'RoofMatl_1010_0', 'RoofMatl_1010_1', 'RoofMatl_1010_2', 'RoofMatl_1010_3', 'Exterior1st_NArw', 'Exterior1st_1010_0', 'Exterior1st_1010_1', 'Exterior1st_1010_2', 'Exterior1st_1010_3', 'Exterior2nd_NArw', 'Exterior2nd_1010_0', 'Exterior2nd_1010_1', 'Exterior2nd_1010_2', 'Exterior2nd_1010_3', 'Exterior2nd_1010_4', 'MasVnrType_NArw', 'MasVnrType_1010_0', 'MasVnrType_1010_1', 'MasVnrType_1010_2', 'MasVnrArea_NArw', 'ExterQual_NArw', 'ExterQual_1010_0', 'ExterQual_1010_1', 'ExterQual_1010_2', 'ExterCond_NArw', 'ExterCond_1010_0', 'ExterCond_1010_1', 'ExterCond_1010_2', 'Foundation_NArw', 'Foundation_1010_0', 'Foundation_1010_1', 'Foundation_1010_2', 'BsmtQual_NArw', 'BsmtQual_1010_0', 'BsmtQual_1010_1', 'BsmtQual_1010_2', 'BsmtCond_NArw', 'BsmtCond_1010_0', 'BsmtCond_1010_1', 'BsmtCond_1010_2', 'BsmtExposure_NArw', 'BsmtExposure_1010_0', 'BsmtExposure_1010_1', 'BsmtExposure_1010_2', 'BsmtFinType1_NArw', 'BsmtFinType1_1010_0', 'BsmtFinType1_1010_1', 'BsmtFinType1_1010_2', 'BsmtFinSF1_NArw', 'BsmtFinType2_NArw', 'BsmtFinType2_1010_0', 'BsmtFinType2_1010_1', 'BsmtFinType2_1010_2', 'BsmtFinSF2_NArw', 'BsmtUnfSF_NArw', 'TotalBsmtSF_NArw', 'Heating_NArw', 'Heating_1010_0', 'Heating_1010_1', 'Heating_1010_2', 'HeatingQC_NArw', 'HeatingQC_1010_0', 'HeatingQC_1010_1', 'HeatingQC_1010_2', 'CentralAir_NArw', 'Electrical_NArw', 'Electrical_1010_0', 'Electrical_1010_1', 'Electrical_1010_2', '1stFlrSF_NArw', '2ndFlrSF_NArw', 'LowQualFinSF_NArw', 'GrLivArea_NArw', 'BsmtFullBath_NArw', 'BsmtHalfBath_NArw', 'BsmtHalfBath_1010_0', 'BsmtHalfBath_1010_1', 'FullBath_NArw', 'HalfBath_NArw', 'HalfBath_1010_0', 'HalfBath_1010_1', 'BedroomAbvGr_NArw', 'KitchenAbvGr_NArw', 'KitchenQual_NArw', 'KitchenQual_1010_0', 'KitchenQual_1010_1', 'KitchenQual_1010_2', 'TotRmsAbvGrd_NArw', 'Functional_NArw', 'Functional_1010_0', 'Functional_1010_1', 'Functional_1010_2', 'Fireplaces_NArw', 'FireplaceQu_NArw', 'FireplaceQu_1010_0', 'FireplaceQu_1010_1', 'FireplaceQu_1010_2', 'GarageType_NArw', 'GarageType_1010_0', 'GarageType_1010_1', 'GarageType_1010_2', 'GarageYrBlt_NArw', 'GarageFinish_NArw', 'GarageFinish_1010_0', 'GarageFinish_1010_1', 'GarageCars_NArw', 'GarageArea_NArw', 'GarageQual_NArw', 'GarageQual_1010_0', 'GarageQual_1010_1', 'GarageQual_1010_2', 'GarageCond_NArw', 'GarageCond_1010_0', 'GarageCond_1010_1', 'GarageCond_1010_2', 'PavedDrive_NArw', 'PavedDrive_1010_0', 'PavedDrive_1010_1', 'WoodDeckSF_NArw', 'OpenPorchSF_NArw', 'EnclosedPorch_NArw', '3SsnPorch_NArw', 'ScreenPorch_NArw', 'PoolArea_NArw', 'PoolQC_NArw', 'PoolQC_1010_0', 'PoolQC_1010_1', 'Fence_NArw', 'Fence_1010_0', 'Fence_1010_1', 'Fence_1010_2', 'MiscFeature_NArw', 'MiscFeature_1010_0', 'MiscFeature_1010_1', 'MiscFeature_1010_2', 'MiscVal_NArw', 'MoSold_NArw', 'YrSold_NArw', 'SaleType_NArw', 'SaleType_1010_0', 'SaleType_1010_1', 'SaleType_1010_2', 'SaleType_1010_3', 'SaleCondition_NArw', 'SaleCondition_1010_0', 'SaleCondition_1010_1', 'SaleCondition_1010_2']\n",
      "\n",
      "Automunge returned label column set: \n",
      "['SalePrice_exc2']\n",
      "\n",
      "_______________\n",
      "Automunge Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML_cmnd = {'autoML_type' : 'autogluon'}\n",
    "\n",
    "#can pass parameters to AutoGluon as shown\n",
    "\n",
    "# ML_cmnd.update({'MLinfill_cmnd' : \n",
    "#                  {'AutoGluon' : \n",
    "#                    {'presets' : 'best_quality'}}})\n",
    "\n",
    "train, train_ID, labels, \\\n",
    "val, val_ID, val_labels, \\\n",
    "test, test_ID, test_labels, \\\n",
    "postprocess_dict = \\\n",
    "am.automunge(df_train,\n",
    "             labels_column = 'SalePrice',\n",
    "             trainID_column = 'Id',\n",
    "             MLinfill = True,\n",
    "             ML_cmnd = ML_cmnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be complete, here we’ll demonstrate passing parameters to the Scikit-Learn random forest models. Note that for random forest there are built in methods to perform grid search or random search hyperparameter tuning when parameters are passed as lists or distributions instead of static figures. Here we’ll demonstrate performing tuning of the n_estimators parameter (which otherwise would default to 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________\n",
      "Begin Automunge processing\n",
      "\n",
      "evaluating column:  MSSubClass\n",
      "processing column:  MSSubClass\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MSSubClass_nmbr', 'MSSubClass_NArw']\n",
      "\n",
      "evaluating column:  MSZoning\n",
      "processing column:  MSZoning\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['MSZoning_NArw', 'MSZoning_1010_0', 'MSZoning_1010_1', 'MSZoning_1010_2']\n",
      "\n",
      "evaluating column:  LotFrontage\n",
      "processing column:  LotFrontage\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['LotFrontage_nmbr', 'LotFrontage_NArw']\n",
      "\n",
      "evaluating column:  LotArea\n",
      "processing column:  LotArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['LotArea_nmbr', 'LotArea_NArw']\n",
      "\n",
      "evaluating column:  Street\n",
      "processing column:  Street\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['Street_bnry', 'Street_NArw']\n",
      "\n",
      "evaluating column:  Alley\n",
      "processing column:  Alley\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['Alley_bnry', 'Alley_NArw']\n",
      "\n",
      "evaluating column:  LotShape\n",
      "processing column:  LotShape\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LotShape_NArw', 'LotShape_1010_0', 'LotShape_1010_1', 'LotShape_1010_2']\n",
      "\n",
      "evaluating column:  LandContour\n",
      "processing column:  LandContour\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LandContour_NArw', 'LandContour_1010_0', 'LandContour_1010_1', 'LandContour_1010_2']\n",
      "\n",
      "evaluating column:  Utilities\n",
      "processing column:  Utilities\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['Utilities_bnry', 'Utilities_NArw']\n",
      "\n",
      "evaluating column:  LotConfig\n",
      "processing column:  LotConfig\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LotConfig_NArw', 'LotConfig_1010_0', 'LotConfig_1010_1', 'LotConfig_1010_2']\n",
      "\n",
      "evaluating column:  LandSlope\n",
      "processing column:  LandSlope\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['LandSlope_NArw', 'LandSlope_1010_0', 'LandSlope_1010_1']\n",
      "\n",
      "evaluating column:  Neighborhood\n",
      "processing column:  Neighborhood\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Neighborhood_NArw', 'Neighborhood_1010_0', 'Neighborhood_1010_1', 'Neighborhood_1010_2', 'Neighborhood_1010_3', 'Neighborhood_1010_4']\n",
      "\n",
      "evaluating column:  Condition1\n",
      "processing column:  Condition1\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Condition1_NArw', 'Condition1_1010_0', 'Condition1_1010_1', 'Condition1_1010_2', 'Condition1_1010_3']\n",
      "\n",
      "evaluating column:  Condition2\n",
      "processing column:  Condition2\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Condition2_NArw', 'Condition2_1010_0', 'Condition2_1010_1', 'Condition2_1010_2', 'Condition2_1010_3']\n",
      "\n",
      "evaluating column:  BldgType\n",
      "processing column:  BldgType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BldgType_NArw', 'BldgType_1010_0', 'BldgType_1010_1', 'BldgType_1010_2']\n",
      "\n",
      "evaluating column:  HouseStyle\n",
      "processing column:  HouseStyle\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['HouseStyle_NArw', 'HouseStyle_1010_0', 'HouseStyle_1010_1', 'HouseStyle_1010_2', 'HouseStyle_1010_3']\n",
      "\n",
      "evaluating column:  OverallQual\n",
      "processing column:  OverallQual\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['OverallQual_nmbr', 'OverallQual_NArw']\n",
      "\n",
      "evaluating column:  OverallCond\n",
      "processing column:  OverallCond\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['OverallCond_nmbr', 'OverallCond_NArw']\n",
      "\n",
      "evaluating column:  YearBuilt\n",
      "processing column:  YearBuilt\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['YearBuilt_nmbr', 'YearBuilt_NArw']\n",
      "\n",
      "evaluating column:  YearRemodAdd\n",
      "processing column:  YearRemodAdd\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['YearRemodAdd_nmbr', 'YearRemodAdd_NArw']\n",
      "\n",
      "evaluating column:  RoofStyle\n",
      "processing column:  RoofStyle\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['RoofStyle_NArw', 'RoofStyle_1010_0', 'RoofStyle_1010_1', 'RoofStyle_1010_2']\n",
      "\n",
      "evaluating column:  RoofMatl\n",
      "processing column:  RoofMatl\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['RoofMatl_NArw', 'RoofMatl_1010_0', 'RoofMatl_1010_1', 'RoofMatl_1010_2', 'RoofMatl_1010_3']\n",
      "\n",
      "evaluating column:  Exterior1st\n",
      "processing column:  Exterior1st\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Exterior1st_NArw', 'Exterior1st_1010_0', 'Exterior1st_1010_1', 'Exterior1st_1010_2', 'Exterior1st_1010_3']\n",
      "\n",
      "evaluating column:  Exterior2nd\n",
      "processing column:  Exterior2nd\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Exterior2nd_NArw', 'Exterior2nd_1010_0', 'Exterior2nd_1010_1', 'Exterior2nd_1010_2', 'Exterior2nd_1010_3', 'Exterior2nd_1010_4']\n",
      "\n",
      "evaluating column:  MasVnrType\n",
      "processing column:  MasVnrType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['MasVnrType_NArw', 'MasVnrType_1010_0', 'MasVnrType_1010_1', 'MasVnrType_1010_2']\n",
      "\n",
      "evaluating column:  MasVnrArea\n",
      "processing column:  MasVnrArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MasVnrArea_nmbr', 'MasVnrArea_NArw']\n",
      "\n",
      "evaluating column:  ExterQual\n",
      "processing column:  ExterQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['ExterQual_NArw', 'ExterQual_1010_0', 'ExterQual_1010_1', 'ExterQual_1010_2']\n",
      "\n",
      "evaluating column:  ExterCond\n",
      "processing column:  ExterCond\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['ExterCond_NArw', 'ExterCond_1010_0', 'ExterCond_1010_1', 'ExterCond_1010_2']\n",
      "\n",
      "evaluating column:  Foundation\n",
      "processing column:  Foundation\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Foundation_NArw', 'Foundation_1010_0', 'Foundation_1010_1', 'Foundation_1010_2']\n",
      "\n",
      "evaluating column:  BsmtQual\n",
      "processing column:  BsmtQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtQual_NArw', 'BsmtQual_1010_0', 'BsmtQual_1010_1', 'BsmtQual_1010_2']\n",
      "\n",
      "evaluating column:  BsmtCond\n",
      "processing column:  BsmtCond\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtCond_NArw', 'BsmtCond_1010_0', 'BsmtCond_1010_1', 'BsmtCond_1010_2']\n",
      "\n",
      "evaluating column:  BsmtExposure\n",
      "processing column:  BsmtExposure\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtExposure_NArw', 'BsmtExposure_1010_0', 'BsmtExposure_1010_1', 'BsmtExposure_1010_2']\n",
      "\n",
      "evaluating column:  BsmtFinType1\n",
      "processing column:  BsmtFinType1\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtFinType1_NArw', 'BsmtFinType1_1010_0', 'BsmtFinType1_1010_1', 'BsmtFinType1_1010_2']\n",
      "\n",
      "evaluating column:  BsmtFinSF1\n",
      "processing column:  BsmtFinSF1\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtFinSF1_nmbr', 'BsmtFinSF1_NArw']\n",
      "\n",
      "evaluating column:  BsmtFinType2\n",
      "processing column:  BsmtFinType2\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtFinType2_NArw', 'BsmtFinType2_1010_0', 'BsmtFinType2_1010_1', 'BsmtFinType2_1010_2']\n",
      "\n",
      "evaluating column:  BsmtFinSF2\n",
      "processing column:  BsmtFinSF2\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtFinSF2_nmbr', 'BsmtFinSF2_NArw']\n",
      "\n",
      "evaluating column:  BsmtUnfSF\n",
      "processing column:  BsmtUnfSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtUnfSF_nmbr', 'BsmtUnfSF_NArw']\n",
      "\n",
      "evaluating column:  TotalBsmtSF\n",
      "processing column:  TotalBsmtSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['TotalBsmtSF_nmbr', 'TotalBsmtSF_NArw']\n",
      "\n",
      "evaluating column:  Heating\n",
      "processing column:  Heating\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Heating_NArw', 'Heating_1010_0', 'Heating_1010_1', 'Heating_1010_2']\n",
      "\n",
      "evaluating column:  HeatingQC\n",
      "processing column:  HeatingQC\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['HeatingQC_NArw', 'HeatingQC_1010_0', 'HeatingQC_1010_1', 'HeatingQC_1010_2']\n",
      "\n",
      "evaluating column:  CentralAir\n",
      "processing column:  CentralAir\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['CentralAir_bnry', 'CentralAir_NArw']\n",
      "\n",
      "evaluating column:  Electrical\n",
      "processing column:  Electrical\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Electrical_NArw', 'Electrical_1010_0', 'Electrical_1010_1', 'Electrical_1010_2']\n",
      "\n",
      "evaluating column:  1stFlrSF\n",
      "processing column:  1stFlrSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['1stFlrSF_nmbr', '1stFlrSF_NArw']\n",
      "\n",
      "evaluating column:  2ndFlrSF\n",
      "processing column:  2ndFlrSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['2ndFlrSF_nmbr', '2ndFlrSF_NArw']\n",
      "\n",
      "evaluating column:  LowQualFinSF\n",
      "processing column:  LowQualFinSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['LowQualFinSF_nmbr', 'LowQualFinSF_NArw']\n",
      "\n",
      "evaluating column:  GrLivArea\n",
      "processing column:  GrLivArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GrLivArea_nmbr', 'GrLivArea_NArw']\n",
      "\n",
      "evaluating column:  BsmtFullBath\n",
      "processing column:  BsmtFullBath\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BsmtFullBath_nmbr', 'BsmtFullBath_NArw']\n",
      "\n",
      "evaluating column:  BsmtHalfBath\n",
      "processing column:  BsmtHalfBath\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['BsmtHalfBath_NArw', 'BsmtHalfBath_1010_0', 'BsmtHalfBath_1010_1']\n",
      "\n",
      "evaluating column:  FullBath\n",
      "processing column:  FullBath\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['FullBath_nmbr', 'FullBath_NArw']\n",
      "\n",
      "evaluating column:  HalfBath\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing column:  HalfBath\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['HalfBath_NArw', 'HalfBath_1010_0', 'HalfBath_1010_1']\n",
      "\n",
      "evaluating column:  BedroomAbvGr\n",
      "processing column:  BedroomAbvGr\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['BedroomAbvGr_nmbr', 'BedroomAbvGr_NArw']\n",
      "\n",
      "evaluating column:  KitchenAbvGr\n",
      "processing column:  KitchenAbvGr\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['KitchenAbvGr_nmbr', 'KitchenAbvGr_NArw']\n",
      "\n",
      "evaluating column:  KitchenQual\n",
      "processing column:  KitchenQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['KitchenQual_NArw', 'KitchenQual_1010_0', 'KitchenQual_1010_1', 'KitchenQual_1010_2']\n",
      "\n",
      "evaluating column:  TotRmsAbvGrd\n",
      "processing column:  TotRmsAbvGrd\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['TotRmsAbvGrd_nmbr', 'TotRmsAbvGrd_NArw']\n",
      "\n",
      "evaluating column:  Functional\n",
      "processing column:  Functional\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Functional_NArw', 'Functional_1010_0', 'Functional_1010_1', 'Functional_1010_2']\n",
      "\n",
      "evaluating column:  Fireplaces\n",
      "processing column:  Fireplaces\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['Fireplaces_nmbr', 'Fireplaces_NArw']\n",
      "\n",
      "evaluating column:  FireplaceQu\n",
      "processing column:  FireplaceQu\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['FireplaceQu_NArw', 'FireplaceQu_1010_0', 'FireplaceQu_1010_1', 'FireplaceQu_1010_2']\n",
      "\n",
      "evaluating column:  GarageType\n",
      "processing column:  GarageType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageType_NArw', 'GarageType_1010_0', 'GarageType_1010_1', 'GarageType_1010_2']\n",
      "\n",
      "evaluating column:  GarageYrBlt\n",
      "processing column:  GarageYrBlt\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GarageYrBlt_nmbr', 'GarageYrBlt_NArw']\n",
      "\n",
      "evaluating column:  GarageFinish\n",
      "processing column:  GarageFinish\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageFinish_NArw', 'GarageFinish_1010_0', 'GarageFinish_1010_1']\n",
      "\n",
      "evaluating column:  GarageCars\n",
      "processing column:  GarageCars\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GarageCars_nmbr', 'GarageCars_NArw']\n",
      "\n",
      "evaluating column:  GarageArea\n",
      "processing column:  GarageArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['GarageArea_nmbr', 'GarageArea_NArw']\n",
      "\n",
      "evaluating column:  GarageQual\n",
      "processing column:  GarageQual\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageQual_NArw', 'GarageQual_1010_0', 'GarageQual_1010_1', 'GarageQual_1010_2']\n",
      "\n",
      "evaluating column:  GarageCond\n",
      "processing column:  GarageCond\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['GarageCond_NArw', 'GarageCond_1010_0', 'GarageCond_1010_1', 'GarageCond_1010_2']\n",
      "\n",
      "evaluating column:  PavedDrive\n",
      "processing column:  PavedDrive\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['PavedDrive_NArw', 'PavedDrive_1010_0', 'PavedDrive_1010_1']\n",
      "\n",
      "evaluating column:  WoodDeckSF\n",
      "processing column:  WoodDeckSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['WoodDeckSF_nmbr', 'WoodDeckSF_NArw']\n",
      "\n",
      "evaluating column:  OpenPorchSF\n",
      "processing column:  OpenPorchSF\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['OpenPorchSF_nmbr', 'OpenPorchSF_NArw']\n",
      "\n",
      "evaluating column:  EnclosedPorch\n",
      "processing column:  EnclosedPorch\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['EnclosedPorch_nmbr', 'EnclosedPorch_NArw']\n",
      "\n",
      "evaluating column:  3SsnPorch\n",
      "processing column:  3SsnPorch\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['3SsnPorch_nmbr', '3SsnPorch_NArw']\n",
      "\n",
      "evaluating column:  ScreenPorch\n",
      "processing column:  ScreenPorch\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['ScreenPorch_nmbr', 'ScreenPorch_NArw']\n",
      "\n",
      "evaluating column:  PoolArea\n",
      "processing column:  PoolArea\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['PoolArea_nmbr', 'PoolArea_NArw']\n",
      "\n",
      "evaluating column:  PoolQC\n",
      "processing column:  PoolQC\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['PoolQC_NArw', 'PoolQC_1010_0', 'PoolQC_1010_1']\n",
      "\n",
      "evaluating column:  Fence\n",
      "processing column:  Fence\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Fence_NArw', 'Fence_1010_0', 'Fence_1010_1', 'Fence_1010_2']\n",
      "\n",
      "evaluating column:  MiscFeature\n",
      "processing column:  MiscFeature\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['MiscFeature_NArw', 'MiscFeature_1010_0', 'MiscFeature_1010_1', 'MiscFeature_1010_2']\n",
      "\n",
      "evaluating column:  MiscVal\n",
      "processing column:  MiscVal\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MiscVal_nmbr', 'MiscVal_NArw']\n",
      "\n",
      "evaluating column:  MoSold\n",
      "processing column:  MoSold\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['MoSold_nmbr', 'MoSold_NArw']\n",
      "\n",
      "evaluating column:  YrSold\n",
      "processing column:  YrSold\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['YrSold_nmbr', 'YrSold_NArw']\n",
      "\n",
      "evaluating column:  SaleType\n",
      "processing column:  SaleType\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['SaleType_NArw', 'SaleType_1010_0', 'SaleType_1010_1', 'SaleType_1010_2', 'SaleType_1010_3']\n",
      "\n",
      "evaluating column:  SaleCondition\n",
      "processing column:  SaleCondition\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['SaleCondition_NArw', 'SaleCondition_1010_0', 'SaleCondition_1010_1', 'SaleCondition_1010_2']\n",
      "\n",
      "______\n",
      "\n",
      "evaluating label column:  SalePrice\n",
      "processing label column:  SalePrice\n",
      "    root label category:  lbnm\n",
      "\n",
      " returned columns:\n",
      "['SalePrice_exc2']\n",
      "\n",
      "______\n",
      "\n",
      "infill to column:  PoolQC_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  PoolQC_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MiscFeature_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  MiscFeature_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MiscFeature_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Alley_bnry\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  Fence_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 222}\n",
      "\n",
      "infill to column:  Fence_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Fence_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  FireplaceQu_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 222}\n",
      "\n",
      "infill to column:  FireplaceQu_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  FireplaceQu_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotFrontage_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  GarageCond_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  GarageCond_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageCond_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageFinish_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  GarageFinish_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageQual_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 222}\n",
      "\n",
      "infill to column:  GarageQual_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageQual_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageType_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  GarageType_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageType_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageYrBlt_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  BsmtExposure_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  BsmtExposure_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtExposure_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinType2_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  BsmtFinType2_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinType2_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtCond_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  BsmtCond_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtCond_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinType1_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  BsmtFinType1_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinType1_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtQual_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  BsmtQual_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtQual_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MasVnrArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  MasVnrType_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 222}\n",
      "\n",
      "infill to column:  MasVnrType_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MasVnrType_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Electrical_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 222}\n",
      "\n",
      "infill to column:  Electrical_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Electrical_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  1stFlrSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  2ndFlrSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  3SsnPorch_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  BedroomAbvGr_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 222}\n",
      "\n",
      "infill to column:  BldgType_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  BldgType_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BldgType_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtFinSF1_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  BsmtFinSF2_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 222}\n",
      "\n",
      "infill to column:  BsmtFullBath_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  BsmtHalfBath_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  BsmtHalfBath_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  BsmtUnfSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  CentralAir_bnry\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  Condition1_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 222}\n",
      "\n",
      "infill to column:  Condition1_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition1_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition1_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition2_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  Condition2_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition2_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Condition2_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  EnclosedPorch_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  ExterCond_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  ExterCond_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ExterCond_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ExterQual_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  ExterQual_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ExterQual_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior1st_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 222}\n",
      "\n",
      "infill to column:  Exterior1st_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior1st_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior1st_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 222}\n",
      "\n",
      "infill to column:  Exterior2nd_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Exterior2nd_1010_4\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Fireplaces_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  Foundation_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 222}\n",
      "\n",
      "infill to column:  Foundation_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Foundation_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  FullBath_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  Functional_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  Functional_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Functional_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  GarageArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 222}\n",
      "\n",
      "infill to column:  GarageCars_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 222}\n",
      "\n",
      "infill to column:  GrLivArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  HalfBath_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  HalfBath_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HeatingQC_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  HeatingQC_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HeatingQC_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Heating_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  Heating_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Heating_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HouseStyle_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 222}\n",
      "\n",
      "infill to column:  HouseStyle_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HouseStyle_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  HouseStyle_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  KitchenAbvGr_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  KitchenQual_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 222}\n",
      "\n",
      "infill to column:  KitchenQual_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  KitchenQual_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LandContour_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 222}\n",
      "\n",
      "infill to column:  LandContour_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LandContour_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LandSlope_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  LandSlope_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  LotConfig_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 222}\n",
      "\n",
      "infill to column:  LotConfig_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotConfig_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotShape_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  LotShape_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LotShape_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  LowQualFinSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  MSSubClass_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  MSZoning_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  MSZoning_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MSZoning_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  MiscVal_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  MoSold_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 222}\n",
      "\n",
      "infill to column:  Neighborhood_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 222}\n",
      "\n",
      "infill to column:  Neighborhood_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Neighborhood_1010_4\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  OpenPorchSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  OverallCond_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  OverallQual_nmbr\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  PavedDrive_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  PavedDrive_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  PoolArea_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  RoofMatl_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  RoofMatl_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofMatl_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofMatl_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofStyle_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  RoofStyle_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  RoofStyle_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleCondition_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  SaleCondition_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleCondition_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleType_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  SaleType_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleType_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SaleType_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  ScreenPorch_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  Street_bnry\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  TotRmsAbvGrd_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  TotalBsmtSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  Utilities_bnry\n",
      "     infill type: MLinfill\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  WoodDeckSF_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  YearBuilt_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 100}\n",
      "\n",
      "infill to column:  YearRemodAdd_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "infill to column:  YrSold_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "tuned parameters:\n",
      "{'n_estimators': 444}\n",
      "\n",
      "______\n",
      "\n",
      "versioning serial stamp:\n",
      "_6.13_524533559245_2021-06-03T21:15:13.523166\n",
      "\n",
      "Automunge returned ID column set: \n",
      "['Id', 'Automunge_index']\n",
      "\n",
      "Automunge returned train column set: \n",
      "['MSSubClass_nmbr', 'LotFrontage_nmbr', 'LotArea_nmbr', 'Street_bnry', 'Alley_bnry', 'Utilities_bnry', 'OverallQual_nmbr', 'OverallCond_nmbr', 'YearBuilt_nmbr', 'YearRemodAdd_nmbr', 'MasVnrArea_nmbr', 'BsmtFinSF1_nmbr', 'BsmtFinSF2_nmbr', 'BsmtUnfSF_nmbr', 'TotalBsmtSF_nmbr', 'CentralAir_bnry', '1stFlrSF_nmbr', '2ndFlrSF_nmbr', 'LowQualFinSF_nmbr', 'GrLivArea_nmbr', 'BsmtFullBath_nmbr', 'FullBath_nmbr', 'BedroomAbvGr_nmbr', 'KitchenAbvGr_nmbr', 'TotRmsAbvGrd_nmbr', 'Fireplaces_nmbr', 'GarageYrBlt_nmbr', 'GarageCars_nmbr', 'GarageArea_nmbr', 'WoodDeckSF_nmbr', 'OpenPorchSF_nmbr', 'EnclosedPorch_nmbr', '3SsnPorch_nmbr', 'ScreenPorch_nmbr', 'PoolArea_nmbr', 'MiscVal_nmbr', 'MoSold_nmbr', 'YrSold_nmbr', 'MSSubClass_NArw', 'MSZoning_NArw', 'MSZoning_1010_0', 'MSZoning_1010_1', 'MSZoning_1010_2', 'LotFrontage_NArw', 'LotArea_NArw', 'Street_NArw', 'Alley_NArw', 'LotShape_NArw', 'LotShape_1010_0', 'LotShape_1010_1', 'LotShape_1010_2', 'LandContour_NArw', 'LandContour_1010_0', 'LandContour_1010_1', 'LandContour_1010_2', 'Utilities_NArw', 'LotConfig_NArw', 'LotConfig_1010_0', 'LotConfig_1010_1', 'LotConfig_1010_2', 'LandSlope_NArw', 'LandSlope_1010_0', 'LandSlope_1010_1', 'Neighborhood_NArw', 'Neighborhood_1010_0', 'Neighborhood_1010_1', 'Neighborhood_1010_2', 'Neighborhood_1010_3', 'Neighborhood_1010_4', 'Condition1_NArw', 'Condition1_1010_0', 'Condition1_1010_1', 'Condition1_1010_2', 'Condition1_1010_3', 'Condition2_NArw', 'Condition2_1010_0', 'Condition2_1010_1', 'Condition2_1010_2', 'Condition2_1010_3', 'BldgType_NArw', 'BldgType_1010_0', 'BldgType_1010_1', 'BldgType_1010_2', 'HouseStyle_NArw', 'HouseStyle_1010_0', 'HouseStyle_1010_1', 'HouseStyle_1010_2', 'HouseStyle_1010_3', 'OverallQual_NArw', 'OverallCond_NArw', 'YearBuilt_NArw', 'YearRemodAdd_NArw', 'RoofStyle_NArw', 'RoofStyle_1010_0', 'RoofStyle_1010_1', 'RoofStyle_1010_2', 'RoofMatl_NArw', 'RoofMatl_1010_0', 'RoofMatl_1010_1', 'RoofMatl_1010_2', 'RoofMatl_1010_3', 'Exterior1st_NArw', 'Exterior1st_1010_0', 'Exterior1st_1010_1', 'Exterior1st_1010_2', 'Exterior1st_1010_3', 'Exterior2nd_NArw', 'Exterior2nd_1010_0', 'Exterior2nd_1010_1', 'Exterior2nd_1010_2', 'Exterior2nd_1010_3', 'Exterior2nd_1010_4', 'MasVnrType_NArw', 'MasVnrType_1010_0', 'MasVnrType_1010_1', 'MasVnrType_1010_2', 'MasVnrArea_NArw', 'ExterQual_NArw', 'ExterQual_1010_0', 'ExterQual_1010_1', 'ExterQual_1010_2', 'ExterCond_NArw', 'ExterCond_1010_0', 'ExterCond_1010_1', 'ExterCond_1010_2', 'Foundation_NArw', 'Foundation_1010_0', 'Foundation_1010_1', 'Foundation_1010_2', 'BsmtQual_NArw', 'BsmtQual_1010_0', 'BsmtQual_1010_1', 'BsmtQual_1010_2', 'BsmtCond_NArw', 'BsmtCond_1010_0', 'BsmtCond_1010_1', 'BsmtCond_1010_2', 'BsmtExposure_NArw', 'BsmtExposure_1010_0', 'BsmtExposure_1010_1', 'BsmtExposure_1010_2', 'BsmtFinType1_NArw', 'BsmtFinType1_1010_0', 'BsmtFinType1_1010_1', 'BsmtFinType1_1010_2', 'BsmtFinSF1_NArw', 'BsmtFinType2_NArw', 'BsmtFinType2_1010_0', 'BsmtFinType2_1010_1', 'BsmtFinType2_1010_2', 'BsmtFinSF2_NArw', 'BsmtUnfSF_NArw', 'TotalBsmtSF_NArw', 'Heating_NArw', 'Heating_1010_0', 'Heating_1010_1', 'Heating_1010_2', 'HeatingQC_NArw', 'HeatingQC_1010_0', 'HeatingQC_1010_1', 'HeatingQC_1010_2', 'CentralAir_NArw', 'Electrical_NArw', 'Electrical_1010_0', 'Electrical_1010_1', 'Electrical_1010_2', '1stFlrSF_NArw', '2ndFlrSF_NArw', 'LowQualFinSF_NArw', 'GrLivArea_NArw', 'BsmtFullBath_NArw', 'BsmtHalfBath_NArw', 'BsmtHalfBath_1010_0', 'BsmtHalfBath_1010_1', 'FullBath_NArw', 'HalfBath_NArw', 'HalfBath_1010_0', 'HalfBath_1010_1', 'BedroomAbvGr_NArw', 'KitchenAbvGr_NArw', 'KitchenQual_NArw', 'KitchenQual_1010_0', 'KitchenQual_1010_1', 'KitchenQual_1010_2', 'TotRmsAbvGrd_NArw', 'Functional_NArw', 'Functional_1010_0', 'Functional_1010_1', 'Functional_1010_2', 'Fireplaces_NArw', 'FireplaceQu_NArw', 'FireplaceQu_1010_0', 'FireplaceQu_1010_1', 'FireplaceQu_1010_2', 'GarageType_NArw', 'GarageType_1010_0', 'GarageType_1010_1', 'GarageType_1010_2', 'GarageYrBlt_NArw', 'GarageFinish_NArw', 'GarageFinish_1010_0', 'GarageFinish_1010_1', 'GarageCars_NArw', 'GarageArea_NArw', 'GarageQual_NArw', 'GarageQual_1010_0', 'GarageQual_1010_1', 'GarageQual_1010_2', 'GarageCond_NArw', 'GarageCond_1010_0', 'GarageCond_1010_1', 'GarageCond_1010_2', 'PavedDrive_NArw', 'PavedDrive_1010_0', 'PavedDrive_1010_1', 'WoodDeckSF_NArw', 'OpenPorchSF_NArw', 'EnclosedPorch_NArw', '3SsnPorch_NArw', 'ScreenPorch_NArw', 'PoolArea_NArw', 'PoolQC_NArw', 'PoolQC_1010_0', 'PoolQC_1010_1', 'Fence_NArw', 'Fence_1010_0', 'Fence_1010_1', 'Fence_1010_2', 'MiscFeature_NArw', 'MiscFeature_1010_0', 'MiscFeature_1010_1', 'MiscFeature_1010_2', 'MiscVal_NArw', 'MoSold_NArw', 'YrSold_NArw', 'SaleType_NArw', 'SaleType_1010_0', 'SaleType_1010_1', 'SaleType_1010_2', 'SaleType_1010_3', 'SaleCondition_NArw', 'SaleCondition_1010_0', 'SaleCondition_1010_1', 'SaleCondition_1010_2']\n",
      "\n",
      "Automunge returned label column set: \n",
      "['SalePrice_exc2']\n",
      "\n",
      "_______________\n",
      "Automunge Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML_cmnd = {'autoML_type' : 'randomforest'}\n",
    "\n",
    "#by passing random forest parameters as a list \n",
    "#each imputation model will perform a grid search\n",
    "\n",
    "ML_cmnd.update({'MLinfill_cmnd' : \n",
    "                  {'RandomForestClassifier' : \n",
    "                    {'n_estimators' : [100, 222, 444] },\n",
    "                   'RandomForestRegressor' : \n",
    "                    {'n_estimators' : [100, 222, 444] }}})\n",
    "\n",
    "train, train_ID, labels, \\\n",
    "val, val_ID, val_labels, \\\n",
    "test, test_ID, test_labels, \\\n",
    "postprocess_dict = \\\n",
    "am.automunge(df_train,\n",
    "             labels_column = 'SalePrice',\n",
    "             trainID_column = 'Id',\n",
    "             MLinfill = True,\n",
    "             ML_cmnd = ML_cmnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
